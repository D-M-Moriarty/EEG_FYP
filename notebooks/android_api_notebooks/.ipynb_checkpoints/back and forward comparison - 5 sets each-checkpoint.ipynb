{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "rest_android = pd.read_csv(\"../../data_files/data_from_android_api/rest/rest_25_mins.csv\")\n",
    "\n",
    "# forward_android1 = pd.read_csv(\"../../data_files/data_from_android_api/forward/forward_5mins_1.csv\")\n",
    "forward_android2 = pd.read_csv(\"../../data_files/data_from_android_api/forward/forward_5mins_2.csv\")\n",
    "forward_android3 = pd.read_csv(\"../../data_files/data_from_android_api/forward/forward_5mins_3.csv\")\n",
    "forward_android4 = pd.read_csv(\"../../data_files/data_from_android_api/forward/forward_5mins_4.csv\")\n",
    "forward_android5 = pd.read_csv(\"../../data_files/data_from_android_api/forward/forward_5mins_5.csv\")\n",
    "\n",
    "back1 = pd.read_csv('../../data_files/data_from_android_api/back/back_5mins_1.csv')\n",
    "back2 = pd.read_csv('../../data_files/data_from_android_api/back/back_5mins_2.csv')\n",
    "back3 = pd.read_csv('../../data_files/data_from_android_api/back/back_5mins_3.csv')\n",
    "back4 = pd.read_csv('../../data_files/data_from_android_api/back/back_5mins_4.csv')\n",
    "\n",
    "# forward = pd.concat([forward_android1, forward_android2, forward_android3, \n",
    "#                      forward_android4, forward_android5])\n",
    "\n",
    "forward = pd.concat([forward_android5, forward_android4])\n",
    "back = pd.concat([back1, back2, back3, back4])\n",
    "\n",
    "dataDF = pd.concat([forward, back])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "u = [back1.delta.mean(), back1.theta.mean(), back1.alphaLow.mean(), \n",
    "     back1.betaHigh.mean(), back1.betaLow.mean(), back1.alphaHigh.mean(), \n",
    "     back1.gammaLow.mean(), back1.gammaMid.mean()]\n",
    "\n",
    "d = [forward.delta.mean(), forward.theta.mean(), forward.alphaLow.mean(), \n",
    "     forward.betaHigh.mean(), forward.betaLow.mean(), forward.alphaHigh.mean(), \n",
    "     forward.gammaLow.mean(), forward.gammaMid.mean()]\n",
    "\n",
    "\n",
    "index = ['delta', 'theta', 'alphaLow','alphaHigh', 'betaLow', 'betaHigh', 'gammaLow', 'gammaMid']\n",
    "\n",
    "df = pd.DataFrame({'back': u, 'forward': d}, index=index)\n",
    "ax = df.plot.bar(rot=0, figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# create an array of shape 30706, 9 = number of records by the features\n",
    "data = np.array([[0 for x in range(8)] for y in range(len(dataDF))])\n",
    "for i in range(len(dataDF)):\n",
    "    data[i] = [dataDF.delta.values[i],\n",
    "                       dataDF.theta.values[i],\n",
    "                       dataDF.alphaLow.values[i],\n",
    "                       dataDF.alphaHigh.values[i],\n",
    "                       dataDF.betaLow.values[i],\n",
    "                       dataDF.betaHigh.values[i],\n",
    "                       dataDF.gammaLow.values[i],\n",
    "                       dataDF.gammaMid.values[i]]\n",
    "    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "encoder = LabelBinarizer()\n",
    "labels = encoder.fit_transform(dataDF.action.values)\n",
    "\n",
    "# creating training and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, labels)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "scaler = MinMaxScaler()\n",
    "stan_scaler = StandardScaler()\n",
    "\n",
    "x_train = stan_scaler.fit_transform(x_train)\n",
    "x_test = stan_scaler.transform(x_test)\n",
    "\n",
    "all_data = dataDF.drop(['action'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14719694 0.18360138 0.10870645 0.10450244 0.11040881 0.10743751\n",
      " 0.13334139 0.1048051 ]\n",
      "The score for Random Forest  0.7348066298342542\n",
      "1642\n",
      "Accuracy for x_test: 0.7348066298342542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:33: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:33: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:33: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracy: 0.68 (+/- 0.22)\n",
      "[0.44262295 0.56284153 0.57377049 0.78688525 0.73770492 0.70879121\n",
      " 0.79120879 0.74175824 0.74033149 0.71823204]\n",
      "Thresh=0.105, n=8, Accuracy: 72.38%\n",
      "Thresh=0.105, n=7, Accuracy: 71.27%\n",
      "Thresh=0.107, n=6, Accuracy: 76.24%\n",
      "Thresh=0.109, n=5, Accuracy: 71.82%\n",
      "Thresh=0.110, n=4, Accuracy: 75.69%\n",
      "Thresh=0.133, n=3, Accuracy: 73.48%\n",
      "Thresh=0.147, n=2, Accuracy: 74.03%\n",
      "Thresh=0.184, n=1, Accuracy: 66.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:33: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:33: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:33: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:33: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:33: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Random Forrest\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(x_train, y_train)\n",
    "\n",
    "print(rfc.feature_importances_)\n",
    "\n",
    "print(\"The score for Random Forest \", rfc.score(x_test, y_test))\n",
    "y_pred = rfc.predict(x_test)\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(len(y_train))\n",
    "print(\"Accuracy for x_test:\", metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "scores = cross_val_score(rfc, all_data, labels, cv=10, scoring='accuracy')\n",
    "print(\"Cross Validation Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "print(scores)\n",
    "\n",
    "# Fit model using each importance as a threshold\n",
    "thresholds = sort(rfc.feature_importances_)\n",
    "for thresh in thresholds:\n",
    "\t# select features using threshold\n",
    "\tselection = SelectFromModel(rfc, threshold=thresh, prefit=True)\n",
    "\tselect_X_train = selection.transform(x_train)\n",
    "\t# train model\n",
    "\tselection_model = RandomForestClassifier()\n",
    "\tselection_model.fit(select_X_train, y_train)\n",
    "\t# eval model\n",
    "\tselect_X_test = selection.transform(x_test)\n",
    "\ty_pred = selection_model.predict(select_X_test)\n",
    "\tpredictions = [round(value) for value in y_pred]\n",
    "\taccuracy = accuracy_score(y_test, predictions)\n",
    "\tprint(\"Thresh=%.3f, n=%d, Accuracy: %.2f%%\" % (thresh, select_X_train.shape[1], accuracy*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "The score for XGBoost  0.6666666666666666\n",
      "Accuracy for x_test: 0.6666666666666666\n",
      "Accuracy: 66.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracy: 0.69 (+/- 0.31)\n",
      "[0.34972678 0.48087432 0.58469945 0.81967213 0.7704918  0.73076923\n",
      " 0.8021978  0.76923077 0.8121547  0.79558011]\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(x_train, y_train)\n",
    "\n",
    "# plot feature importance\n",
    "plot_importance(xgb)\n",
    "pyplot.show()\n",
    "print(xgb)\n",
    "print(\"The score for XGBoost \", xgb.score(x_test, y_test))\n",
    "y_pred = xgb.predict(x_test)\n",
    "\n",
    "print(\"Accuracy for x_test:\", metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = metrics.accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "\n",
    "scores = cross_val_score(xgb, all_data, labels, cv=10, scoring='accuracy')\n",
    "print(\"Cross Validation Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_set = [(x_train, y_train), (x_test, y_test)]\n",
    "eval_metric = [\"auc\",\"error\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Tuning and feature importance XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score for XGBoost  0.7734806629834254\n",
      "Accuracy for x_test: 0.7734806629834254\n",
      "Accuracy: 77.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracy: 0.70 (+/- 0.22)\n",
      "[0.46994536 0.53005464 0.61748634 0.80327869 0.73770492 0.73626374\n",
      " 0.76923077 0.75824176 0.79558011 0.77348066]\n",
      "Thresh=0.091, n=8, Accuracy: 77.35%\n",
      "Thresh=0.103, n=7, Accuracy: 76.24%\n",
      "Thresh=0.106, n=6, Accuracy: 76.24%\n",
      "Thresh=0.111, n=5, Accuracy: 77.90%\n",
      "Thresh=0.128, n=4, Accuracy: 76.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresh=0.129, n=3, Accuracy: 75.14%\n",
      "Thresh=0.133, n=2, Accuracy: 72.93%\n",
      "Thresh=0.199, n=1, Accuracy: 81.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "from numpy import sort\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "xgb = XGBClassifier(silent=True, \n",
    "                      scale_pos_weight=1,\n",
    "                      learning_rate=0.01,  \n",
    "                      colsample_bytree = 0.4,\n",
    "                      subsample = 0.3,\n",
    "                      objective='binary:logistic', \n",
    "                      n_estimators=100, \n",
    "                      reg_alpha = 0.3,\n",
    "                      max_depth=4, \n",
    "                      gamma=2)\n",
    "xgb.fit(x_train, y_train)\n",
    "# plot feature importance\n",
    "plot_importance(xgb)\n",
    "pyplot.show()\n",
    "# print(xgb)\n",
    "print(\"The score for XGBoost \", xgb.score(x_test, y_test))\n",
    "y_pred = xgb.predict(x_test)\n",
    "\n",
    "print(\"Accuracy for x_test:\", metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = metrics.accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "\n",
    "scores = cross_val_score(xgb, all_data, labels, cv=10, scoring='accuracy')\n",
    "print(\"Cross Validation Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "print(scores)\n",
    "\n",
    "# Fit model using each importance as a threshold\n",
    "thresholds = sort(xgb.feature_importances_)\n",
    "for thresh in thresholds:\n",
    "\t# select features using threshold\n",
    "\tselection = SelectFromModel(xgb, threshold=thresh, prefit=True)\n",
    "\tselect_X_train = selection.transform(x_train)\n",
    "\t# train model\n",
    "\tselection_model = XGBClassifier(silent=True, \n",
    "                      scale_pos_weight=1,\n",
    "                      learning_rate=0.01,  \n",
    "                      colsample_bytree = 0.4,\n",
    "                      subsample = 0.3,\n",
    "                      objective='binary:logistic', \n",
    "                      n_estimators=100, \n",
    "                      reg_alpha = 0.3,\n",
    "                      max_depth=4, \n",
    "                      gamma=2)\n",
    "\tselection_model.fit(select_X_train, y_train)\n",
    "\t# eval model\n",
    "\tselect_X_test = selection.transform(x_test)\n",
    "\ty_pred = selection_model.predict(select_X_test)\n",
    "\tpredictions = [round(value) for value in y_pred]\n",
    "\taccuracy = accuracy_score(y_test, predictions)\n",
    "\tprint(\"Thresh=%.3f, n=%d, Accuracy: %.2f%%\" % (thresh, select_X_train.shape[1], accuracy*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_90 (Dense)             (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 10,641\n",
      "Trainable params: 10,641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1642/1642 [==============================] - 3s 2ms/step - loss: 0.6251 - acc: 0.6663\n",
      "Epoch 2/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.6052 - acc: 0.6760\n",
      "Epoch 3/100\n",
      "1642/1642 [==============================] - 1s 837us/step - loss: 0.6012 - acc: 0.6736\n",
      "Epoch 4/100\n",
      "1642/1642 [==============================] - 1s 838us/step - loss: 0.5999 - acc: 0.6790\n",
      "Epoch 5/100\n",
      "1642/1642 [==============================] - 1s 838us/step - loss: 0.5954 - acc: 0.6797\n",
      "Epoch 6/100\n",
      "1642/1642 [==============================] - 1s 840us/step - loss: 0.5865 - acc: 0.6827\n",
      "Epoch 7/100\n",
      "1642/1642 [==============================] - 2s 947us/step - loss: 0.5792 - acc: 0.6778\n",
      "Epoch 8/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.5680 - acc: 0.6833\n",
      "Epoch 9/100\n",
      "1642/1642 [==============================] - 3s 2ms/step - loss: 0.5594 - acc: 0.7077\n",
      "Epoch 10/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.5559 - acc: 0.7016\n",
      "Epoch 11/100\n",
      "1642/1642 [==============================] - 2s 975us/step - loss: 0.5512 - acc: 0.6998\n",
      "Epoch 12/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.5494 - acc: 0.6955\n",
      "Epoch 13/100\n",
      "1642/1642 [==============================] - 2s 981us/step - loss: 0.5466 - acc: 0.7113\n",
      "Epoch 14/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.5450 - acc: 0.7144\n",
      "Epoch 15/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.5398 - acc: 0.7156\n",
      "Epoch 16/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.5368 - acc: 0.7217\n",
      "Epoch 17/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.5364 - acc: 0.7125\n",
      "Epoch 18/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.5339 - acc: 0.7125\n",
      "Epoch 19/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.5307 - acc: 0.7107\n",
      "Epoch 20/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.5309 - acc: 0.7156\n",
      "Epoch 21/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.5285 - acc: 0.7144\n",
      "Epoch 22/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.5248 - acc: 0.7095\n",
      "Epoch 23/100\n",
      "1642/1642 [==============================] - 2s 978us/step - loss: 0.5197 - acc: 0.7235\n",
      "Epoch 24/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.5220 - acc: 0.7217\n",
      "Epoch 25/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.5220 - acc: 0.7235\n",
      "Epoch 26/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.5194 - acc: 0.7199\n",
      "Epoch 27/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.5189 - acc: 0.7235\n",
      "Epoch 28/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.5204 - acc: 0.7247\n",
      "Epoch 29/100\n",
      "1642/1642 [==============================] - 2s 995us/step - loss: 0.5177 - acc: 0.7217\n",
      "Epoch 30/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.5144 - acc: 0.7284\n",
      "Epoch 31/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.5109 - acc: 0.7333\n",
      "Epoch 32/100\n",
      "1642/1642 [==============================] - 2s 999us/step - loss: 0.5104 - acc: 0.7333\n",
      "Epoch 33/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.5151 - acc: 0.7180\n",
      "Epoch 34/100\n",
      "1642/1642 [==============================] - 2s 994us/step - loss: 0.5101 - acc: 0.7314\n",
      "Epoch 35/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.5107 - acc: 0.7217\n",
      "Epoch 36/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.5113 - acc: 0.7272\n",
      "Epoch 37/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.5126 - acc: 0.7326\n",
      "Epoch 38/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.5128 - acc: 0.7326\n",
      "Epoch 39/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.5043 - acc: 0.7320\n",
      "Epoch 40/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.5112 - acc: 0.7272\n",
      "Epoch 41/100\n",
      "1642/1642 [==============================] - 2s 999us/step - loss: 0.5076 - acc: 0.7192\n",
      "Epoch 42/100\n",
      "1642/1642 [==============================] - 2s 987us/step - loss: 0.5066 - acc: 0.7290\n",
      "Epoch 43/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.5059 - acc: 0.7205\n",
      "Epoch 44/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.5088 - acc: 0.7339\n",
      "Epoch 45/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.5086 - acc: 0.7345A: 0s - loss: 0.5176 - acc: \n",
      "Epoch 46/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.5042 - acc: 0.7259\n",
      "Epoch 47/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.5105 - acc: 0.7345\n",
      "Epoch 48/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.5034 - acc: 0.7302\n",
      "Epoch 49/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.5067 - acc: 0.7290\n",
      "Epoch 50/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.5056 - acc: 0.7266A: 1s - loss: 0.4995 - a - ETA: 1s - loss: 0\n",
      "Epoch 51/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.5015 - acc: 0.7302\n",
      "Epoch 52/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.5033 - acc: 0.7284\n",
      "Epoch 53/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.5000 - acc: 0.7345\n",
      "Epoch 54/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.5001 - acc: 0.7326\n",
      "Epoch 55/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.4971 - acc: 0.7369\n",
      "Epoch 56/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.4988 - acc: 0.7302\n",
      "Epoch 57/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.5011 - acc: 0.7333\n",
      "Epoch 58/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.4979 - acc: 0.7333\n",
      "Epoch 59/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.4971 - acc: 0.7272\n",
      "Epoch 60/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.4978 - acc: 0.7345\n",
      "Epoch 61/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.4973 - acc: 0.7393\n",
      "Epoch 62/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.4961 - acc: 0.7369\n",
      "Epoch 63/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.4999 - acc: 0.7296\n",
      "Epoch 64/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.4985 - acc: 0.7241\n",
      "Epoch 65/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.4950 - acc: 0.7351\n",
      "Epoch 66/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.4915 - acc: 0.7363\n",
      "Epoch 67/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.4949 - acc: 0.7387\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1642/1642 [==============================] - 2s 965us/step - loss: 0.4927 - acc: 0.7339\n",
      "Epoch 69/100\n",
      "1642/1642 [==============================] - 2s 998us/step - loss: 0.4901 - acc: 0.7473\n",
      "Epoch 70/100\n",
      "1642/1642 [==============================] - 2s 978us/step - loss: 0.4920 - acc: 0.7363\n",
      "Epoch 71/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.4945 - acc: 0.7387\n",
      "Epoch 72/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.4936 - acc: 0.7351\n",
      "Epoch 73/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.4915 - acc: 0.7375\n",
      "Epoch 74/100\n",
      "1642/1642 [==============================] - 2s 953us/step - loss: 0.4925 - acc: 0.7320\n",
      "Epoch 75/100\n",
      "1642/1642 [==============================] - 2s 993us/step - loss: 0.4901 - acc: 0.7406\n",
      "Epoch 76/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.4901 - acc: 0.7326\n",
      "Epoch 77/100\n",
      "1642/1642 [==============================] - 2s 968us/step - loss: 0.4908 - acc: 0.7333\n",
      "Epoch 78/100\n",
      "1642/1642 [==============================] - 2s 958us/step - loss: 0.4895 - acc: 0.7333\n",
      "Epoch 79/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.4927 - acc: 0.7357\n",
      "Epoch 80/100\n",
      "1642/1642 [==============================] - 2s 966us/step - loss: 0.4873 - acc: 0.7333\n",
      "Epoch 81/100\n",
      "1642/1642 [==============================] - 2s 990us/step - loss: 0.4881 - acc: 0.7400\n",
      "Epoch 82/100\n",
      "1642/1642 [==============================] - 2s 993us/step - loss: 0.4868 - acc: 0.7387\n",
      "Epoch 83/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.4865 - acc: 0.7369\n",
      "Epoch 84/100\n",
      "1642/1642 [==============================] - 2s 960us/step - loss: 0.4850 - acc: 0.7339\n",
      "Epoch 85/100\n",
      "1642/1642 [==============================] - 2s 982us/step - loss: 0.4863 - acc: 0.7412\n",
      "Epoch 86/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.4882 - acc: 0.7320\n",
      "Epoch 87/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.4836 - acc: 0.7418\n",
      "Epoch 88/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.4804 - acc: 0.7357\n",
      "Epoch 89/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.4878 - acc: 0.7375\n",
      "Epoch 90/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.4851 - acc: 0.7393\n",
      "Epoch 91/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.4835 - acc: 0.7406\n",
      "Epoch 92/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.4836 - acc: 0.7375\n",
      "Epoch 93/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.4799 - acc: 0.7369\n",
      "Epoch 94/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.4810 - acc: 0.7393\n",
      "Epoch 95/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.4793 - acc: 0.7436A: 0s - loss: 0\n",
      "Epoch 96/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.4828 - acc: 0.7387\n",
      "Epoch 97/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.4809 - acc: 0.7302\n",
      "Epoch 98/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.4760 - acc: 0.7400\n",
      "Epoch 99/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.4841 - acc: 0.7424\n",
      "Epoch 100/100\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.4836 - acc: 0.7357\n",
      "181/181 [==============================] - 0s 2ms/step\n",
      "loss and metrics [0.451305543520174, 0.7845303873989463]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "# from keras import regularizers kernel_regularizer=regularizers.l2(0.01), \n",
    "from keras.optimizers import Adam\n",
    "\n",
    "network = models.Sequential()\n",
    "\n",
    "network.add(layers.Dense(16, input_shape=(8,)))\n",
    "network.add(layers.Dense(32, activation=\"relu\"))\n",
    "network.add(layers.Dense(64, activation=\"relu\"))\n",
    "network.add(layers.Dense(64, activation=\"relu\"))\n",
    "network.add(layers.Dense(32, activation=\"relu\"))\n",
    "network.add(layers.Dense(32, activation=\"relu\"))\n",
    "network.add(layers.Dense(16, activation=\"sigmoid\"))\n",
    "network.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Adam = Adam(lr=0.05)\n",
    "network.compile(optimizer=Adam(lr=0.00038),\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['acc'])\n",
    "\n",
    "network.summary()\n",
    "\n",
    "history = network.fit(x_train, y_train,\n",
    "                      epochs=100, verbose=1, batch_size=2)\n",
    "\n",
    "loss_and_metrics = network.evaluate(x_test, y_test)\n",
    "print('loss and metrics', loss_and_metrics)\n",
    "\n",
    "# print('prediction: ', network.predict(test_data))\n",
    "\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "all_labels = dataDF.action.values\n",
    "\n",
    "encoder = LabelBinarizer()\n",
    "all_labels = encoder.fit_transform(all_labels)\n",
    "    \n",
    "# create an array of shape 30706, 9 = number of records by the features\n",
    "all_data = np.array([[0 for x in range(8)] for y in range(len(dataDF))])\n",
    "for i in range(len(dataDF)):\n",
    "    all_data[i] = [dataDF.delta.values[i],\n",
    "                       dataDF.theta.values[i],\n",
    "                       dataDF.alphaLow.values[i],\n",
    "                       dataDF.alphaHigh.values[i],\n",
    "                       dataDF.betaLow.values[i],\n",
    "                       dataDF.betaHigh.values[i],\n",
    "                       dataDF.gammaLow.values[i],\n",
    "                       dataDF.gammaMid.values[i]]\n",
    "    \n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "scaler = MinMaxScaler()\n",
    "stan_scaler = StandardScaler()\n",
    "\n",
    "all_data = scaler.fit_transform(all_data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold 1/10.............................................\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 5,425\n",
      "Trainable params: 5,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1312 samples, validate on 328 samples\n",
      "Epoch 1/40\n",
      "1312/1312 [==============================] - 1s 882us/step - loss: 0.6792 - acc: 0.5534 - val_loss: 0.5226 - val_acc: 0.9238\n",
      "Epoch 2/40\n",
      "1312/1312 [==============================] - 1s 472us/step - loss: 0.6486 - acc: 0.6235 - val_loss: 0.4408 - val_acc: 0.9573\n",
      "Epoch 3/40\n",
      "1312/1312 [==============================] - 1s 447us/step - loss: 0.6424 - acc: 0.6402 - val_loss: 0.3889 - val_acc: 0.9604\n",
      "Epoch 4/40\n",
      "1312/1312 [==============================] - 1s 446us/step - loss: 0.6428 - acc: 0.6319 - val_loss: 0.4392 - val_acc: 0.9329\n",
      "Epoch 5/40\n",
      "1312/1312 [==============================] - 1s 442us/step - loss: 0.6406 - acc: 0.6448 - val_loss: 0.4502 - val_acc: 0.9299\n",
      "Epoch 6/40\n",
      "1312/1312 [==============================] - 1s 445us/step - loss: 0.6399 - acc: 0.6425 - val_loss: 0.4551 - val_acc: 0.9299\n",
      "Epoch 7/40\n",
      "1312/1312 [==============================] - 1s 451us/step - loss: 0.6397 - acc: 0.6402 - val_loss: 0.4427 - val_acc: 0.9360\n",
      "Epoch 8/40\n",
      "1312/1312 [==============================] - 1s 472us/step - loss: 0.6379 - acc: 0.6448 - val_loss: 0.4335 - val_acc: 0.9329\n",
      "Epoch 9/40\n",
      "1312/1312 [==============================] - 1s 455us/step - loss: 0.6366 - acc: 0.6448 - val_loss: 0.4678 - val_acc: 0.8963\n",
      "Epoch 10/40\n",
      "1312/1312 [==============================] - 1s 478us/step - loss: 0.6357 - acc: 0.6441 - val_loss: 0.4733 - val_acc: 0.8963\n",
      "Epoch 11/40\n",
      "1312/1312 [==============================] - 1s 473us/step - loss: 0.6339 - acc: 0.6486 - val_loss: 0.5033 - val_acc: 0.8963\n",
      "Epoch 12/40\n",
      "1312/1312 [==============================] - 1s 532us/step - loss: 0.6344 - acc: 0.6463 - val_loss: 0.4403 - val_acc: 0.9360\n",
      "Epoch 13/40\n",
      "1312/1312 [==============================] - 1s 494us/step - loss: 0.6317 - acc: 0.6479 - val_loss: 0.4885 - val_acc: 0.8963\n",
      "Epoch 14/40\n",
      "1312/1312 [==============================] - 1s 441us/step - loss: 0.6293 - acc: 0.6433 - val_loss: 0.4361 - val_acc: 0.9390\n",
      "Epoch 15/40\n",
      "1312/1312 [==============================] - 1s 449us/step - loss: 0.6216 - acc: 0.6463 - val_loss: 0.4412 - val_acc: 0.8963\n",
      "Epoch 16/40\n",
      "1312/1312 [==============================] - 1s 444us/step - loss: 0.6125 - acc: 0.6441 - val_loss: 0.5305 - val_acc: 0.8628\n",
      "Epoch 17/40\n",
      "1312/1312 [==============================] - 1s 454us/step - loss: 0.5978 - acc: 0.6753 - val_loss: 0.3566 - val_acc: 0.9268\n",
      "Epoch 18/40\n",
      "1312/1312 [==============================] - 1s 443us/step - loss: 0.5893 - acc: 0.6890 - val_loss: 0.3590 - val_acc: 0.9268\n",
      "Epoch 19/40\n",
      "1312/1312 [==============================] - 1s 461us/step - loss: 0.5801 - acc: 0.6966 - val_loss: 0.3001 - val_acc: 0.9421\n",
      "Epoch 20/40\n",
      "1312/1312 [==============================] - 1s 445us/step - loss: 0.5752 - acc: 0.6928 - val_loss: 0.3026 - val_acc: 0.9390\n",
      "Epoch 21/40\n",
      "1312/1312 [==============================] - 1s 458us/step - loss: 0.5703 - acc: 0.7058 - val_loss: 0.3784 - val_acc: 0.8811\n",
      "Epoch 22/40\n",
      "1312/1312 [==============================] - 1s 449us/step - loss: 0.5638 - acc: 0.7088 - val_loss: 0.3380 - val_acc: 0.9116\n",
      "Epoch 23/40\n",
      "1312/1312 [==============================] - 1s 436us/step - loss: 0.5631 - acc: 0.7165 - val_loss: 0.3201 - val_acc: 0.9085\n",
      "Epoch 24/40\n",
      "1312/1312 [==============================] - 1s 448us/step - loss: 0.5608 - acc: 0.7149 - val_loss: 0.2839 - val_acc: 0.9238\n",
      "Epoch 25/40\n",
      "1312/1312 [==============================] - 1s 450us/step - loss: 0.5561 - acc: 0.7172 - val_loss: 0.3227 - val_acc: 0.8963\n",
      "Epoch 26/40\n",
      "1312/1312 [==============================] - 1s 461us/step - loss: 0.5566 - acc: 0.7210 - val_loss: 0.2831 - val_acc: 0.9177\n",
      "Epoch 27/40\n",
      "1312/1312 [==============================] - 1s 443us/step - loss: 0.5516 - acc: 0.7165 - val_loss: 0.3372 - val_acc: 0.8780\n",
      "Epoch 28/40\n",
      "1312/1312 [==============================] - 1s 446us/step - loss: 0.5521 - acc: 0.7203 - val_loss: 0.2979 - val_acc: 0.8994\n",
      "Epoch 29/40\n",
      "1312/1312 [==============================] - 1s 444us/step - loss: 0.5489 - acc: 0.7264 - val_loss: 0.3327 - val_acc: 0.8628\n",
      "Epoch 30/40\n",
      "1312/1312 [==============================] - 1s 454us/step - loss: 0.5485 - acc: 0.7241 - val_loss: 0.2991 - val_acc: 0.8933\n",
      "Epoch 31/40\n",
      "1312/1312 [==============================] - 1s 447us/step - loss: 0.5465 - acc: 0.7317 - val_loss: 0.3535 - val_acc: 0.8567\n",
      "Epoch 32/40\n",
      "1312/1312 [==============================] - 1s 466us/step - loss: 0.5453 - acc: 0.7233 - val_loss: 0.3195 - val_acc: 0.8750\n",
      "Epoch 33/40\n",
      "1312/1312 [==============================] - 1s 519us/step - loss: 0.5379 - acc: 0.7393 - val_loss: 0.2689 - val_acc: 0.8933\n",
      "Epoch 34/40\n",
      "1312/1312 [==============================] - 1s 515us/step - loss: 0.5380 - acc: 0.7218 - val_loss: 0.3228 - val_acc: 0.8689\n",
      "Epoch 35/40\n",
      "1312/1312 [==============================] - 1s 441us/step - loss: 0.5418 - acc: 0.7248 - val_loss: 0.3437 - val_acc: 0.8598\n",
      "Epoch 36/40\n",
      "1312/1312 [==============================] - 1s 454us/step - loss: 0.5407 - acc: 0.7279 - val_loss: 0.2774 - val_acc: 0.8994\n",
      "Epoch 37/40\n",
      "1312/1312 [==============================] - 1s 537us/step - loss: 0.5352 - acc: 0.7317 - val_loss: 0.2756 - val_acc: 0.8902\n",
      "Epoch 38/40\n",
      "1312/1312 [==============================] - 1s 467us/step - loss: 0.5344 - acc: 0.7370 - val_loss: 0.3373 - val_acc: 0.8537\n",
      "Epoch 39/40\n",
      "1312/1312 [==============================] - 1s 563us/step - loss: 0.5357 - acc: 0.7340 - val_loss: 0.3185 - val_acc: 0.8689\n",
      "Epoch 40/40\n",
      "1312/1312 [==============================] - 1s 469us/step - loss: 0.5364 - acc: 0.7279 - val_loss: 0.2949 - val_acc: 0.8780\n",
      "183/183 [==============================] - 0s 16us/step\n",
      "Average accuracy of model on the dev set =  0.3715847001049688\n",
      "Training on fold 2/10.............................................\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 5,425\n",
      "Trainable params: 5,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1312 samples, validate on 328 samples\n",
      "Epoch 1/40\n",
      "1312/1312 [==============================] - 1s 844us/step - loss: 0.6765 - acc: 0.5800 - val_loss: 0.5323 - val_acc: 0.9817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/40\n",
      "1312/1312 [==============================] - 1s 453us/step - loss: 0.6463 - acc: 0.6220 - val_loss: 0.4731 - val_acc: 0.9085\n",
      "Epoch 3/40\n",
      "1312/1312 [==============================] - 1s 450us/step - loss: 0.6380 - acc: 0.6364 - val_loss: 0.4228 - val_acc: 0.9543\n",
      "Epoch 4/40\n",
      "1312/1312 [==============================] - 1s 439us/step - loss: 0.6319 - acc: 0.6402 - val_loss: 0.4703 - val_acc: 0.8963\n",
      "Epoch 5/40\n",
      "1312/1312 [==============================] - 1s 462us/step - loss: 0.6242 - acc: 0.6509 - val_loss: 0.3579 - val_acc: 0.9634\n",
      "Epoch 6/40\n",
      "1312/1312 [==============================] - 1s 463us/step - loss: 0.6195 - acc: 0.6387 - val_loss: 0.3883 - val_acc: 0.9421\n",
      "Epoch 7/40\n",
      "1312/1312 [==============================] - 1s 459us/step - loss: 0.6087 - acc: 0.6593 - val_loss: 0.4487 - val_acc: 0.8872\n",
      "Epoch 8/40\n",
      "1312/1312 [==============================] - 1s 487us/step - loss: 0.6000 - acc: 0.6639 - val_loss: 0.3806 - val_acc: 0.9238\n",
      "Epoch 9/40\n",
      "1312/1312 [==============================] - 1s 468us/step - loss: 0.5872 - acc: 0.6928 - val_loss: 0.3639 - val_acc: 0.8963\n",
      "Epoch 10/40\n",
      "1312/1312 [==============================] - 1s 478us/step - loss: 0.5814 - acc: 0.6989 - val_loss: 0.4290 - val_acc: 0.8354\n",
      "Epoch 11/40\n",
      "1312/1312 [==============================] - 1s 449us/step - loss: 0.5753 - acc: 0.6959 - val_loss: 0.3801 - val_acc: 0.8598\n",
      "Epoch 12/40\n",
      "1312/1312 [==============================] - 1s 587us/step - loss: 0.5681 - acc: 0.7111 - val_loss: 0.3043 - val_acc: 0.9085\n",
      "Epoch 13/40\n",
      "1312/1312 [==============================] - 1s 491us/step - loss: 0.5636 - acc: 0.7111 - val_loss: 0.4636 - val_acc: 0.7988\n",
      "Epoch 14/40\n",
      "1312/1312 [==============================] - 1s 460us/step - loss: 0.5622 - acc: 0.7149 - val_loss: 0.3119 - val_acc: 0.8872\n",
      "Epoch 15/40\n",
      "1312/1312 [==============================] - 1s 532us/step - loss: 0.5579 - acc: 0.7119 - val_loss: 0.2846 - val_acc: 0.8994\n",
      "Epoch 16/40\n",
      "1312/1312 [==============================] - 1s 730us/step - loss: 0.5572 - acc: 0.7119 - val_loss: 0.3012 - val_acc: 0.8811\n",
      "Epoch 17/40\n",
      "1312/1312 [==============================] - 1s 674us/step - loss: 0.5542 - acc: 0.7195 - val_loss: 0.3104 - val_acc: 0.8720\n",
      "Epoch 18/40\n",
      "1312/1312 [==============================] - 1s 649us/step - loss: 0.5506 - acc: 0.7203 - val_loss: 0.3019 - val_acc: 0.8720\n",
      "Epoch 19/40\n",
      "1312/1312 [==============================] - 1s 481us/step - loss: 0.5547 - acc: 0.7233 - val_loss: 0.2957 - val_acc: 0.8689\n",
      "Epoch 20/40\n",
      "1312/1312 [==============================] - 1s 464us/step - loss: 0.5472 - acc: 0.7210 - val_loss: 0.3755 - val_acc: 0.7774\n",
      "Epoch 21/40\n",
      "1312/1312 [==============================] - 1s 496us/step - loss: 0.5479 - acc: 0.7233 - val_loss: 0.2820 - val_acc: 0.8780\n",
      "Epoch 22/40\n",
      "1312/1312 [==============================] - 1s 472us/step - loss: 0.5472 - acc: 0.7172 - val_loss: 0.2691 - val_acc: 0.8780\n",
      "Epoch 23/40\n",
      "1312/1312 [==============================] - 1s 473us/step - loss: 0.5420 - acc: 0.7264 - val_loss: 0.2928 - val_acc: 0.8628\n",
      "Epoch 24/40\n",
      "1312/1312 [==============================] - 1s 489us/step - loss: 0.5483 - acc: 0.7172 - val_loss: 0.3054 - val_acc: 0.8598\n",
      "Epoch 25/40\n",
      "1312/1312 [==============================] - 1s 645us/step - loss: 0.5421 - acc: 0.7111 - val_loss: 0.3143 - val_acc: 0.8598\n",
      "Epoch 26/40\n",
      "1312/1312 [==============================] - 1s 671us/step - loss: 0.5414 - acc: 0.7188 - val_loss: 0.2654 - val_acc: 0.8720\n",
      "Epoch 27/40\n",
      "1312/1312 [==============================] - 1s 657us/step - loss: 0.5395 - acc: 0.7256 - val_loss: 0.2943 - val_acc: 0.8598\n",
      "Epoch 28/40\n",
      "1312/1312 [==============================] - 1s 688us/step - loss: 0.5399 - acc: 0.7195 - val_loss: 0.3033 - val_acc: 0.8537\n",
      "Epoch 29/40\n",
      "1312/1312 [==============================] - 1s 523us/step - loss: 0.5387 - acc: 0.7172 - val_loss: 0.2858 - val_acc: 0.8445\n",
      "Epoch 30/40\n",
      "1312/1312 [==============================] - 1s 542us/step - loss: 0.5388 - acc: 0.7149 - val_loss: 0.4688 - val_acc: 0.7378\n",
      "Epoch 31/40\n",
      "1312/1312 [==============================] - 1s 492us/step - loss: 0.5373 - acc: 0.7248 - val_loss: 0.2745 - val_acc: 0.8628\n",
      "Epoch 32/40\n",
      "1312/1312 [==============================] - 1s 503us/step - loss: 0.5357 - acc: 0.7226 - val_loss: 0.3672 - val_acc: 0.8079\n",
      "Epoch 33/40\n",
      "1312/1312 [==============================] - 1s 518us/step - loss: 0.5309 - acc: 0.7218 - val_loss: 0.3888 - val_acc: 0.7988\n",
      "Epoch 34/40\n",
      "1312/1312 [==============================] - 1s 504us/step - loss: 0.5314 - acc: 0.7325 - val_loss: 0.3056 - val_acc: 0.8354\n",
      "Epoch 35/40\n",
      "1312/1312 [==============================] - 1s 477us/step - loss: 0.5322 - acc: 0.7248 - val_loss: 0.3451 - val_acc: 0.8201\n",
      "Epoch 36/40\n",
      "1312/1312 [==============================] - 1s 530us/step - loss: 0.5317 - acc: 0.7287 - val_loss: 0.3703 - val_acc: 0.8079\n",
      "Epoch 37/40\n",
      "1312/1312 [==============================] - 1s 501us/step - loss: 0.5331 - acc: 0.7165 - val_loss: 0.3412 - val_acc: 0.8232\n",
      "Epoch 38/40\n",
      "1312/1312 [==============================] - 1s 468us/step - loss: 0.5271 - acc: 0.7309 - val_loss: 0.3464 - val_acc: 0.8232\n",
      "Epoch 39/40\n",
      "1312/1312 [==============================] - 1s 489us/step - loss: 0.5341 - acc: 0.7287 - val_loss: 0.3034 - val_acc: 0.8354\n",
      "Epoch 40/40\n",
      "1312/1312 [==============================] - 1s 485us/step - loss: 0.5301 - acc: 0.7226 - val_loss: 0.3430 - val_acc: 0.8140\n",
      "183/183 [==============================] - 0s 26us/step\n",
      "Average accuracy of model on the dev set =  0.398907103336574\n",
      "Training on fold 3/10.............................................\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 5,425\n",
      "Trainable params: 5,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1312 samples, validate on 328 samples\n",
      "Epoch 1/40\n",
      "1312/1312 [==============================] - 1s 904us/step - loss: 0.6729 - acc: 0.5922 - val_loss: 0.5477 - val_acc: 0.9878\n",
      "Epoch 2/40\n",
      "1312/1312 [==============================] - 1s 509us/step - loss: 0.6548 - acc: 0.6166 - val_loss: 0.5002 - val_acc: 0.9024\n",
      "Epoch 3/40\n",
      "1312/1312 [==============================] - 1s 485us/step - loss: 0.6453 - acc: 0.6288 - val_loss: 0.4844 - val_acc: 0.8994\n",
      "Epoch 4/40\n",
      "1312/1312 [==============================] - 1s 470us/step - loss: 0.6408 - acc: 0.6357 - val_loss: 0.4461 - val_acc: 0.9116\n",
      "Epoch 5/40\n",
      "1312/1312 [==============================] - 1s 460us/step - loss: 0.6359 - acc: 0.6319 - val_loss: 0.4121 - val_acc: 0.9146\n",
      "Epoch 6/40\n",
      "1312/1312 [==============================] - 1s 478us/step - loss: 0.6306 - acc: 0.6372 - val_loss: 0.4121 - val_acc: 0.9329\n",
      "Epoch 7/40\n",
      "1312/1312 [==============================] - 1s 450us/step - loss: 0.6247 - acc: 0.6372 - val_loss: 0.4283 - val_acc: 0.9024\n",
      "Epoch 8/40\n",
      "1312/1312 [==============================] - 1s 468us/step - loss: 0.6183 - acc: 0.6364 - val_loss: 0.4475 - val_acc: 0.8933\n",
      "Epoch 9/40\n",
      "1312/1312 [==============================] - 1s 470us/step - loss: 0.6101 - acc: 0.6486 - val_loss: 0.3893 - val_acc: 0.9299\n",
      "Epoch 10/40\n",
      "1312/1312 [==============================] - 1s 463us/step - loss: 0.6042 - acc: 0.6601 - val_loss: 0.4527 - val_acc: 0.8811\n",
      "Epoch 11/40\n",
      "1312/1312 [==============================] - 1s 480us/step - loss: 0.5939 - acc: 0.6715 - val_loss: 0.3442 - val_acc: 0.9116\n",
      "Epoch 12/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1312/1312 [==============================] - 1s 479us/step - loss: 0.5891 - acc: 0.6684 - val_loss: 0.3487 - val_acc: 0.8994\n",
      "Epoch 13/40\n",
      "1312/1312 [==============================] - 1s 461us/step - loss: 0.5801 - acc: 0.6799 - val_loss: 0.3555 - val_acc: 0.8598\n",
      "Epoch 14/40\n",
      "1312/1312 [==============================] - 1s 458us/step - loss: 0.5813 - acc: 0.6784 - val_loss: 0.3981 - val_acc: 0.8384\n",
      "Epoch 15/40\n",
      "1312/1312 [==============================] - 1s 449us/step - loss: 0.5754 - acc: 0.6890 - val_loss: 0.3431 - val_acc: 0.8841\n",
      "Epoch 16/40\n",
      "1312/1312 [==============================] - 1s 476us/step - loss: 0.5705 - acc: 0.6989 - val_loss: 0.4066 - val_acc: 0.8293\n",
      "Epoch 17/40\n",
      "1312/1312 [==============================] - 1s 457us/step - loss: 0.5626 - acc: 0.7043 - val_loss: 0.3578 - val_acc: 0.8232\n",
      "Epoch 18/40\n",
      "1312/1312 [==============================] - 1s 544us/step - loss: 0.5619 - acc: 0.7073 - val_loss: 0.2108 - val_acc: 0.9238\n",
      "Epoch 19/40\n",
      "1312/1312 [==============================] - 1s 718us/step - loss: 0.5651 - acc: 0.7035 - val_loss: 0.3478 - val_acc: 0.8567\n",
      "Epoch 20/40\n",
      "1312/1312 [==============================] - 1s 582us/step - loss: 0.5610 - acc: 0.7027 - val_loss: 0.3086 - val_acc: 0.8750\n",
      "Epoch 21/40\n",
      "1312/1312 [==============================] - 1s 455us/step - loss: 0.5564 - acc: 0.7073 - val_loss: 0.2813 - val_acc: 0.8689\n",
      "Epoch 22/40\n",
      "1312/1312 [==============================] - 1s 469us/step - loss: 0.5558 - acc: 0.7050 - val_loss: 0.2596 - val_acc: 0.8872\n",
      "Epoch 23/40\n",
      "1312/1312 [==============================] - 1s 475us/step - loss: 0.5554 - acc: 0.7127 - val_loss: 0.3092 - val_acc: 0.8537\n",
      "Epoch 24/40\n",
      "1312/1312 [==============================] - 1s 448us/step - loss: 0.5518 - acc: 0.6974 - val_loss: 0.3237 - val_acc: 0.8537\n",
      "Epoch 25/40\n",
      "1312/1312 [==============================] - 1s 527us/step - loss: 0.5511 - acc: 0.6936 - val_loss: 0.3827 - val_acc: 0.8110\n",
      "Epoch 26/40\n",
      "1312/1312 [==============================] - 1s 586us/step - loss: 0.5472 - acc: 0.7073 - val_loss: 0.3180 - val_acc: 0.8384\n",
      "Epoch 27/40\n",
      "1312/1312 [==============================] - 1s 860us/step - loss: 0.5426 - acc: 0.7043 - val_loss: 0.4209 - val_acc: 0.7652\n",
      "Epoch 28/40\n",
      "1312/1312 [==============================] - 1s 646us/step - loss: 0.5456 - acc: 0.7127 - val_loss: 0.2418 - val_acc: 0.8811\n",
      "Epoch 29/40\n",
      "1312/1312 [==============================] - 1s 568us/step - loss: 0.5508 - acc: 0.7081 - val_loss: 0.3084 - val_acc: 0.8415\n",
      "Epoch 30/40\n",
      "1312/1312 [==============================] - 1s 527us/step - loss: 0.5445 - acc: 0.7111 - val_loss: 0.2859 - val_acc: 0.8476\n",
      "Epoch 31/40\n",
      "1312/1312 [==============================] - 1s 572us/step - loss: 0.5429 - acc: 0.7149 - val_loss: 0.3223 - val_acc: 0.8232\n",
      "Epoch 32/40\n",
      "1312/1312 [==============================] - 1s 568us/step - loss: 0.5405 - acc: 0.7134 - val_loss: 0.4203 - val_acc: 0.7652\n",
      "Epoch 33/40\n",
      "1312/1312 [==============================] - 1s 559us/step - loss: 0.5444 - acc: 0.7096 - val_loss: 0.2449 - val_acc: 0.8780\n",
      "Epoch 34/40\n",
      "1312/1312 [==============================] - 1s 556us/step - loss: 0.5393 - acc: 0.7081 - val_loss: 0.3441 - val_acc: 0.8079\n",
      "Epoch 35/40\n",
      "1312/1312 [==============================] - 1s 509us/step - loss: 0.5396 - acc: 0.7226 - val_loss: 0.2839 - val_acc: 0.8567\n",
      "Epoch 36/40\n",
      "1312/1312 [==============================] - 1s 490us/step - loss: 0.5380 - acc: 0.7081 - val_loss: 0.3049 - val_acc: 0.8293\n",
      "Epoch 37/40\n",
      "1312/1312 [==============================] - 1s 460us/step - loss: 0.5379 - acc: 0.7188 - val_loss: 0.2673 - val_acc: 0.8567\n",
      "Epoch 38/40\n",
      "1312/1312 [==============================] - 1s 473us/step - loss: 0.5353 - acc: 0.7165 - val_loss: 0.2612 - val_acc: 0.8567\n",
      "Epoch 39/40\n",
      "1312/1312 [==============================] - 1s 458us/step - loss: 0.5413 - acc: 0.7210 - val_loss: 0.2690 - val_acc: 0.8598\n",
      "Epoch 40/40\n",
      "1312/1312 [==============================] - 1s 475us/step - loss: 0.5320 - acc: 0.7088 - val_loss: 0.3284 - val_acc: 0.7988\n",
      "183/183 [==============================] - 0s 18us/step\n",
      "Average accuracy of model on the dev set =  0.4389799637872665\n",
      "Training on fold 4/10.............................................\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_26 (Dense)             (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 5,425\n",
      "Trainable params: 5,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1312 samples, validate on 328 samples\n",
      "Epoch 1/40\n",
      "1312/1312 [==============================] - 1s 1ms/step - loss: 0.7127 - acc: 0.4748 - val_loss: 0.4994 - val_acc: 0.9817\n",
      "Epoch 2/40\n",
      "1312/1312 [==============================] - 1s 506us/step - loss: 0.6683 - acc: 0.5953 - val_loss: 0.5508 - val_acc: 0.9207\n",
      "Epoch 3/40\n",
      "1312/1312 [==============================] - 1s 507us/step - loss: 0.6637 - acc: 0.6052 - val_loss: 0.4675 - val_acc: 0.9604\n",
      "Epoch 4/40\n",
      "1312/1312 [==============================] - 1s 519us/step - loss: 0.6604 - acc: 0.5998 - val_loss: 0.4542 - val_acc: 0.9573\n",
      "Epoch 5/40\n",
      "1312/1312 [==============================] - 1s 478us/step - loss: 0.6584 - acc: 0.6006 - val_loss: 0.4594 - val_acc: 0.9543\n",
      "Epoch 6/40\n",
      "1312/1312 [==============================] - 1s 504us/step - loss: 0.6586 - acc: 0.6037 - val_loss: 0.4504 - val_acc: 0.9604\n",
      "Epoch 7/40\n",
      "1312/1312 [==============================] - 1s 461us/step - loss: 0.6564 - acc: 0.6098 - val_loss: 0.4696 - val_acc: 0.9573\n",
      "Epoch 8/40\n",
      "1312/1312 [==============================] - 1s 470us/step - loss: 0.6555 - acc: 0.6136 - val_loss: 0.4581 - val_acc: 0.9512\n",
      "Epoch 9/40\n",
      "1312/1312 [==============================] - 1s 476us/step - loss: 0.6553 - acc: 0.6029 - val_loss: 0.4244 - val_acc: 0.9634\n",
      "Epoch 10/40\n",
      "1312/1312 [==============================] - 1s 469us/step - loss: 0.6547 - acc: 0.6189 - val_loss: 0.4204 - val_acc: 0.9543\n",
      "Epoch 11/40\n",
      "1312/1312 [==============================] - 1s 467us/step - loss: 0.6532 - acc: 0.6174 - val_loss: 0.4336 - val_acc: 0.9634\n",
      "Epoch 12/40\n",
      "1312/1312 [==============================] - 1s 480us/step - loss: 0.6530 - acc: 0.6105 - val_loss: 0.4536 - val_acc: 0.9451\n",
      "Epoch 13/40\n",
      "1312/1312 [==============================] - 1s 476us/step - loss: 0.6518 - acc: 0.6189 - val_loss: 0.4810 - val_acc: 0.9024\n",
      "Epoch 14/40\n",
      "1312/1312 [==============================] - 1s 498us/step - loss: 0.6500 - acc: 0.6189 - val_loss: 0.3927 - val_acc: 0.9634\n",
      "Epoch 15/40\n",
      "1312/1312 [==============================] - 1s 507us/step - loss: 0.6499 - acc: 0.6143 - val_loss: 0.4992 - val_acc: 0.9024\n",
      "Epoch 16/40\n",
      "1312/1312 [==============================] - 1s 501us/step - loss: 0.6484 - acc: 0.6189 - val_loss: 0.4358 - val_acc: 0.9573\n",
      "Epoch 17/40\n",
      "1312/1312 [==============================] - 1s 469us/step - loss: 0.6473 - acc: 0.6204 - val_loss: 0.4535 - val_acc: 0.9085\n",
      "Epoch 18/40\n",
      "1312/1312 [==============================] - 1s 473us/step - loss: 0.6452 - acc: 0.6334 - val_loss: 0.4316 - val_acc: 0.9604\n",
      "Epoch 19/40\n",
      "1312/1312 [==============================] - 1s 503us/step - loss: 0.6443 - acc: 0.6265 - val_loss: 0.4398 - val_acc: 0.9085\n",
      "Epoch 20/40\n",
      "1312/1312 [==============================] - 1s 554us/step - loss: 0.6386 - acc: 0.6227 - val_loss: 0.4959 - val_acc: 0.9360\n",
      "Epoch 21/40\n",
      "1312/1312 [==============================] - 1s 466us/step - loss: 0.6385 - acc: 0.6349 - val_loss: 0.4613 - val_acc: 0.9055\n",
      "Epoch 22/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1312/1312 [==============================] - 1s 484us/step - loss: 0.6370 - acc: 0.6326 - val_loss: 0.4911 - val_acc: 0.9085\n",
      "Epoch 23/40\n",
      "1312/1312 [==============================] - 1s 480us/step - loss: 0.6325 - acc: 0.6303 - val_loss: 0.5865 - val_acc: 0.8720\n",
      "Epoch 24/40\n",
      "1312/1312 [==============================] - 1s 463us/step - loss: 0.6310 - acc: 0.6258 - val_loss: 0.4284 - val_acc: 0.9421\n",
      "Epoch 25/40\n",
      "1312/1312 [==============================] - 1s 462us/step - loss: 0.6265 - acc: 0.6418 - val_loss: 0.5109 - val_acc: 0.8933\n",
      "Epoch 26/40\n",
      "1312/1312 [==============================] - 1s 455us/step - loss: 0.6237 - acc: 0.6311 - val_loss: 0.3867 - val_acc: 0.9573\n",
      "Epoch 27/40\n",
      "1312/1312 [==============================] - 1s 507us/step - loss: 0.6225 - acc: 0.6311 - val_loss: 0.4323 - val_acc: 0.9482\n",
      "Epoch 28/40\n",
      "1312/1312 [==============================] - 1s 544us/step - loss: 0.6179 - acc: 0.6334 - val_loss: 0.4112 - val_acc: 0.9482\n",
      "Epoch 29/40\n",
      "1312/1312 [==============================] - 1s 474us/step - loss: 0.6152 - acc: 0.6364 - val_loss: 0.4232 - val_acc: 0.9116\n",
      "Epoch 30/40\n",
      "1312/1312 [==============================] - 1s 730us/step - loss: 0.6103 - acc: 0.6593 - val_loss: 0.4392 - val_acc: 0.8963\n",
      "Epoch 31/40\n",
      "1312/1312 [==============================] - 1s 660us/step - loss: 0.6064 - acc: 0.6684 - val_loss: 0.3026 - val_acc: 0.9665\n",
      "Epoch 32/40\n",
      "1312/1312 [==============================] - 1s 473us/step - loss: 0.6051 - acc: 0.6509 - val_loss: 0.3918 - val_acc: 0.9024\n",
      "Epoch 33/40\n",
      "1312/1312 [==============================] - 1s 459us/step - loss: 0.6055 - acc: 0.6616 - val_loss: 0.4164 - val_acc: 0.8933\n",
      "Epoch 34/40\n",
      "1312/1312 [==============================] - 1s 466us/step - loss: 0.6039 - acc: 0.6593 - val_loss: 0.4180 - val_acc: 0.8994\n",
      "Epoch 35/40\n",
      "1312/1312 [==============================] - 1s 461us/step - loss: 0.6010 - acc: 0.6623 - val_loss: 0.2840 - val_acc: 0.9665\n",
      "Epoch 36/40\n",
      "1312/1312 [==============================] - 1s 445us/step - loss: 0.6021 - acc: 0.6646 - val_loss: 0.3376 - val_acc: 0.9146\n",
      "Epoch 37/40\n",
      "1312/1312 [==============================] - 1s 449us/step - loss: 0.5955 - acc: 0.6738 - val_loss: 0.3838 - val_acc: 0.9177\n",
      "Epoch 38/40\n",
      "1312/1312 [==============================] - 1s 457us/step - loss: 0.5970 - acc: 0.6639 - val_loss: 0.4084 - val_acc: 0.8659\n",
      "Epoch 39/40\n",
      "1312/1312 [==============================] - 1s 463us/step - loss: 0.5937 - acc: 0.6730 - val_loss: 0.3216 - val_acc: 0.9268\n",
      "Epoch 40/40\n",
      "1312/1312 [==============================] - 1s 598us/step - loss: 0.5922 - acc: 0.6700 - val_loss: 0.3088 - val_acc: 0.9207\n",
      "183/183 [==============================] - 0s 43us/step\n",
      "Average accuracy of model on the dev set =  0.5286885254044351\n",
      "Training on fold 5/10.............................................\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_32 (Dense)             (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 5,425\n",
      "Trainable params: 5,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1312 samples, validate on 328 samples\n",
      "Epoch 1/40\n",
      "1312/1312 [==============================] - 1s 1ms/step - loss: 0.6843 - acc: 0.5877 - val_loss: 0.5249 - val_acc: 0.9848\n",
      "Epoch 2/40\n",
      "1312/1312 [==============================] - 1s 507us/step - loss: 0.6655 - acc: 0.6029 - val_loss: 0.4592 - val_acc: 0.9878\n",
      "Epoch 3/40\n",
      "1312/1312 [==============================] - 1s 500us/step - loss: 0.6587 - acc: 0.5983 - val_loss: 0.4710 - val_acc: 0.9604\n",
      "Epoch 4/40\n",
      "1312/1312 [==============================] - 1s 465us/step - loss: 0.6530 - acc: 0.6143 - val_loss: 0.4267 - val_acc: 0.9634\n",
      "Epoch 5/40\n",
      "1312/1312 [==============================] - 1s 494us/step - loss: 0.6503 - acc: 0.6181 - val_loss: 0.4224 - val_acc: 0.9634\n",
      "Epoch 6/40\n",
      "1312/1312 [==============================] - 1s 507us/step - loss: 0.6478 - acc: 0.6220 - val_loss: 0.4149 - val_acc: 0.9604\n",
      "Epoch 7/40\n",
      "1312/1312 [==============================] - 1s 484us/step - loss: 0.6446 - acc: 0.6212 - val_loss: 0.3869 - val_acc: 0.9848\n",
      "Epoch 8/40\n",
      "1312/1312 [==============================] - 1s 512us/step - loss: 0.6440 - acc: 0.6189 - val_loss: 0.4455 - val_acc: 0.9543\n",
      "Epoch 9/40\n",
      "1312/1312 [==============================] - 1s 515us/step - loss: 0.6412 - acc: 0.6197 - val_loss: 0.4277 - val_acc: 0.9573\n",
      "Epoch 10/40\n",
      "1312/1312 [==============================] - 1s 523us/step - loss: 0.6380 - acc: 0.6143 - val_loss: 0.4507 - val_acc: 0.8872\n",
      "Epoch 11/40\n",
      "1312/1312 [==============================] - 1s 516us/step - loss: 0.6353 - acc: 0.6113 - val_loss: 0.4113 - val_acc: 0.9756\n",
      "Epoch 12/40\n",
      "1312/1312 [==============================] - 1s 528us/step - loss: 0.6320 - acc: 0.6242 - val_loss: 0.3766 - val_acc: 0.9817\n",
      "Epoch 13/40\n",
      "1312/1312 [==============================] - 1s 528us/step - loss: 0.6260 - acc: 0.6341 - val_loss: 0.4631 - val_acc: 0.7744\n",
      "Epoch 14/40\n",
      "1312/1312 [==============================] - 1s 482us/step - loss: 0.6246 - acc: 0.6319 - val_loss: 0.4636 - val_acc: 0.7957\n",
      "Epoch 15/40\n",
      "1312/1312 [==============================] - 1s 522us/step - loss: 0.6218 - acc: 0.6471 - val_loss: 0.3618 - val_acc: 0.9543\n",
      "Epoch 16/40\n",
      "1312/1312 [==============================] - 1s 501us/step - loss: 0.6167 - acc: 0.6563 - val_loss: 0.3430 - val_acc: 0.9482\n",
      "Epoch 17/40\n",
      "1312/1312 [==============================] - 1s 463us/step - loss: 0.6148 - acc: 0.6479 - val_loss: 0.4317 - val_acc: 0.8841\n",
      "Epoch 18/40\n",
      "1312/1312 [==============================] - 1s 473us/step - loss: 0.6109 - acc: 0.6555 - val_loss: 0.3800 - val_acc: 0.9024\n",
      "Epoch 19/40\n",
      "1312/1312 [==============================] - 1s 478us/step - loss: 0.6082 - acc: 0.6570 - val_loss: 0.3336 - val_acc: 0.9482\n",
      "Epoch 20/40\n",
      "1312/1312 [==============================] - 1s 477us/step - loss: 0.6075 - acc: 0.6623 - val_loss: 0.3410 - val_acc: 0.9360\n",
      "Epoch 21/40\n",
      "1312/1312 [==============================] - 1s 490us/step - loss: 0.6043 - acc: 0.6616 - val_loss: 0.3144 - val_acc: 0.9360\n",
      "Epoch 22/40\n",
      "1312/1312 [==============================] - 1s 491us/step - loss: 0.6004 - acc: 0.6646 - val_loss: 0.4810 - val_acc: 0.7561\n",
      "Epoch 23/40\n",
      "1312/1312 [==============================] - 1s 545us/step - loss: 0.6016 - acc: 0.6669 - val_loss: 0.3640 - val_acc: 0.8841\n",
      "Epoch 24/40\n",
      "1312/1312 [==============================] - 1s 762us/step - loss: 0.6013 - acc: 0.6601 - val_loss: 0.3558 - val_acc: 0.9085\n",
      "Epoch 25/40\n",
      "1312/1312 [==============================] - 1s 677us/step - loss: 0.5972 - acc: 0.6646 - val_loss: 0.3029 - val_acc: 0.9268\n",
      "Epoch 26/40\n",
      "1312/1312 [==============================] - 1s 644us/step - loss: 0.5953 - acc: 0.6669 - val_loss: 0.4125 - val_acc: 0.8506\n",
      "Epoch 27/40\n",
      "1312/1312 [==============================] - 1s 589us/step - loss: 0.5939 - acc: 0.6738 - val_loss: 0.3641 - val_acc: 0.8994\n",
      "Epoch 28/40\n",
      "1312/1312 [==============================] - 1s 590us/step - loss: 0.5940 - acc: 0.6784 - val_loss: 0.3201 - val_acc: 0.9146\n",
      "Epoch 29/40\n",
      "1312/1312 [==============================] - 1s 596us/step - loss: 0.5918 - acc: 0.6646 - val_loss: 0.3184 - val_acc: 0.9207\n",
      "Epoch 30/40\n",
      "1312/1312 [==============================] - 1s 634us/step - loss: 0.5917 - acc: 0.6593 - val_loss: 0.3627 - val_acc: 0.8689\n",
      "Epoch 31/40\n",
      "1312/1312 [==============================] - 1s 598us/step - loss: 0.5902 - acc: 0.6776 - val_loss: 0.2794 - val_acc: 0.9299\n",
      "Epoch 32/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1312/1312 [==============================] - 1s 615us/step - loss: 0.5899 - acc: 0.6654 - val_loss: 0.3745 - val_acc: 0.8689\n",
      "Epoch 33/40\n",
      "1312/1312 [==============================] - 1s 566us/step - loss: 0.5847 - acc: 0.6776 - val_loss: 0.2465 - val_acc: 0.9390\n",
      "Epoch 34/40\n",
      "1312/1312 [==============================] - 1s 660us/step - loss: 0.5863 - acc: 0.6753 - val_loss: 0.3730 - val_acc: 0.8537\n",
      "Epoch 35/40\n",
      "1312/1312 [==============================] - 1s 829us/step - loss: 0.5847 - acc: 0.6692 - val_loss: 0.3849 - val_acc: 0.8445\n",
      "Epoch 36/40\n",
      "1312/1312 [==============================] - 1s 726us/step - loss: 0.5836 - acc: 0.6745 - val_loss: 0.2761 - val_acc: 0.9055\n",
      "Epoch 37/40\n",
      "1312/1312 [==============================] - 1s 601us/step - loss: 0.5802 - acc: 0.6806 - val_loss: 0.4446 - val_acc: 0.8110\n",
      "Epoch 38/40\n",
      "1312/1312 [==============================] - 1s 599us/step - loss: 0.5824 - acc: 0.6715 - val_loss: 0.3650 - val_acc: 0.8598\n",
      "Epoch 39/40\n",
      "1312/1312 [==============================] - 1s 571us/step - loss: 0.5808 - acc: 0.6730 - val_loss: 0.3367 - val_acc: 0.8720\n",
      "Epoch 40/40\n",
      "1312/1312 [==============================] - 1s 590us/step - loss: 0.5784 - acc: 0.6791 - val_loss: 0.3359 - val_acc: 0.8780\n",
      "183/183 [==============================] - 0s 26us/step\n",
      "Average accuracy of model on the dev set =  0.5759562848695641\n",
      "Training on fold 6/10.............................................\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_38 (Dense)             (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 5,425\n",
      "Trainable params: 5,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1312 samples, validate on 329 samples\n",
      "Epoch 1/40\n",
      "1312/1312 [==============================] - 2s 1ms/step - loss: 0.6765 - acc: 0.5854 - val_loss: 0.5139 - val_acc: 1.0000\n",
      "Epoch 2/40\n",
      "1312/1312 [==============================] - 1s 636us/step - loss: 0.6640 - acc: 0.6067 - val_loss: 0.5359 - val_acc: 0.9119\n",
      "Epoch 3/40\n",
      "1312/1312 [==============================] - 1s 652us/step - loss: 0.6569 - acc: 0.6067 - val_loss: 0.4612 - val_acc: 0.9666\n",
      "Epoch 4/40\n",
      "1312/1312 [==============================] - 1s 840us/step - loss: 0.6519 - acc: 0.6037 - val_loss: 0.4918 - val_acc: 0.9027\n",
      "Epoch 5/40\n",
      "1312/1312 [==============================] - 1s 573us/step - loss: 0.6478 - acc: 0.6082 - val_loss: 0.4449 - val_acc: 0.9453\n",
      "Epoch 6/40\n",
      "1312/1312 [==============================] - 1s 494us/step - loss: 0.6468 - acc: 0.6098 - val_loss: 0.4503 - val_acc: 0.9210\n",
      "Epoch 7/40\n",
      "1312/1312 [==============================] - 1s 500us/step - loss: 0.6444 - acc: 0.6090 - val_loss: 0.4625 - val_acc: 0.9119\n",
      "Epoch 8/40\n",
      "1312/1312 [==============================] - 1s 485us/step - loss: 0.6429 - acc: 0.6197 - val_loss: 0.4530 - val_acc: 0.9210\n",
      "Epoch 9/40\n",
      "1312/1312 [==============================] - 1s 474us/step - loss: 0.6421 - acc: 0.6189 - val_loss: 0.4660 - val_acc: 0.9149\n",
      "Epoch 10/40\n",
      "1312/1312 [==============================] - 1s 471us/step - loss: 0.6392 - acc: 0.6197 - val_loss: 0.4352 - val_acc: 0.9392\n",
      "Epoch 11/40\n",
      "1312/1312 [==============================] - 1s 510us/step - loss: 0.6384 - acc: 0.6288 - val_loss: 0.3851 - val_acc: 0.9605\n",
      "Epoch 12/40\n",
      "1312/1312 [==============================] - 1s 490us/step - loss: 0.6358 - acc: 0.6212 - val_loss: 0.4595 - val_acc: 0.9088\n",
      "Epoch 13/40\n",
      "1312/1312 [==============================] - 1s 492us/step - loss: 0.6341 - acc: 0.6250 - val_loss: 0.3970 - val_acc: 0.9514\n",
      "Epoch 14/40\n",
      "1312/1312 [==============================] - 1s 488us/step - loss: 0.6301 - acc: 0.6387 - val_loss: 0.4359 - val_acc: 0.9422\n",
      "Epoch 15/40\n",
      "1312/1312 [==============================] - 1s 485us/step - loss: 0.6267 - acc: 0.6280 - val_loss: 0.4143 - val_acc: 0.9119\n",
      "Epoch 16/40\n",
      "1312/1312 [==============================] - 1s 511us/step - loss: 0.6201 - acc: 0.6380 - val_loss: 0.3980 - val_acc: 0.9119\n",
      "Epoch 17/40\n",
      "1312/1312 [==============================] - 1s 495us/step - loss: 0.6184 - acc: 0.6402 - val_loss: 0.4181 - val_acc: 0.8845\n",
      "Epoch 18/40\n",
      "1312/1312 [==============================] - 1s 488us/step - loss: 0.6122 - acc: 0.6532 - val_loss: 0.3069 - val_acc: 0.9574\n",
      "Epoch 19/40\n",
      "1312/1312 [==============================] - 1s 492us/step - loss: 0.6087 - acc: 0.6608 - val_loss: 0.3504 - val_acc: 0.9453\n",
      "Epoch 20/40\n",
      "1312/1312 [==============================] - 1s 653us/step - loss: 0.6035 - acc: 0.6669 - val_loss: 0.3185 - val_acc: 0.9392\n",
      "Epoch 21/40\n",
      "1312/1312 [==============================] - 1s 835us/step - loss: 0.5998 - acc: 0.6524 - val_loss: 0.3232 - val_acc: 0.9271\n",
      "Epoch 22/40\n",
      "1312/1312 [==============================] - 1s 584us/step - loss: 0.5978 - acc: 0.6623 - val_loss: 0.3163 - val_acc: 0.9240\n",
      "Epoch 23/40\n",
      "1312/1312 [==============================] - 1s 487us/step - loss: 0.5972 - acc: 0.6631 - val_loss: 0.3339 - val_acc: 0.9179\n",
      "Epoch 24/40\n",
      "1312/1312 [==============================] - 1s 519us/step - loss: 0.5945 - acc: 0.6784 - val_loss: 0.3419 - val_acc: 0.9119\n",
      "Epoch 25/40\n",
      "1312/1312 [==============================] - 1s 496us/step - loss: 0.5917 - acc: 0.6684 - val_loss: 0.2473 - val_acc: 0.9635\n",
      "Epoch 26/40\n",
      "1312/1312 [==============================] - 1s 489us/step - loss: 0.5900 - acc: 0.6723 - val_loss: 0.3022 - val_acc: 0.9149\n",
      "Epoch 27/40\n",
      "1312/1312 [==============================] - 1s 478us/step - loss: 0.5899 - acc: 0.6707 - val_loss: 0.3183 - val_acc: 0.9149\n",
      "Epoch 28/40\n",
      "1312/1312 [==============================] - 1s 497us/step - loss: 0.5888 - acc: 0.6730 - val_loss: 0.2867 - val_acc: 0.9210\n",
      "Epoch 29/40\n",
      "1312/1312 [==============================] - 1s 490us/step - loss: 0.5852 - acc: 0.6768 - val_loss: 0.3127 - val_acc: 0.9088\n",
      "Epoch 30/40\n",
      "1312/1312 [==============================] - 1s 490us/step - loss: 0.5878 - acc: 0.6822 - val_loss: 0.2756 - val_acc: 0.9210\n",
      "Epoch 31/40\n",
      "1312/1312 [==============================] - 1s 475us/step - loss: 0.5852 - acc: 0.6662 - val_loss: 0.3602 - val_acc: 0.8723\n",
      "Epoch 32/40\n",
      "1312/1312 [==============================] - 1s 493us/step - loss: 0.5859 - acc: 0.6723 - val_loss: 0.3110 - val_acc: 0.9119\n",
      "Epoch 33/40\n",
      "1312/1312 [==============================] - 1s 488us/step - loss: 0.5857 - acc: 0.6730 - val_loss: 0.3501 - val_acc: 0.8845\n",
      "Epoch 34/40\n",
      "1312/1312 [==============================] - 1s 495us/step - loss: 0.5819 - acc: 0.6806 - val_loss: 0.3783 - val_acc: 0.8754\n",
      "Epoch 35/40\n",
      "1312/1312 [==============================] - 1s 524us/step - loss: 0.5815 - acc: 0.6845 - val_loss: 0.3608 - val_acc: 0.8632\n",
      "Epoch 36/40\n",
      "1312/1312 [==============================] - 1s 485us/step - loss: 0.5800 - acc: 0.6822 - val_loss: 0.3243 - val_acc: 0.9058\n",
      "Epoch 37/40\n",
      "1312/1312 [==============================] - 1s 493us/step - loss: 0.5802 - acc: 0.6730 - val_loss: 0.3147 - val_acc: 0.8906\n",
      "Epoch 38/40\n",
      "1312/1312 [==============================] - 1s 485us/step - loss: 0.5809 - acc: 0.6867 - val_loss: 0.3034 - val_acc: 0.9058\n",
      "Epoch 39/40\n",
      "1312/1312 [==============================] - 1s 519us/step - loss: 0.5755 - acc: 0.6837 - val_loss: 0.2003 - val_acc: 0.9574\n",
      "Epoch 40/40\n",
      "1312/1312 [==============================] - 1s 800us/step - loss: 0.5836 - acc: 0.6768 - val_loss: 0.2842 - val_acc: 0.9058\n",
      "182/182 [==============================] - 0s 45us/step\n",
      "Average accuracy of model on the dev set =  0.6109159513495196\n",
      "Training on fold 7/10.............................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_44 (Dense)             (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 5,425\n",
      "Trainable params: 5,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1312 samples, validate on 329 samples\n",
      "Epoch 1/40\n",
      "1312/1312 [==============================] - 1s 1ms/step - loss: 0.6881 - acc: 0.5236 - val_loss: 0.4898 - val_acc: 0.9939\n",
      "Epoch 2/40\n",
      "1312/1312 [==============================] - 1s 519us/step - loss: 0.6643 - acc: 0.5960 - val_loss: 0.4940 - val_acc: 0.9666\n",
      "Epoch 3/40\n",
      "1312/1312 [==============================] - 1s 499us/step - loss: 0.6597 - acc: 0.5945 - val_loss: 0.4834 - val_acc: 0.9635\n",
      "Epoch 4/40\n",
      "1312/1312 [==============================] - 1s 521us/step - loss: 0.6579 - acc: 0.5922 - val_loss: 0.4586 - val_acc: 0.9635\n",
      "Epoch 5/40\n",
      "1312/1312 [==============================] - 1s 498us/step - loss: 0.6552 - acc: 0.5998 - val_loss: 0.4354 - val_acc: 0.9635\n",
      "Epoch 6/40\n",
      "1312/1312 [==============================] - 1s 491us/step - loss: 0.6543 - acc: 0.6098 - val_loss: 0.4364 - val_acc: 0.9635\n",
      "Epoch 7/40\n",
      "1312/1312 [==============================] - 1s 491us/step - loss: 0.6518 - acc: 0.6067 - val_loss: 0.5004 - val_acc: 0.9179\n",
      "Epoch 8/40\n",
      "1312/1312 [==============================] - 1s 533us/step - loss: 0.6514 - acc: 0.6105 - val_loss: 0.4592 - val_acc: 0.9544\n",
      "Epoch 9/40\n",
      "1312/1312 [==============================] - 1s 507us/step - loss: 0.6509 - acc: 0.6151 - val_loss: 0.4386 - val_acc: 0.9605\n",
      "Epoch 10/40\n",
      "1312/1312 [==============================] - 1s 488us/step - loss: 0.6504 - acc: 0.6128 - val_loss: 0.4563 - val_acc: 0.9666\n",
      "Epoch 11/40\n",
      "1312/1312 [==============================] - 1s 491us/step - loss: 0.6483 - acc: 0.6105 - val_loss: 0.4486 - val_acc: 0.9574\n",
      "Epoch 12/40\n",
      "1312/1312 [==============================] - 1s 493us/step - loss: 0.6464 - acc: 0.6151 - val_loss: 0.4638 - val_acc: 0.9210\n",
      "Epoch 13/40\n",
      "1312/1312 [==============================] - 1s 540us/step - loss: 0.6442 - acc: 0.6212 - val_loss: 0.4417 - val_acc: 0.9210\n",
      "Epoch 14/40\n",
      "1312/1312 [==============================] - 1s 529us/step - loss: 0.6423 - acc: 0.6242 - val_loss: 0.4198 - val_acc: 0.9605\n",
      "Epoch 15/40\n",
      "1312/1312 [==============================] - 1s 506us/step - loss: 0.6409 - acc: 0.6098 - val_loss: 0.4573 - val_acc: 0.9514\n",
      "Epoch 16/40\n",
      "1312/1312 [==============================] - 1s 493us/step - loss: 0.6357 - acc: 0.6242 - val_loss: 0.4339 - val_acc: 0.9179\n",
      "Epoch 17/40\n",
      "1312/1312 [==============================] - 1s 513us/step - loss: 0.6332 - acc: 0.6273 - val_loss: 0.4209 - val_acc: 0.9574\n",
      "Epoch 18/40\n",
      "1312/1312 [==============================] - 1s 553us/step - loss: 0.6288 - acc: 0.6242 - val_loss: 0.4690 - val_acc: 0.8967\n",
      "Epoch 19/40\n",
      "1312/1312 [==============================] - 1s 811us/step - loss: 0.6267 - acc: 0.6341 - val_loss: 0.3887 - val_acc: 0.9392\n",
      "Epoch 20/40\n",
      "1312/1312 [==============================] - 1s 681us/step - loss: 0.6216 - acc: 0.6486 - val_loss: 0.4729 - val_acc: 0.9149\n",
      "Epoch 21/40\n",
      "1312/1312 [==============================] - 1s 709us/step - loss: 0.6187 - acc: 0.6509 - val_loss: 0.3844 - val_acc: 0.9453\n",
      "Epoch 22/40\n",
      "1312/1312 [==============================] - 1s 668us/step - loss: 0.6163 - acc: 0.6517 - val_loss: 0.3738 - val_acc: 0.9453\n",
      "Epoch 23/40\n",
      "1312/1312 [==============================] - 1s 777us/step - loss: 0.6132 - acc: 0.6585 - val_loss: 0.3848 - val_acc: 0.9271\n",
      "Epoch 24/40\n",
      "1312/1312 [==============================] - ETA: 0s - loss: 0.6079 - acc: 0.666 - 1s 780us/step - loss: 0.6084 - acc: 0.6669 - val_loss: 0.4712 - val_acc: 0.8571\n",
      "Epoch 25/40\n",
      "1312/1312 [==============================] - 1s 667us/step - loss: 0.6038 - acc: 0.6578 - val_loss: 0.3006 - val_acc: 0.9514\n",
      "Epoch 26/40\n",
      "1312/1312 [==============================] - 1s 743us/step - loss: 0.6075 - acc: 0.6585 - val_loss: 0.3111 - val_acc: 0.9392\n",
      "Epoch 27/40\n",
      "1312/1312 [==============================] - 1s 736us/step - loss: 0.6046 - acc: 0.6601 - val_loss: 0.3369 - val_acc: 0.9271\n",
      "Epoch 28/40\n",
      "1312/1312 [==============================] - 1s 655us/step - loss: 0.6009 - acc: 0.6677 - val_loss: 0.4505 - val_acc: 0.8663\n",
      "Epoch 29/40\n",
      "1312/1312 [==============================] - 1s 654us/step - loss: 0.5999 - acc: 0.6555 - val_loss: 0.3677 - val_acc: 0.8997\n",
      "Epoch 30/40\n",
      "1312/1312 [==============================] - 1s 642us/step - loss: 0.5972 - acc: 0.6639 - val_loss: 0.3210 - val_acc: 0.9240\n",
      "Epoch 31/40\n",
      "1312/1312 [==============================] - 1s 695us/step - loss: 0.5960 - acc: 0.6723 - val_loss: 0.2896 - val_acc: 0.9331\n",
      "Epoch 32/40\n",
      "1312/1312 [==============================] - 1s 601us/step - loss: 0.5994 - acc: 0.6623 - val_loss: 0.3523 - val_acc: 0.8815\n",
      "Epoch 33/40\n",
      "1312/1312 [==============================] - 1s 594us/step - loss: 0.5931 - acc: 0.6639 - val_loss: 0.3287 - val_acc: 0.9119\n",
      "Epoch 34/40\n",
      "1312/1312 [==============================] - 1s 589us/step - loss: 0.5940 - acc: 0.6631 - val_loss: 0.2805 - val_acc: 0.9301\n",
      "Epoch 35/40\n",
      "1312/1312 [==============================] - 1s 580us/step - loss: 0.5920 - acc: 0.6799 - val_loss: 0.4022 - val_acc: 0.8541\n",
      "Epoch 36/40\n",
      "1312/1312 [==============================] - 1s 651us/step - loss: 0.5911 - acc: 0.6723 - val_loss: 0.3541 - val_acc: 0.8784\n",
      "Epoch 37/40\n",
      "1312/1312 [==============================] - 1s 648us/step - loss: 0.5922 - acc: 0.6684 - val_loss: 0.3426 - val_acc: 0.8967\n",
      "Epoch 38/40\n",
      "1312/1312 [==============================] - 1s 603us/step - loss: 0.5875 - acc: 0.6753 - val_loss: 0.3473 - val_acc: 0.8906\n",
      "Epoch 39/40\n",
      "1312/1312 [==============================] - 1s 590us/step - loss: 0.5875 - acc: 0.6715 - val_loss: 0.3840 - val_acc: 0.8541\n",
      "Epoch 40/40\n",
      "1312/1312 [==============================] - 1s 576us/step - loss: 0.5883 - acc: 0.6692 - val_loss: 0.4111 - val_acc: 0.8602\n",
      "182/182 [==============================] - 0s 23us/step\n",
      "Average accuracy of model on the dev set =  0.639811788941989\n",
      "Training on fold 8/10.............................................\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_50 (Dense)             (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 5,425\n",
      "Trainable params: 5,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1312 samples, validate on 329 samples\n",
      "Epoch 1/40\n",
      "1312/1312 [==============================] - 2s 1ms/step - loss: 0.6841 - acc: 0.5511 - val_loss: 0.5237 - val_acc: 0.9878\n",
      "Epoch 2/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1312/1312 [==============================] - 1s 637us/step - loss: 0.6672 - acc: 0.5907 - val_loss: 0.4880 - val_acc: 0.9574\n",
      "Epoch 3/40\n",
      "1312/1312 [==============================] - 1s 642us/step - loss: 0.6615 - acc: 0.6075 - val_loss: 0.4767 - val_acc: 0.9544\n",
      "Epoch 4/40\n",
      "1312/1312 [==============================] - 1s 635us/step - loss: 0.6592 - acc: 0.6105 - val_loss: 0.4525 - val_acc: 0.9574\n",
      "Epoch 5/40\n",
      "1312/1312 [==============================] - 1s 682us/step - loss: 0.6566 - acc: 0.6082 - val_loss: 0.4729 - val_acc: 0.9514\n",
      "Epoch 6/40\n",
      "1312/1312 [==============================] - 1s 634us/step - loss: 0.6539 - acc: 0.6143 - val_loss: 0.4286 - val_acc: 0.9574\n",
      "Epoch 7/40\n",
      "1312/1312 [==============================] - 1s 680us/step - loss: 0.6526 - acc: 0.6166 - val_loss: 0.4382 - val_acc: 0.9574\n",
      "Epoch 8/40\n",
      "1312/1312 [==============================] - 1s 714us/step - loss: 0.6509 - acc: 0.6166 - val_loss: 0.4886 - val_acc: 0.9271\n",
      "Epoch 9/40\n",
      "1312/1312 [==============================] - 1s 649us/step - loss: 0.6499 - acc: 0.6120 - val_loss: 0.4728 - val_acc: 0.9149\n",
      "Epoch 10/40\n",
      "1312/1312 [==============================] - 1s 667us/step - loss: 0.6480 - acc: 0.6227 - val_loss: 0.5266 - val_acc: 0.9149\n",
      "Epoch 11/40\n",
      "1312/1312 [==============================] - 1s 737us/step - loss: 0.6473 - acc: 0.6220 - val_loss: 0.4639 - val_acc: 0.9514\n",
      "Epoch 12/40\n",
      "1312/1312 [==============================] - 1s 688us/step - loss: 0.6455 - acc: 0.6151 - val_loss: 0.4621 - val_acc: 0.9422\n",
      "Epoch 13/40\n",
      "1312/1312 [==============================] - 1s 611us/step - loss: 0.6433 - acc: 0.6250 - val_loss: 0.4946 - val_acc: 0.9422\n",
      "Epoch 14/40\n",
      "1312/1312 [==============================] - 1s 655us/step - loss: 0.6410 - acc: 0.6235 - val_loss: 0.4473 - val_acc: 0.9179\n",
      "Epoch 15/40\n",
      "1312/1312 [==============================] - 1s 676us/step - loss: 0.6397 - acc: 0.6326 - val_loss: 0.4625 - val_acc: 0.9210\n",
      "Epoch 16/40\n",
      "1312/1312 [==============================] - 1s 708us/step - loss: 0.6369 - acc: 0.6220 - val_loss: 0.4285 - val_acc: 0.9574\n",
      "Epoch 17/40\n",
      "1312/1312 [==============================] - 1s 700us/step - loss: 0.6332 - acc: 0.6364 - val_loss: 0.5001 - val_acc: 0.9392\n",
      "Epoch 18/40\n",
      "1312/1312 [==============================] - 1s 819us/step - loss: 0.6316 - acc: 0.6296 - val_loss: 0.4504 - val_acc: 0.9422\n",
      "Epoch 19/40\n",
      "1312/1312 [==============================] - 1s 883us/step - loss: 0.6268 - acc: 0.6296 - val_loss: 0.4955 - val_acc: 0.9453\n",
      "Epoch 20/40\n",
      "1312/1312 [==============================] - 1s 868us/step - loss: 0.6222 - acc: 0.6425 - val_loss: 0.3896 - val_acc: 0.9422\n",
      "Epoch 21/40\n",
      "1312/1312 [==============================] - 1s 708us/step - loss: 0.6199 - acc: 0.6387 - val_loss: 0.3847 - val_acc: 0.9331\n",
      "Epoch 22/40\n",
      "1312/1312 [==============================] - 1s 566us/step - loss: 0.6160 - acc: 0.6380 - val_loss: 0.3487 - val_acc: 0.9362\n",
      "Epoch 23/40\n",
      "1312/1312 [==============================] - 1s 522us/step - loss: 0.6117 - acc: 0.6532 - val_loss: 0.4014 - val_acc: 0.9362\n",
      "Epoch 24/40\n",
      "1312/1312 [==============================] - 1s 521us/step - loss: 0.6063 - acc: 0.6662 - val_loss: 0.3182 - val_acc: 0.9453\n",
      "Epoch 25/40\n",
      "1312/1312 [==============================] - 1s 693us/step - loss: 0.6069 - acc: 0.6616 - val_loss: 0.3888 - val_acc: 0.9240\n",
      "Epoch 26/40\n",
      "1312/1312 [==============================] - 1s 802us/step - loss: 0.6031 - acc: 0.6662 - val_loss: 0.3724 - val_acc: 0.9240\n",
      "Epoch 27/40\n",
      "1312/1312 [==============================] - 1s 515us/step - loss: 0.6034 - acc: 0.6616 - val_loss: 0.3496 - val_acc: 0.9271\n",
      "Epoch 28/40\n",
      "1312/1312 [==============================] - 1s 521us/step - loss: 0.6009 - acc: 0.6684 - val_loss: 0.3093 - val_acc: 0.9362\n",
      "Epoch 29/40\n",
      "1312/1312 [==============================] - 1s 528us/step - loss: 0.5994 - acc: 0.6669 - val_loss: 0.3275 - val_acc: 0.9271\n",
      "Epoch 30/40\n",
      "1312/1312 [==============================] - 1s 489us/step - loss: 0.5988 - acc: 0.6669 - val_loss: 0.3142 - val_acc: 0.9301\n",
      "Epoch 31/40\n",
      "1312/1312 [==============================] - 1s 488us/step - loss: 0.5961 - acc: 0.6578 - val_loss: 0.4090 - val_acc: 0.8845\n",
      "Epoch 32/40\n",
      "1312/1312 [==============================] - 1s 491us/step - loss: 0.5957 - acc: 0.6768 - val_loss: 0.3638 - val_acc: 0.8845\n",
      "Epoch 33/40\n",
      "1312/1312 [==============================] - 1s 489us/step - loss: 0.5945 - acc: 0.6707 - val_loss: 0.3531 - val_acc: 0.9058\n",
      "Epoch 34/40\n",
      "1312/1312 [==============================] - 1s 514us/step - loss: 0.5931 - acc: 0.6700 - val_loss: 0.3309 - val_acc: 0.9179\n",
      "Epoch 35/40\n",
      "1312/1312 [==============================] - 1s 500us/step - loss: 0.5937 - acc: 0.6738 - val_loss: 0.3133 - val_acc: 0.9149\n",
      "Epoch 36/40\n",
      "1312/1312 [==============================] - 1s 497us/step - loss: 0.5947 - acc: 0.6768 - val_loss: 0.3232 - val_acc: 0.9179\n",
      "Epoch 37/40\n",
      "1312/1312 [==============================] - 1s 492us/step - loss: 0.5895 - acc: 0.6799 - val_loss: 0.3425 - val_acc: 0.8936\n",
      "Epoch 38/40\n",
      "1312/1312 [==============================] - 1s 497us/step - loss: 0.5918 - acc: 0.6662 - val_loss: 0.3649 - val_acc: 0.8815\n",
      "Epoch 39/40\n",
      "1312/1312 [==============================] - 1s 513us/step - loss: 0.5892 - acc: 0.6753 - val_loss: 0.3060 - val_acc: 0.9119\n",
      "Epoch 40/40\n",
      "1312/1312 [==============================] - 1s 517us/step - loss: 0.5884 - acc: 0.6677 - val_loss: 0.3129 - val_acc: 0.9088\n",
      "182/182 [==============================] - 0s 23us/step\n",
      "Average accuracy of model on the dev set =  0.6546155355138328\n",
      "Training on fold 9/10.............................................\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_56 (Dense)             (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 5,425\n",
      "Trainable params: 5,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1313 samples, validate on 329 samples\n",
      "Epoch 1/40\n",
      "1313/1313 [==============================] - 1s 1ms/step - loss: 0.6863 - acc: 0.5248 - val_loss: 0.5280 - val_acc: 1.0000\n",
      "Epoch 2/40\n",
      "1313/1313 [==============================] - 1s 494us/step - loss: 0.6632 - acc: 0.5933 - val_loss: 0.4471 - val_acc: 0.9757\n",
      "Epoch 3/40\n",
      "1313/1313 [==============================] - 1s 498us/step - loss: 0.6547 - acc: 0.6047 - val_loss: 0.5072 - val_acc: 0.9210\n",
      "Epoch 4/40\n",
      "1313/1313 [==============================] - 1s 515us/step - loss: 0.6509 - acc: 0.6169 - val_loss: 0.5161 - val_acc: 0.8875\n",
      "Epoch 5/40\n",
      "1313/1313 [==============================] - 1s 608us/step - loss: 0.6494 - acc: 0.6177 - val_loss: 0.4570 - val_acc: 0.9210\n",
      "Epoch 6/40\n",
      "1313/1313 [==============================] - 1s 816us/step - loss: 0.6457 - acc: 0.6245 - val_loss: 0.4588 - val_acc: 0.9210\n",
      "Epoch 7/40\n",
      "1313/1313 [==============================] - 1s 565us/step - loss: 0.6437 - acc: 0.6192 - val_loss: 0.4799 - val_acc: 0.9119\n",
      "Epoch 8/40\n",
      "1313/1313 [==============================] - 1s 505us/step - loss: 0.6412 - acc: 0.6238 - val_loss: 0.4919 - val_acc: 0.9058\n",
      "Epoch 9/40\n",
      "1313/1313 [==============================] - 1s 500us/step - loss: 0.6368 - acc: 0.6222 - val_loss: 0.4615 - val_acc: 0.9210\n",
      "Epoch 10/40\n",
      "1313/1313 [==============================] - 1s 551us/step - loss: 0.6344 - acc: 0.6169 - val_loss: 0.4841 - val_acc: 0.8997\n",
      "Epoch 11/40\n",
      "1313/1313 [==============================] - 1s 508us/step - loss: 0.6297 - acc: 0.6413 - val_loss: 0.3957 - val_acc: 0.9453\n",
      "Epoch 12/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1313/1313 [==============================] - 1s 544us/step - loss: 0.6257 - acc: 0.6337 - val_loss: 0.3498 - val_acc: 0.9392\n",
      "Epoch 13/40\n",
      "1313/1313 [==============================] - 1s 519us/step - loss: 0.6190 - acc: 0.6428 - val_loss: 0.4588 - val_acc: 0.8237\n",
      "Epoch 14/40\n",
      "1313/1313 [==============================] - 1s 533us/step - loss: 0.6150 - acc: 0.6618 - val_loss: 0.3787 - val_acc: 0.9149\n",
      "Epoch 15/40\n",
      "1313/1313 [==============================] - 1s 500us/step - loss: 0.6136 - acc: 0.6420 - val_loss: 0.3502 - val_acc: 0.9210\n",
      "Epoch 16/40\n",
      "1313/1313 [==============================] - 1s 497us/step - loss: 0.6107 - acc: 0.6588 - val_loss: 0.3967 - val_acc: 0.8967\n",
      "Epoch 17/40\n",
      "1313/1313 [==============================] - 1s 494us/step - loss: 0.6075 - acc: 0.6535 - val_loss: 0.3923 - val_acc: 0.8723\n",
      "Epoch 18/40\n",
      "1313/1313 [==============================] - 1s 497us/step - loss: 0.6032 - acc: 0.6611 - val_loss: 0.3497 - val_acc: 0.9119\n",
      "Epoch 19/40\n",
      "1313/1313 [==============================] - 1s 496us/step - loss: 0.6025 - acc: 0.6664 - val_loss: 0.3183 - val_acc: 0.8875\n",
      "Epoch 20/40\n",
      "1313/1313 [==============================] - 1s 522us/step - loss: 0.5990 - acc: 0.6687 - val_loss: 0.3581 - val_acc: 0.8663\n",
      "Epoch 21/40\n",
      "1313/1313 [==============================] - 1s 600us/step - loss: 0.6011 - acc: 0.6687 - val_loss: 0.4055 - val_acc: 0.8571\n",
      "Epoch 22/40\n",
      "1313/1313 [==============================] - 1s 553us/step - loss: 0.5999 - acc: 0.6634 - val_loss: 0.3445 - val_acc: 0.8754\n",
      "Epoch 23/40\n",
      "1313/1313 [==============================] - 1s 558us/step - loss: 0.5955 - acc: 0.6710 - val_loss: 0.3199 - val_acc: 0.8906\n",
      "Epoch 24/40\n",
      "1313/1313 [==============================] - 1s 502us/step - loss: 0.5941 - acc: 0.6710 - val_loss: 0.3478 - val_acc: 0.8784\n",
      "Epoch 25/40\n",
      "1313/1313 [==============================] - 1s 515us/step - loss: 0.5935 - acc: 0.6710 - val_loss: 0.3061 - val_acc: 0.8815\n",
      "Epoch 26/40\n",
      "1313/1313 [==============================] - 1s 606us/step - loss: 0.5935 - acc: 0.6725 - val_loss: 0.4060 - val_acc: 0.8267\n",
      "Epoch 27/40\n",
      "1313/1313 [==============================] - 1s 731us/step - loss: 0.5911 - acc: 0.6649 - val_loss: 0.4126 - val_acc: 0.8328\n",
      "Epoch 28/40\n",
      "1313/1313 [==============================] - 1s 584us/step - loss: 0.5916 - acc: 0.6870 - val_loss: 0.4159 - val_acc: 0.8207\n",
      "Epoch 29/40\n",
      "1313/1313 [==============================] - 1s 524us/step - loss: 0.5886 - acc: 0.6725 - val_loss: 0.4623 - val_acc: 0.7781\n",
      "Epoch 30/40\n",
      "1313/1313 [==============================] - 1s 536us/step - loss: 0.5897 - acc: 0.6618 - val_loss: 0.3430 - val_acc: 0.8723\n",
      "Epoch 31/40\n",
      "1313/1313 [==============================] - 1s 703us/step - loss: 0.5886 - acc: 0.6679 - val_loss: 0.3537 - val_acc: 0.8511\n",
      "Epoch 32/40\n",
      "1313/1313 [==============================] - 1s 708us/step - loss: 0.5870 - acc: 0.6740 - val_loss: 0.3387 - val_acc: 0.8602\n",
      "Epoch 33/40\n",
      "1313/1313 [==============================] - 1s 647us/step - loss: 0.5850 - acc: 0.6717 - val_loss: 0.4331 - val_acc: 0.8055\n",
      "Epoch 34/40\n",
      "1313/1313 [==============================] - 1s 607us/step - loss: 0.5872 - acc: 0.6710 - val_loss: 0.4237 - val_acc: 0.8116\n",
      "Epoch 35/40\n",
      "1313/1313 [==============================] - 1s 611us/step - loss: 0.5864 - acc: 0.6657 - val_loss: 0.4509 - val_acc: 0.7964\n",
      "Epoch 36/40\n",
      "1313/1313 [==============================] - 1s 628us/step - loss: 0.5854 - acc: 0.6702 - val_loss: 0.3031 - val_acc: 0.8632\n",
      "Epoch 37/40\n",
      "1313/1313 [==============================] - 1s 607us/step - loss: 0.5845 - acc: 0.6763 - val_loss: 0.3161 - val_acc: 0.8693\n",
      "Epoch 38/40\n",
      "1313/1313 [==============================] - 1s 622us/step - loss: 0.5833 - acc: 0.6748 - val_loss: 0.3344 - val_acc: 0.8541\n",
      "Epoch 39/40\n",
      "1313/1313 [==============================] - 1s 612us/step - loss: 0.5817 - acc: 0.6725 - val_loss: 0.3725 - val_acc: 0.8419\n",
      "Epoch 40/40\n",
      "1313/1313 [==============================] - 1s 542us/step - loss: 0.5819 - acc: 0.6816 - val_loss: 0.3450 - val_acc: 0.8511\n",
      "181/181 [==============================] - 0s 28us/step\n",
      "Average accuracy of model on the dev set =  0.6702782661407238\n",
      "Training on fold 10/10.............................................\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_62 (Dense)             (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 5,425\n",
      "Trainable params: 5,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1313 samples, validate on 329 samples\n",
      "Epoch 1/40\n",
      "1313/1313 [==============================] - 2s 2ms/step - loss: 0.6780 - acc: 0.5887 - val_loss: 0.5372 - val_acc: 0.9939\n",
      "Epoch 2/40\n",
      "1313/1313 [==============================] - 1s 807us/step - loss: 0.6622 - acc: 0.6101 - val_loss: 0.4369 - val_acc: 0.9757\n",
      "Epoch 3/40\n",
      "1313/1313 [==============================] - 1s 732us/step - loss: 0.6578 - acc: 0.6078 - val_loss: 0.4634 - val_acc: 0.9635\n",
      "Epoch 4/40\n",
      "1313/1313 [==============================] - 1s 729us/step - loss: 0.6545 - acc: 0.6139 - val_loss: 0.4861 - val_acc: 0.8875\n",
      "Epoch 5/40\n",
      "1313/1313 [==============================] - 1s 740us/step - loss: 0.6519 - acc: 0.6139 - val_loss: 0.4545 - val_acc: 0.9483\n",
      "Epoch 6/40\n",
      "1313/1313 [==============================] - 1s 708us/step - loss: 0.6510 - acc: 0.6116 - val_loss: 0.4819 - val_acc: 0.8936\n",
      "Epoch 7/40\n",
      "1313/1313 [==============================] - 1s 742us/step - loss: 0.6499 - acc: 0.6123 - val_loss: 0.4494 - val_acc: 0.9453\n",
      "Epoch 8/40\n",
      "1313/1313 [==============================] - 1s 713us/step - loss: 0.6482 - acc: 0.6177 - val_loss: 0.4583 - val_acc: 0.9483\n",
      "Epoch 9/40\n",
      "1313/1313 [==============================] - 1s 893us/step - loss: 0.6467 - acc: 0.6253 - val_loss: 0.4911 - val_acc: 0.8875\n",
      "Epoch 10/40\n",
      "1313/1313 [==============================] - 1s 550us/step - loss: 0.6454 - acc: 0.6238 - val_loss: 0.4265 - val_acc: 0.9422\n",
      "Epoch 11/40\n",
      "1313/1313 [==============================] - 1s 544us/step - loss: 0.6429 - acc: 0.6283 - val_loss: 0.4757 - val_acc: 0.8906\n",
      "Epoch 12/40\n",
      "1313/1313 [==============================] - 1s 524us/step - loss: 0.6402 - acc: 0.6207 - val_loss: 0.4313 - val_acc: 0.8967\n",
      "Epoch 13/40\n",
      "1313/1313 [==============================] - 1s 531us/step - loss: 0.6383 - acc: 0.6215 - val_loss: 0.4418 - val_acc: 0.8906\n",
      "Epoch 14/40\n",
      "1313/1313 [==============================] - 1s 592us/step - loss: 0.6348 - acc: 0.6260 - val_loss: 0.4548 - val_acc: 0.8875\n",
      "Epoch 15/40\n",
      "1313/1313 [==============================] - 1s 520us/step - loss: 0.6299 - acc: 0.6321 - val_loss: 0.4045 - val_acc: 0.9453\n",
      "Epoch 16/40\n",
      "1313/1313 [==============================] - 1s 522us/step - loss: 0.6265 - acc: 0.6329 - val_loss: 0.4227 - val_acc: 0.9392\n",
      "Epoch 17/40\n",
      "1313/1313 [==============================] - 1s 513us/step - loss: 0.6206 - acc: 0.6420 - val_loss: 0.3928 - val_acc: 0.9271\n",
      "Epoch 18/40\n",
      "1313/1313 [==============================] - 1s 506us/step - loss: 0.6151 - acc: 0.6405 - val_loss: 0.4849 - val_acc: 0.8146\n",
      "Epoch 19/40\n",
      "1313/1313 [==============================] - 1s 537us/step - loss: 0.6121 - acc: 0.6565 - val_loss: 0.4635 - val_acc: 0.8176\n",
      "Epoch 20/40\n",
      "1313/1313 [==============================] - 1s 533us/step - loss: 0.6060 - acc: 0.6634 - val_loss: 0.3789 - val_acc: 0.8480\n",
      "Epoch 21/40\n",
      "1313/1313 [==============================] - 1s 738us/step - loss: 0.6057 - acc: 0.6573 - val_loss: 0.3867 - val_acc: 0.8602\n",
      "Epoch 22/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1313/1313 [==============================] - 1s 913us/step - loss: 0.6007 - acc: 0.6725 - val_loss: 0.3414 - val_acc: 0.8693\n",
      "Epoch 23/40\n",
      "1313/1313 [==============================] - 1s 559us/step - loss: 0.6012 - acc: 0.6603 - val_loss: 0.4097 - val_acc: 0.8571\n",
      "Epoch 24/40\n",
      "1313/1313 [==============================] - 1s 566us/step - loss: 0.5963 - acc: 0.6603 - val_loss: 0.3163 - val_acc: 0.8997\n",
      "Epoch 25/40\n",
      "1313/1313 [==============================] - 1s 509us/step - loss: 0.5969 - acc: 0.6695 - val_loss: 0.4352 - val_acc: 0.7872\n",
      "Epoch 26/40\n",
      "1313/1313 [==============================] - 1s 551us/step - loss: 0.5947 - acc: 0.6710 - val_loss: 0.3785 - val_acc: 0.8480\n",
      "Epoch 27/40\n",
      "1313/1313 [==============================] - 1s 501us/step - loss: 0.5907 - acc: 0.6695 - val_loss: 0.5104 - val_acc: 0.7629\n",
      "Epoch 28/40\n",
      "1313/1313 [==============================] - 1s 501us/step - loss: 0.5888 - acc: 0.6657 - val_loss: 0.4437 - val_acc: 0.8055\n",
      "Epoch 29/40\n",
      "1313/1313 [==============================] - 1s 525us/step - loss: 0.5905 - acc: 0.6740 - val_loss: 0.3104 - val_acc: 0.8815\n",
      "Epoch 30/40\n",
      "1313/1313 [==============================] - 1s 503us/step - loss: 0.5872 - acc: 0.6740 - val_loss: 0.3871 - val_acc: 0.8389\n",
      "Epoch 31/40\n",
      "1313/1313 [==============================] - 1s 527us/step - loss: 0.5847 - acc: 0.6778 - val_loss: 0.3824 - val_acc: 0.8359\n",
      "Epoch 32/40\n",
      "1313/1313 [==============================] - 1s 535us/step - loss: 0.5850 - acc: 0.6824 - val_loss: 0.2613 - val_acc: 0.9027\n",
      "Epoch 33/40\n",
      "1313/1313 [==============================] - 1s 535us/step - loss: 0.5846 - acc: 0.6710 - val_loss: 0.2929 - val_acc: 0.8845\n",
      "Epoch 34/40\n",
      "1313/1313 [==============================] - 1s 532us/step - loss: 0.5846 - acc: 0.6733 - val_loss: 0.3795 - val_acc: 0.8419\n",
      "Epoch 35/40\n",
      "1313/1313 [==============================] - 1s 502us/step - loss: 0.5830 - acc: 0.6717 - val_loss: 0.3204 - val_acc: 0.8663\n",
      "Epoch 36/40\n",
      "1313/1313 [==============================] - 1s 537us/step - loss: 0.5829 - acc: 0.6809 - val_loss: 0.3948 - val_acc: 0.8207\n",
      "Epoch 37/40\n",
      "1313/1313 [==============================] - 1s 507us/step - loss: 0.5791 - acc: 0.6748 - val_loss: 0.2638 - val_acc: 0.8906\n",
      "Epoch 38/40\n",
      "1313/1313 [==============================] - 1s 534us/step - loss: 0.5798 - acc: 0.6771 - val_loss: 0.3273 - val_acc: 0.8602\n",
      "Epoch 39/40\n",
      "1313/1313 [==============================] - 1s 506us/step - loss: 0.5761 - acc: 0.6862 - val_loss: 0.3815 - val_acc: 0.8176\n",
      "Epoch 40/40\n",
      "1313/1313 [==============================] - 1s 515us/step - loss: 0.5738 - acc: 0.6870 - val_loss: 0.2565 - val_acc: 0.9027\n",
      "181/181 [==============================] - 0s 25us/step\n",
      "Average accuracy of model on the dev set =  0.680046019735941\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, random_state=12)\n",
    "avg_loss = []\n",
    "avg_acc = []\n",
    "# Loop through the indices the split() method returns\n",
    "for index, (train_index, test_index) in enumerate(skf.split(all_data, labels)):\n",
    "    print(\"Training on fold \" + str(index + 1) + \"/10.............................................\")\n",
    "    # Generate batches from indices\n",
    "    x_train, x_test = all_data[train_index], all_data[test_index]\n",
    "    # use one-hot vectors as labels\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "\n",
    "    network = models.Sequential()\n",
    "    \n",
    "\n",
    "    network.add(layers.Dense(16, input_shape=(8,)))\n",
    "    network.add(layers.Dense(32, activation=\"relu\"))\n",
    "    network.add(layers.Dense(64, activation=\"relu\"))\n",
    "    network.add(layers.Dense(32, activation=\"relu\"))\n",
    "    network.add(layers.Dense(16, activation=\"sigmoid\"))\n",
    "    network.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Adam = Adam(lr=0.05)\n",
    "    network.compile(optimizer=Adam(lr=0.00038),\n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=['acc'])\n",
    "\n",
    "    network.summary()\n",
    "\n",
    "    history = network.fit(x_train, y_train, validation_split=0.2,\n",
    "                          epochs=40, verbose=1, batch_size=3)\n",
    "\n",
    "    loss, accuracy = network.evaluate(x_test, y_test)\n",
    "\n",
    "    # evaluate and store the accuracy\n",
    "#     loss, accuracy = model.evaluate(xtest_imagelist, ytest, verbose=1)\n",
    "    avg_loss.append(loss)\n",
    "    avg_acc.append(accuracy)\n",
    "\n",
    "    # cross validation score\n",
    "    print(\"Average accuracy of model on the dev set = \", np.mean(avg_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
