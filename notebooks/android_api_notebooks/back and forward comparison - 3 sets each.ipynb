{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "rest_android = pd.read_csv(\"../../data_files/data_from_android_api/rest/rest_25_mins.csv\")\n",
    "\n",
    "forward_android3 = pd.read_csv(\"../../data_files/data_from_android_api/forward/forward_5mins_3.csv\")\n",
    "forward_android4 = pd.read_csv(\"../../data_files/data_from_android_api/forward/forward_5mins_4.csv\")\n",
    "forward_android5 = pd.read_csv(\"../../data_files/data_from_android_api/forward/forward_5mins_5.csv\")\n",
    "\n",
    "back1 = pd.read_csv('../../data_files/data_from_android_api/back/back_5mins_1.csv')\n",
    "back2 = pd.read_csv('../../data_files/data_from_android_api/back/back_5mins_2.csv')\n",
    "back3 = pd.read_csv('../../data_files/data_from_android_api/back/back_5mins_3.csv')\n",
    "\n",
    "forward = pd.concat([forward_android3, forward_android4, forward_android5])\n",
    "back = pd.concat([back1, back2, back3])\n",
    "\n",
    "dataDF = pd.concat([forward, back])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "u = [back.delta.mean(), back.theta.mean(), back.alphaLow.mean(), \n",
    "     back.betaHigh.mean(), back.betaLow.mean(), back.alphaHigh.mean(), \n",
    "     back.gammaLow.mean(), back.gammaMid.mean()]\n",
    "\n",
    "d = [forward.delta.mean(), forward.theta.mean(), forward.alphaLow.mean(), \n",
    "     forward.betaHigh.mean(), forward.betaLow.mean(), forward.alphaHigh.mean(), \n",
    "     forward.gammaLow.mean(), forward.gammaMid.mean()]\n",
    "\n",
    "\n",
    "index = ['delta', 'theta', 'alphaLow','alphaHigh', 'betaLow', 'betaHigh', 'gammaLow', 'gammaMid']\n",
    "\n",
    "df = pd.DataFrame({'back': u, 'forward': d}, index=index)\n",
    "ax = df.plot.bar(rot=0, figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# create an array of shape 30706, 9 = number of records by the features\n",
    "data = np.array([[0 for x in range(8)] for y in range(len(dataDF))])\n",
    "for i in range(len(dataDF)):\n",
    "    data[i] = [dataDF.delta.values[i],\n",
    "                       dataDF.theta.values[i],\n",
    "                       dataDF.alphaLow.values[i],\n",
    "                       dataDF.alphaHigh.values[i],\n",
    "                       dataDF.betaLow.values[i],\n",
    "                       dataDF.betaHigh.values[i],\n",
    "                       dataDF.gammaLow.values[i],\n",
    "                       dataDF.gammaMid.values[i]]\n",
    "    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "encoder = LabelBinarizer()\n",
    "labels = encoder.fit_transform(dataDF.action.values)\n",
    "\n",
    "# creating training and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, labels)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "scaler = MinMaxScaler()\n",
    "stan_scaler = StandardScaler()\n",
    "\n",
    "x_train = stan_scaler.fit_transform(x_train)\n",
    "x_test = stan_scaler.transform(x_test)\n",
    "\n",
    "all_data = dataDF.drop(['action'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.22042284 0.14594739 0.10373953 0.09494873 0.10523178 0.09295838\n",
      " 0.10846624 0.12828511]\n",
      "The score for Random Forest  0.6508620689655172\n",
      "1392\n",
      "Accuracy for x_test: 0.6508620689655172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracy: 0.62 (+/- 0.22)\n",
      "[0.44919786 0.47058824 0.52406417 0.53513514 0.69189189 0.74054054\n",
      " 0.67027027 0.75675676 0.67567568 0.6972973 ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Random Forrest\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(x_train, y_train)\n",
    "\n",
    "print(rfc.feature_importances_)\n",
    "\n",
    "print(\"The score for Random Forest \", rfc.score(x_test, y_test))\n",
    "y_pred = rfc.predict(x_test)\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(len(y_train))\n",
    "print(\"Accuracy for x_test:\", metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "scores = cross_val_score(rfc, all_data, labels, cv=10, scoring='accuracy')\n",
    "print(\"Cross Validation Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "The score for XGBoost  0.7068965517241379\n",
      "Accuracy for x_test: 0.7068965517241379\n",
      "Accuracy: 70.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracy: 0.68 (+/- 0.33)\n",
      "[0.44385027 0.44919786 0.51871658 0.54594595 0.82162162 0.87027027\n",
      " 0.74054054 0.82702703 0.78918919 0.82702703]\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(x_train, y_train)\n",
    "\n",
    "# plot feature importance\n",
    "plot_importance(xgb)\n",
    "pyplot.show()\n",
    "print(xgb)\n",
    "print(\"The score for XGBoost \", xgb.score(x_test, y_test))\n",
    "y_pred = xgb.predict(x_test)\n",
    "\n",
    "print(\"Accuracy for x_test:\", metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = metrics.accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "\n",
    "scores = cross_val_score(xgb, all_data, labels, cv=10, scoring='accuracy')\n",
    "print(\"Cross Validation Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_set = [(x_train, y_train), (x_test, y_test)]\n",
    "eval_metric = [\"auc\",\"error\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Tuning and feature importance XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score for XGBoost  0.6767241379310345\n",
      "Accuracy for x_test: 0.6767241379310345\n",
      "Accuracy: 67.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracy: 0.69 (+/- 0.33)\n",
      "[0.43315508 0.45454545 0.51336898 0.57297297 0.82162162 0.87567568\n",
      " 0.75135135 0.84324324 0.78378378 0.81621622]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresh=0.034, n=8, Accuracy: 67.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresh=0.034, n=8, Accuracy: 67.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresh=0.053, n=6, Accuracy: 68.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresh=0.071, n=5, Accuracy: 67.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresh=0.081, n=4, Accuracy: 68.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresh=0.111, n=3, Accuracy: 68.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresh=0.214, n=2, Accuracy: 68.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresh=0.402, n=1, Accuracy: 68.75%\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "from numpy import sort\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "xgb = XGBClassifier(silent=True, \n",
    "                      scale_pos_weight=1,\n",
    "                      learning_rate=0.01,  \n",
    "                      colsample_bytree = 0.4,\n",
    "                      subsample = 0.3,\n",
    "                      objective='binary:logistic', \n",
    "                      n_estimators=1000, \n",
    "                      reg_alpha = 0.3,\n",
    "                      max_depth=4, \n",
    "                      gamma=10)\n",
    "xgb.fit(x_train, y_train)\n",
    "# plot feature importance\n",
    "plot_importance(xgb)\n",
    "pyplot.show()\n",
    "# print(xgb)\n",
    "print(\"The score for XGBoost \", xgb.score(x_test, y_test))\n",
    "y_pred = xgb.predict(x_test)\n",
    "\n",
    "print(\"Accuracy for x_test:\", metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = metrics.accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "\n",
    "scores = cross_val_score(xgb, all_data, labels, cv=10, scoring='accuracy')\n",
    "print(\"Cross Validation Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "print(scores)\n",
    "\n",
    "# Fit model using each importance as a threshold\n",
    "thresholds = sort(xgb.feature_importances_)\n",
    "for thresh in thresholds:\n",
    "\t# select features using threshold\n",
    "\tselection = SelectFromModel(xgb, threshold=thresh, prefit=True)\n",
    "\tselect_X_train = selection.transform(x_train)\n",
    "\t# train model\n",
    "\tselection_model = XGBClassifier(silent=True, \n",
    "                      scale_pos_weight=1,\n",
    "                      learning_rate=0.01,  \n",
    "                      colsample_bytree = 0.4,\n",
    "                      subsample = 0.3,\n",
    "                      objective='binary:logistic', \n",
    "                      n_estimators=1000, \n",
    "                      reg_alpha = 0.3,\n",
    "                      max_depth=4, \n",
    "                      gamma=10)\n",
    "\tselection_model.fit(select_X_train, y_train)\n",
    "\t# eval model\n",
    "\tselect_X_test = selection.transform(x_test)\n",
    "\ty_pred = selection_model.predict(select_X_test)\n",
    "\tpredictions = [round(value) for value in y_pred]\n",
    "\taccuracy = accuracy_score(y_test, predictions)\n",
    "\tprint(\"Thresh=%.3f, n=%d, Accuracy: %.2f%%\" % (thresh, select_X_train.shape[1], accuracy*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 6,481\n",
      "Trainable params: 6,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "1392/1392 [==============================] - 1s 988us/step - loss: 0.6879 - acc: 0.5532\n",
      "Epoch 2/40\n",
      "1392/1392 [==============================] - 1s 561us/step - loss: 0.6717 - acc: 0.5704\n",
      "Epoch 3/40\n",
      "1392/1392 [==============================] - 1s 553us/step - loss: 0.6682 - acc: 0.5704\n",
      "Epoch 4/40\n",
      "1392/1392 [==============================] - 1s 548us/step - loss: 0.6641 - acc: 0.5761\n",
      "Epoch 5/40\n",
      "1392/1392 [==============================] - 1s 568us/step - loss: 0.6615 - acc: 0.5884\n",
      "Epoch 6/40\n",
      "1392/1392 [==============================] - 1s 634us/step - loss: 0.6575 - acc: 0.5927\n",
      "Epoch 7/40\n",
      "1392/1392 [==============================] - 1s 548us/step - loss: 0.6515 - acc: 0.6121\n",
      "Epoch 8/40\n",
      "1392/1392 [==============================] - 1s 563us/step - loss: 0.6474 - acc: 0.6228\n",
      "Epoch 9/40\n",
      "1392/1392 [==============================] - 1s 580us/step - loss: 0.6432 - acc: 0.6286\n",
      "Epoch 10/40\n",
      "1392/1392 [==============================] - 1s 615us/step - loss: 0.6375 - acc: 0.6372\n",
      "Epoch 11/40\n",
      "1392/1392 [==============================] - 1s 590us/step - loss: 0.6323 - acc: 0.6386\n",
      "Epoch 12/40\n",
      "1392/1392 [==============================] - 1s 586us/step - loss: 0.6303 - acc: 0.6509\n",
      "Epoch 13/40\n",
      "1392/1392 [==============================] - 1s 562us/step - loss: 0.6264 - acc: 0.6487\n",
      "Epoch 14/40\n",
      "1392/1392 [==============================] - 1s 603us/step - loss: 0.6262 - acc: 0.6552\n",
      "Epoch 15/40\n",
      "1392/1392 [==============================] - 1s 558us/step - loss: 0.6197 - acc: 0.6631\n",
      "Epoch 16/40\n",
      "1392/1392 [==============================] - 1s 611us/step - loss: 0.6127 - acc: 0.6767 0s - loss: 0.6107 - acc: 0.677\n",
      "Epoch 17/40\n",
      "1392/1392 [==============================] - 1s 559us/step - loss: 0.6159 - acc: 0.6624\n",
      "Epoch 18/40\n",
      "1392/1392 [==============================] - 1s 713us/step - loss: 0.6148 - acc: 0.6638\n",
      "Epoch 19/40\n",
      "1392/1392 [==============================] - 1s 602us/step - loss: 0.6088 - acc: 0.6753\n",
      "Epoch 20/40\n",
      "1392/1392 [==============================] - 1s 765us/step - loss: 0.6067 - acc: 0.6767 0s - loss: 0.61\n",
      "Epoch 21/40\n",
      "1392/1392 [==============================] - 1s 686us/step - loss: 0.6109 - acc: 0.6674\n",
      "Epoch 22/40\n",
      "1392/1392 [==============================] - 1s 700us/step - loss: 0.6069 - acc: 0.6674\n",
      "Epoch 23/40\n",
      "1392/1392 [==============================] - 1s 738us/step - loss: 0.6073 - acc: 0.6717\n",
      "Epoch 24/40\n",
      "1392/1392 [==============================] - 1s 701us/step - loss: 0.6031 - acc: 0.6767\n",
      "Epoch 25/40\n",
      "1392/1392 [==============================] - 1s 705us/step - loss: 0.6010 - acc: 0.6717\n",
      "Epoch 26/40\n",
      "1392/1392 [==============================] - 1s 629us/step - loss: 0.6004 - acc: 0.6782\n",
      "Epoch 27/40\n",
      "1392/1392 [==============================] - 1s 667us/step - loss: 0.6031 - acc: 0.6767\n",
      "Epoch 28/40\n",
      "1392/1392 [==============================] - 1s 684us/step - loss: 0.5989 - acc: 0.6760\n",
      "Epoch 29/40\n",
      "1392/1392 [==============================] - 1s 652us/step - loss: 0.5973 - acc: 0.6818 0s - loss: 0.5882 - a\n",
      "Epoch 30/40\n",
      "1392/1392 [==============================] - 1s 685us/step - loss: 0.5984 - acc: 0.6803\n",
      "Epoch 31/40\n",
      "1392/1392 [==============================] - 1s 641us/step - loss: 0.5927 - acc: 0.6810\n",
      "Epoch 32/40\n",
      "1392/1392 [==============================] - 1s 648us/step - loss: 0.5965 - acc: 0.6746\n",
      "Epoch 33/40\n",
      "1392/1392 [==============================] - 1s 639us/step - loss: 0.5933 - acc: 0.6825\n",
      "Epoch 34/40\n",
      "1392/1392 [==============================] - 1s 642us/step - loss: 0.5982 - acc: 0.6710\n",
      "Epoch 35/40\n",
      "1392/1392 [==============================] - 1s 666us/step - loss: 0.5926 - acc: 0.6868\n",
      "Epoch 36/40\n",
      "1392/1392 [==============================] - 1s 641us/step - loss: 0.5905 - acc: 0.6717\n",
      "Epoch 37/40\n",
      "1392/1392 [==============================] - 1s 609us/step - loss: 0.5937 - acc: 0.6789\n",
      "Epoch 38/40\n",
      "1392/1392 [==============================] - 1s 636us/step - loss: 0.5980 - acc: 0.6717\n",
      "Epoch 39/40\n",
      "1392/1392 [==============================] - 1s 664us/step - loss: 0.5878 - acc: 0.6983\n",
      "Epoch 40/40\n",
      "1392/1392 [==============================] - 1s 609us/step - loss: 0.5882 - acc: 0.6882\n",
      "464/464 [==============================] - 0s 138us/step\n",
      "loss and metrics [0.6365093444955761, 0.646551724137931]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAIABJREFUeJzt3Xl4VOX1wPHvyR52EgICCYQdArKOiKCyuFFrtVpLsXWBqlSUavWnLXaxlm5qaxet1eKKC+Ju0VKRiriCkEjYAgiEJYGEhEDCGrKd3x/3BoeQZCYhk5kk5/M88zj3zntnztyWOXl3UVWMMcaY2oQFOwBjjDGhz5KFMcYYnyxZGGOM8cmShTHGGJ8sWRhjjPHJkoUxxhifLFmYFk9EkkVERSTCj7LTROTTxojLmFBiycI0KSKyQ0RKRKRTlfPp7g9+cnAiM6Z5s2RhmqLtwDWVByJyJhAbvHBCgz81I2Pqy5KFaYpeAK73Or4BeN67gIi0F5HnRSRfRHaKyC9FJMx9LVxE/iwi+0QkE/hmNdc+LSI5IrJbRH4nIuH+BCYir4lIrogUicjHIjLY67VYEXnYjadIRD4VkVj3tXNF5HMRKRSRLBGZ5p5fJiI3eb3HSc1gbm3qNhHZAmxxz/3dfY+DIpImIud5lQ8XkZ+LyDYROeS+niQij4nIw1W+yzsi8hN/vrdp/ixZmKZoBdBORAa5P+LfA16sUuZRoD3QGxiPk1ymu6/dDFwGjAA8wNVVrp0HlAF93TIXAzfhn/8C/YDOwJfAS16v/RkYBYwF4oCfAhUi0sO97lEgARgOpPv5eQDfBs4GUtzjVe57xAHzgddEJMZ97S6cWtmlQDvgh8BR9ztf45VQOwEXAC/XIQ7TnKmqPezRZB7ADuBC4JfAH4HJwBIgAlAgGQgHjgMpXtf9CFjmPl8K3OL12sXutRFAF/faWK/XrwE+dJ9PAz71M9YO7vu2x/nD7BgwrJpy9wJv1fAey4CbvI5P+nz3/Sf5iONA5ecCm4Eraii3EbjIfT4LWBTs/73tEToPa+M0TdULwMdAL6o0QQGdgChgp9e5nUB393k3IKvKa5V6ApFAjohUngurUr5abi3n98B3cWoIFV7xRAMxwLZqLk2q4by/TopNRP4PpybUDSeZtHNj8PVZ84BrcZLvtcDfTyMm08xYM5RpklR1J05H96XAm1Ve3geU4vzwV+oB7Haf5+D8aHq/VikLp2bRSVU7uI92qjoY374PXIFT82mPU8sBEDemYqBPNddl1XAe4AjQyuv4jGrKnFg62u2f+BkwBeioqh2AIjcGX5/1InCFiAwDBgFv11DOtECWLExTdiNOE8wR75OqWg68CvxeRNqKSE+ctvrKfo1XgdtFJFFEOgKzva7NAd4HHhaRdiISJiJ9RGS8H/G0xUk0BTg/8H/wet8K4BngLyLSze1oPkdEonH6NS4UkSkiEiEi8SIy3L00HbhKRFqJSF/3O/uKoQzIByJE5D6cmkWlp4Dfikg/cQwVkXg3xmyc/o4XgDdU9Zgf39m0EJYsTJOlqttUNbWGl3+M81d5JvApTkfvM+5rTwKLgTU4ndBVaybX4zRjZeC0978OdPUjpOdxmrR2u9euqPL63cA6nB/k/cCDQJiq7sKpIf2fez4dGOZe81egBNiL00z0ErVbjNNZ/pUbSzEnN1P9BSdZvg8cBJ7m5GHH84AzcRKGMSeIqm1+ZIxxiMj5ODWwZLc2ZAxgNQtjjEtEIoE7gKcsUZiqLFkYYxCRQUAhTnPb34IcjglB1gxljDHGJ6tZGGOM8anZTMrr1KmTJicnBzsMY4xpUtLS0vapaoKvcs0mWSQnJ5OaWtMoSmOMMdURkZ2+S1kzlDHGGD9YsjDGGOOTJQtjjDE+BbTPQkQm46xcGY4z0eeBKq//FZjoHrYCOrsLnyEiN+AsQw3wO1WdV9fPLy0tJTs7m+Li4vp+hSYnJiaGxMREIiMjgx2KMaYZCViycJdrfgy4CMgGVonIQlXNqCyjqnd6lf8xzkYziEgc8GucjWkUSHOvPVCXGLKzs2nbti3Jycl4LTfdbKkqBQUFZGdn06tXr2CHY4xpRgLZDDUa2KqqmapaAizAWb65Jtfw9a5clwBLVHW/myCW4GxyUyfFxcXEx8e3iEQBICLEx8e3qJqUMaZxBDJZdOfk1S6z+XrzmZO4S0j3wtnBzO9rRWSGiKSKSGp+fn61QbSURFGppX1fY0zjCGSyqO5Xq6a1RaYCr7v7EPh9rarOVVWPqnoSEnzOKTHGmCYna/9R3l27J9hhBDRZZHPybmSJQE3feConbwxfl2tDVkFBAcOHD2f48OGcccYZdO/e/cRxSUmJX+8xffp0Nm/eHOBIjTGh6vGPtjFr/mpWbt8f1DgCORpqFdBPRHrhbAYzFWfbyZOIyACgI7Dc6/Ri4A/uLmYAF+Nsat+kxMfHk56eDsD9999PmzZtuPvuu08qU7kZelhY9Xn72WefDXicxpjQtXpXIQBz3t3AwtvOJSwsOE3NAatZqGoZMAvnh38j8KqqbhCROSJyuVfRa4AF6rX8raruB36Lk3BWAXPcc83C1q1bGTJkCLfccgsjR44kJyeHGTNm4PF4GDx4MHPmzDlR9txzzyU9PZ2ysjI6dOjA7NmzGTZsGOeccw55eXlB/BbGmEA7WlLG5tyDDDyjLet3H+SNL7ODFktA51mo6iJgUZVz91U5vr+Ga5/h620wT9tv3tlAxp6DDfV2AKR0a8evvzW4XtdmZGTw7LPP8sQTTwDwwAMPEBcXR1lZGRMnTuTqq68mJSXlpGuKiooYP348DzzwAHfddRfPPPMMs2fPru7tjTHNwLrsIioU7rlkAI8u3cpDizdz6ZldaR3d+Mv62QzuIOnTpw9nnXXWieOXX36ZkSNHMnLkSDZu3EhGRsYp18TGxvKNb3wDgFGjRrFjx47GCtcYEwSrs5wmqOFJHbjvWynkHzrO48u2BSWWZrPqrC/1rQEESuvWrU8837JlC3//+99ZuXIlHTp04Nprr612rkRUVNSJ5+Hh4ZSVlTVKrMaY4EjfVUjP+FbEt4kmvk00VwzvxpOfZDJ1dBKJHVs1aixWswgBBw8epG3btrRr146cnBwWL14c7JCMMSEgPauQ4UkdThz/bPJARODB9xp/hKQlixAwcuRIUlJSGDJkCDfffDPjxo0LdkjGmCDLLSom92DxScmiW4dYZpzfh3fW7CFtZ+OO+Wk2e3B7PB6tuvnRxo0bGTRoUJAiCp6W+r2NaU7eW5/DLS9+yVu3jmVEj44nzh8tKWPin5dxRrsY3rp13GkPpRWRNFX1+CpnNQtjjAlBq7MKiQoPI6Vbu5POt4qK4KeXDGRNdhFvp+9utHgsWRhjTAhavauQQd3aER0RfsprV47oztDE9jz43iaOljTOQJdmnyyaSzObv1ra9zWmOSorr2BddhEjvPorvIWFCfddlsLeg8d54qPMRompWSeLmJgYCgoKWswPaOV+FjExMcEOxRhzGr7ae5hjpeWM6FF9sgDwJMdx2dCuzP14G3sKjwU8pmY9zyIxMZHs7GxqWr68OarcKc8Y03Sle03Gq83sbwzk/Yy9PPTeJv42dURAY2rWySIyMtJ2jDPGNDnpWQeIax1Fj7jaJ94ldmzFbRP6cqy0HFUN6H42zTpZGGNMQ3j0gy2UVSh3XtS/UT5v9a5ChiW29+vH/44L+zVCRM28z8IYY07X4eNlPLZsK48v20bhUf/2oTkdh4pL2Zp/mOFJHX0XbkSWLIwxphbvrc+luLSCkvIKFq4J/B5sa7OLUKXWzu1gsGRhjDG1eGt1Nj3iWpHStR2vpmYF/PMqO7eH+ejcbmyWLIwxpgY5Rcf4fFsB3x7RnSmeRNbvPsjGnIbdF6eq1bsK6Z3QmvaxkQH9nLqyZGGMMTVYmL4HVWfG9BXDuxMVHsZrqYHbrU5VSc864HPIbDBYsjDGNHuLN+Ry0V8+Imv/0Tpd99bq3Yzo0YFenVrTsXUUF6Z05u303ZSUVQQkzuwDx9h3uKTGmdvBFNBkISKTRWSziGwVkWr3/xSRKSKSISIbRGS+1/mH3HMbReQRCeQAYmNMQFVUKL96ez2e3y3hpnmreOqTTNbvLqK8wv/VFeq7EkP2gaPc/doatuQd5p/Ltvp9Xcaeg2zKPcRVI7qfOPfdUUnsP1LC0k176xWLL5X9Fd6rzIaKgM2zEJFw4DHgIiAbWCUiC1U1w6tMP+BeYJyqHhCRzu75scA4YKhb9FNgPLAsUPEaYwKjokL52RtreS0tm/H9E9iWf4T/bcwDoF1MBKN7xTOmdxxjesfTsXUU2fuPkn3gmPtwnxceZe/B4/zg7B7cd1mK35PPysor+MmCdFThksFdeC01m1sn9CXJx2Q3cDq2I8KEy4Z2O3HuvH6d6Nw2mtdSs5k8pGv9bkgt0rMKiY4IY8AZbRv8vU9XICfljQa2qmomgIgsAK4AvDeXvhl4TFUPAKhqnntegRggChAgEghMKjfGBExFhTL7TSdR3H5BP+5yJ7XlFB3ji8z9rMgsYEVmAf/bWP0/785to0nsGMuIpI4cLyvn2c92EN86ilmT/JuI9sjSraTuPMDfpw5ndK84PtyUzz+XbeOPV51Z63XlFcq/0/cwYUBnOrb+ejvjiPAwvjMqkbkfZ5J3sJjO7Rp2Hbb0rELO7N6eyPDQ6yEIZLLoDniPM8sGzq5Spj+AiHwGhAP3q+p7qrpcRD4EcnCSxT9UdWPVDxCRGcAMgB49ejT8NzDG1Ftlong11UkUd3rNNO7aPpZvj+jOt90mnj2Fx/hiewFHS8pJ6tiKxI6xdOsQS0zk18tzqyp3vbqGP7//FWe0j+XqUbWvgfZFZgH/WLqFq0Y6ndMAU0cnMf+LXdw2sU+te1h/vm0feYeOc9XI7qe89t1RiTy+bBtvrt7NLeP7+HUvysoriPCRAErKKli3u4jrx/T06z0bWyDTV3X1xKqNjhFAP2ACcA3wlIh0EJG+wCAgESfpTBKR8095M9W5qupRVU9CQkKDBm9MS3S0pKxO/Qg1qahQ7n1znZMoJvXlzgv71dp01K1DLFeOSOQHZ/fk/P4J9E5oc1KiABARHvzOUMb1jWf2G2v5+KuaFwgtPFrCT15Jp0dcK+ZcMeTE+ZkT+hAmwmMfbqs1/re+3E3bmAgmDex8ymu9E9owqmdHXkvN8qsfZdWO/Qyfs4RnPt1ea7lNuQcpKatgeIhNxqsUyGSRDSR5HScCVac/ZgP/VtVSVd0ObMZJHlcCK1T1sKoeBv4LjAlgrMa0eJtzD3HOH5cyfM779e6EBidR/PytdbySmsWPJ/Xlzov6N9gCd1ERYTx+7Sj6dm7DzBfTWL+76JQyqk4fyb7Dx3n0mpG0if66AaVr+1i+d1YSr6dlkX2g+pFRR0vKeG9DLpcN7XpKwqr03VGJbMs/wmq3Q7omuUXFzHzxS46WlPG7/2Tw+dZ9NZb1d6XZYAlkslgF9BORXiISBUwFFlYp8zYwEUBEOuE0S2UCu4DxIhIhIpE4ndunNEMZU5ODxaVUNMBfyPVRdKyU4tLyoHx2eYVy+Hjdd07LKTrGtGdXEh0RxmVDu5KZf4Tf/Wcjlz366UnJY112Ua07s1UmigWrspg1sS93NWCiqNQuJpJ5PxxN+9hIpj+36pThsPNX7mLxhr3cc8kAzkxsf8r1Myc4TUf/XFZ97WLxhlyOlpRz5Yiam7m+ObQrMZG1z7k4XlbOLS+mcaykjDdvHUffzm24bf6XNSap9F2FJLSNpnuH2BrfM5gC1mehqmUiMgtYjNMf8YyqbhCROUCqqi50X7tYRDKAcuAeVS0QkdeBScA6nKar91T1nUDFapqX/UdKGP+nD5k5oQ+3Tugb8M8rOlrKF9sLWOF22G7MPcjo5DhevnkMYWGNN+K74PBxbno+la15h/nXdaMY26eTX9cdLC5l+rOrOFRcxqs/OufEns97Dxaf6IBekbn/xAgmgPjWUSR2jCXR7V+ofL54Qy4LVmVx28Q+/N/FDZ8oKnVpF8NzPxzN1Y9/zrRnV/LGzLF0aBXFV3sPMeedDM7r14mbzu1d7bXdOji1i1dWZXHbxL6n/Di/tXoP3TvE4ulZ8/DVtjGRXDqkK++s2cN9l6UQG3VqDeT+hRtIzyrkiWtHMjypA/+6zsPl//iUH72Qxhszx55Sa0nPKmR4UoeALjN+OqS57CLn8Xg0NTU12GGYEPDER9t44L+b6No+hk9+OtFnx2JdHS8r5+Ov9rEis4Dl25zkoArREWF4kjvSuW0Mb63ezUNXD2WKJ8n3GzaA7fuOMO3ZleQWFdO1fQy7C4/x5+8OO9GxW9t3mfbMKlbt2M9z00dzbr+aE0xuUTGpO/ezyx3amrX/KLsPHCO78NhJk9Rum9iHuy8e0Cg/eisyC7j+6ZUMTWzP0zecxZR/LafgyHEW3XEendvWPFJpT+Exxv/pQ6Z4kvj9lV+PjMo7WMyYP37ArRP6cvclA2r97OXbCrjmyRX89XvDTqmFvPTFTn7x1npum9iHey4ZeOL80k17uXFeKt8e3p2/TBl24h4VHi1h+Jwl3HPJAG6bGPg/cLyJSJqqenyVs/0sTLNSXqG8sHwn7WMjySkq5qOv8rlgUJcG/Yx7XlvLwjV7iI4IY1TPjtx5YX/G9I5nWFJ7oiPCqahQsvYf5Y+LNnLRoC4nDb0MhLSdB7j5eecPpZdnjKFPpzbMeCGVOxakk33gGLdO6FPtD3dFhXLPa2tZnlnAX6YMqzVRAJzRPuakOQfe77Pv8HGyDhxDVRnVs2Oj/XU8pnc8f/neMGbNX80Ff1nGvsMlPDf9rFoTBTi1iymeJF5NdWoX3dzaxcI1e6hQuLKaUVBVnd0rjqS4WF5LzT4pWaTt3M/9Czcwvn8Cd110csKZNLALd13Yn4eXfMWZ3dvzw3OdzdlOTMYL0f4KsOU+TDPz4aY8dhceY84Vg+nUJpqXV+5q0PfflHuQhWv28MNxvVjz64uZf/MYbr+gH6N7xREd4TQrhIUJv7tyCAeLy3jwvU0N+vlVvbc+l+8/uYJ2MRG8OXMsI3t0pH2rSJ6/cTSXD+vGnxZv5pdvr6es/NTlKR5cvImFa/ZwzyUDuGpk/bfiDQsTOreLYVTPjniS4xq9GeWyod345TcHse9wCTee24sJA04dwVSdW92/4L1ndb/55W6GJbanT0Ibn9eHhQlXj0zi820FJ/pN9h4s5pYXv6Rbh1gemTqC8GqaIW+b2JeLU7rw+0UbWb6tAHCShQjV9rGECksWplmZt3wHXdpFc+mZXZniSWTppjxyihpuM/tHP9hKm+gIbr+gb40jZQAGntGOG8/txYJVWaTt3N9gn+/t2c+2M/OlNFK6teONmWNJ7tT6xGvREeH87XvDmTmhDy99sYsZL6RxxKvje97nO/jXR5lcO6YHt07wb65AKLvpvN68f+f5/OLSQX5f071DLN/1OH0XewqPsTn3EBk5B7lyhO9aRaXvjOqOCLyelk1JWQUzX3Tu89zrPLRvVf2qsWFhwsNThpEc34pZ879kd+Ex0rMK6d+5LW1jQmulWW+WLEyzkZl/mE+27OMHZ/ckMjyMqWf1oELh1VUNs0ro5txD/GddDtPGJtOhle+mpTsu6Ee39jH84q3q/7Kvr4oK5bfvZvCbdzK4cFAX5t80hvg20aeUCwsTfjZ5IL/99hCWbc5j6twV5B86znvrc7j/nQ1clNKF31w+JGQ7VOuqf5e2dR5QUJkoH1+2jbdW7yY8TPjWsFOb2mqS2LEVY/vE83paNr9euIEvdxXyp6uH+Vyuo21MJHOv93C8rIJbXkg70bkdyixZmGbjhRU7iQwXpo52OpV7xLfivH6deGXVrgaZaPbIB1toEx3BjW47sy+toyO471uD2ZR7iOc+33Hanw9QXFrOrJe/5OlPt3PDOT154tpR1Y7E8XbdmJ7Mvc7D1rzDfPuxz7hjQTrDkzrU2EzSkiR2bMXVo5zaxetpWYzvn1Bt4q3NFE8SuwuP8fLKXdwyvg/fHOrfmlF9Etrw1+8NZ93uIgqPlobsZLxKlixMs3C0pIzX07L5xpCuJ3Vufn90D/YUFdc629cfm3MPsWh9DjeM7VmnDutLBndh0sDO/HXJV6fdHJaZf5gr//k5i9bl8otLB3H/5YP9/rG/MKULC2aM4XhZOd06xPL0DWf5TDItxW0T+1Chyr7DJXVqgqp0yeAzSGgbzfn9E7jHxwiqqi5K6cJPLuyHCJyVHFfnz25MlixMs/D26j0cKi7j+nNOXlfnwpQudGoTzfzT7Oh+ZOkWWkWG1zh2vyYiwm8uH0y5KnPeyfB9QQ3eWbOHbz36KTlFx3hmmoebz+9d5+ajYUkdWHr3BN798bnEBXiEVlOS2LEV14zuQVzrKC5KqfvIuZjIcP5353iem3ZWvWpqd1zQj+WzL6BvZ9+d6sFkycI0earK88t3kNK1HaOqTKSKDA/ju25Hd25Rcb3e/6u9h1i0Lodp45LrNQw2Ka4VP57Uj/+uz+XDzXm+L/BSXFrOL95ax49fXs2AM9ryn9vPY9LA+g8FbhcTSetoGzFf1X3fSmHp/42vddBCbdq3iqz3BEwR4Yz2Dbt6bSBYsjBN3qodB9iUe4jrz+lZ7V/bU89KorxCeS01q5qrfXvkg/rVKrzdfF5v+iS05tf/3uD3UiA79h3hO49/zktf7OJH5/fmlR+dE7JLQTR1keFhfg1aaMksWZgmb97yHbSLiahxtnLP+Nac27cTC1Zl1bmje8teZwTUDWPrV6uoFBURxm+/PYRd+4/y2Ie+d2v7z9ocLnv0U7IPHOOp6z3ce+mgkNzjwLQcVh81Tdreg8UsXp/LtLHJtXbYXjO6B7fN/5JPtuT7PWkLnM1zYiPDuem8+tcqKo3t04krR3TniY+20TYmgqgafvw35hzildQshid14B/fH1HrvgvGNBZLFqZJm//FLspVudbHhjEXpXQhvnUUL6/c5Xey2LL3EO+u3cMt4/s0WIfwzy8dxIrMAv6wqOaZ3SJw07m9+OnkgURFWG3ChAZLFqbJKimrYP7KXYzvn3DS7OXqREWEcbUnkac+2e73dpiVtYqbG6BWUSmhbTQf3TPxpNnUVUVGhJ20B4MxocD+bDFN1uINueQfOs4N5yT7VX7qWT2cju403zO6t+Y5tYrrz0lu8GGmURFhdGwdVePDEoUJRZYsTJP1wvKd9Ihrxfj+/m2p26tTa8b2iefllbt8boz0yAeVtQr/Zmsb09xZsjBN0sacg6zcsZ/rxvSs0/j2a0b3IPvAMT6tYXvLvQeLeXVVFu+s3cN15/Ss89IPxjRXVt81TdLzy3cQHeFMuKuLiwd3Ic7t6D6/f4LXbnDOLnfb9x0BnBVJZzRgX4UxTZ0lC9PkrNy+n1dWZfGDs3vWeSJVdEQ43x2VyNOfbmfSn5eR6SaHttERjO4Vxw/O7sGY3vEM6tquxS+yZ4y3gCYLEZkM/B1nD+6nVPWBaspMAe7H2Wt7jap+3z3fA3gKSHJfu1RVdwQyXhP6io6W8pMFq+kR14qffWOg7wuqce2YnizZuJde8a25ZrSTHFK6WXIwpjYBSxYiEg48BlwEZAOrRGShqmZ4lekH3AuMU9UDIuI9AP554PequkRE2gANtyGAaZJUldlvriXv0HHevHVsvUcNJcW1Yun/TWjY4Ixp5gLZwT0a2KqqmapaAiwArqhS5mbgMVU9AKCqeQAikgJEqOoS9/xhVT0awFhNE/Dyyiz+uz6Xey4ZwNDE0F7735jmJpDJojvgvXJbtnvOW3+gv4h8JiIr3GaryvOFIvKmiKwWkT+5NZWTiMgMEUkVkdT8/NPbr8CEti17DzHn3Q2c169Tg06SM8b4J5DJoroG4KqD2yOAfsAE4BrgKRHp4J4/D7gbOAvoDUw75c1U56qqR1U9CQn+jbU3TU9xaTk/fnk1raMieHjKsHovBW2Mqb9AJotsnM7pSonAnmrK/FtVS1V1O7AZJ3lkA6vdJqwy4G1gZABjNSHsj4s2sin3EH+eMuykXfCMMY0nkMliFdBPRHqJSBQwFVhYpczbwEQAEemE0/yU6V7bUUQqqwuTgPpvM2aarCUZe5m3fCc3ntuLiXVYLdYY07AClizcGsEsYDGwEXhVVTeIyBwRudwtthgoEJEM4EPgHlUtUNVynCaoD0RkHU6T1pOBitWEptyiYn76+hoGd2vHTyfXbW9jY0zDEtW6bQYTqjwej6ampgY7DNNAyiuUa5/6gvSsQt69/Vz6JIT2/sTGNFUikqaqHl/lbAa3CUmPLt3C8swCHrp6qCUKY0KALSRoQs7radn87X9buGpkd747qm5rPxljAsOShQkpH3+Vz+w31jKubzwPXDUUERsma0wosGRhQsb63UXMfDGNvp3b8Pi1o2xLUWNCiP1rNCEha/9Rpj+3ivaxkTw3fTTtYiKDHZIxxoslCxN0hUdLmPbsSo6XlvPcD0dzRnubeGdMqLFkYQJiW/5hLvzLR9z75lrSdu6npiHaxaXl3DQvlaz9x5h7vYf+Xdo2cqTGGH/Y0FkTEI99uJVd+4+y+8AxXl6ZRe9OrfnOqESuGtmdru1jAWcuxZ2vpJO68wD/+P4IxvSOD3LUxpiaWLIwDS77wFEWpu/h+nOSuevi/ixal8Pradn8afFmHn5/M+f2S+DqUYmk7djPf9fn8stvDuKyod2CHbYxphaWLEyDe+qT7QDcdF4v2kRHMMWTxBRPEjsLjvBGWjZvfLmb219eDcCN5/biJlty3JiQZ8nCNKiCw8dZsGoX3x7RnW4dYk96rWd8a+66eAA/ubA/KzILyNx3hO+P7hGkSI0xdWHJwjSoeZ/voLi0glvG11xbCAsTxvbtxNi+nRoxMmPM6bDRUKbBHD5exrzlO7k4pQt9O9uoJmOaE0sWpsEsWLmLomOlzJzQJ9ihGGMamCUL0yCOl5Xz5CeZnNM7nhE9OgY7HGNMA7NkYRrEv1fvYe/B41arMKaZsmRhTlt5hfLEx9sY3K0d5/WzTmtjmiNLFua0LcnIJTP/CDMn9LElxY1ppgKaLERksohsFpGtIjK7hjJTRCQvH5E+AAAZS0lEQVRDRDaIyPwqr7UTkd0i8o9AxmnqT1V5fNk2esa34htDugY7HGNMgARsnoWIhAOPARcB2cAqEVmoqhleZfoB9wLjVPWAiHSu8ja/BT4KVIzm9C3fVsCa7CL+cOWZhIdZrcKY5iqQNYvRwFZVzVTVEmABcEWVMjcDj6nqAQBVzat8QURGAV2A9wMYozlNj3+0jYS20Vw1snuwQzHGBJDPZCEis0SkPmMhuwNZXsfZ7jlv/YH+IvKZiKwQkcnuZ4YBDwP31ONzTSNZl13EJ1v2ceO5vYiJDA92OMaYAPKnGeoMnCakL4FngMVa0+YEJ6uuTaLqdRFAP2ACkAh8IiJDgGuBRaqaVVuHqYjMAGYA9Ohhaww1puLSch5ZuoW2MRH84Gy798Y0dz6Thar+UkR+BVwMTAf+ISKvAk+r6rZaLs0GkryOE4E91ZRZoaqlwHYR2YyTPM4BzhORW4E2QJSIHFbVkzrJVXUuMBfA4/H4k8BMPRWXlvPlrgOsyNzPim0FpGcVUlJewe2T+tLWtkA1ptnzq4NbVVVEcoFcoAzoCLwuIktU9ac1XLYK6CcivYDdwFTg+1XKvA1cAzwnIp1wmqUyVfUHlQVEZBrgqZooTOBt2XuId9bmsCKzgPRdTnIIEzize3umj0tmTO94xvdPCHaYxphG4DNZiMjtwA3APuAp4B5VLXX7FbYA1SYLVS0TkVnAYiAceEZVN4jIHCBVVRe6r10sIhlAufveBQ3xxczpySk6xlX//JwjJWUM6d6eaeOSGdM7Dk9yHO2sJmFMiyO+uh/cH/enVXVnNa8NUtWNgQquLjwej6ampgY7jGZBVZn+3Cq+yNzPojvOo1en1sEOyRgTICKSpqoeX+X8GTq7CNjv9cZtReRsgFBJFKZhvZaWzbLN+fxs8gBLFMYYwL9k8Thw2Ov4iHvONEM5Rcf47bsZjO4Vx/XnJAc7HGNMiPAnWYj3UFlVrcB22GuWVJWfv7mO0vIK/nT1UMJsRrYxxuVPssgUkdtFJNJ93AFkBjow0/je+HI3H27O52eTB9Iz3pqfjDFf8ydZ3AKMxRn+mg2cjTsRzjQfuUXF/OadDYxOjuMGa34yxlThz6S8PJw5EqaZUlV+/pbT/PSgNT8ZY6rhzzyLGOBGYDAQU3leVX8YwLhMI3pr9W6WbsrjV5el2OgnY0y1/GmGegFnfahLcJYLTwQOBTIo03jyDhZz/8INeHp2ZNrY5GCHY4wJUf4ki76q+ivgiKrOA74JnBnYsExjqGx+Ol5WwUNXD7X9KIwxNfInWZS6/y10V4RtDyQHLCLTaF5Py+Z/G/O455IB9E5oE+xwjDEhzJ/5EnPd/Sx+CSzEWQX2VwGNygTce+tzuffNdZzdK47p43oFOxxjTIirNVm4iwUedHey+xjo3ShRmYBavCGXWfO/5MzE9jx1g8ean4wxPtXaDOXO1p7VSLGYRrB4Qy63veQkink/HG17URhj/OJPn8USEblbRJJEJK7yEfDITIN7300UQ7o7icKWGjfG+MufPovK+RS3eZ1TrEmqSVmSsZfb5juJ4vkbLVEYY+rGnxnc1vvZxC3J2MutL6WR0s0ShTGmfvyZwX19dedV9fmGD8c0tP95JwprejLG1JM/zVBneT2PAS4AvgQsWYS4FZkFzHwpjZSu7Xj+h6NpH2uJwhhTP/40Q/3Y+1hE2uMsAWJCWEWFcv/CDXRtH8vzN55ticIYc1r8GQ1V1VGgnz8FRWSyiGwWka0iMruGMlNEJENENojIfPfccBFZ7p5bKyLfq0ecLdrCNXvYlHuIuy8ZYInCGHPa/OmzeAdn9BM4ySUFeNWP68KBx4CLcPbBWCUiC1U1w6tMP+BeYJyqHhCRzu5LR4HrVXWLiHQD0kRksaoW1uG7tVglZRU8vGQzKV3bcdmZXYMdjjGmGfCnz+LPXs/LgJ2qmu3HdaOBraqaCSAiC4ArgAyvMjcDj7kzxCv3zkBVv6osoKp7RCQPSAAsWfhhwapdZO0/xnPTh9jeFMaYBuFPstgF5KhqMYCIxIpIsqru8HFddyDL67hylz1v/d33/AwIB+5X1fe8C4jIaCAK2Fb1A0RkBu6ufT169PDjqzR/R46X8cgHWzm7Vxzj+ycEOxxjTDPhT5/Fa0CF13G5e86X6v6k1SrHETj9HxOAa4CnRKTDiTcQ6YrTmT7dXXrk5DdTnauqHlX1JCTYDyPAs59tZ9/h4/x08kBErFZhjGkY/iSLCFUtqTxwn0f5cV02kOR1nAjsqabMv1W1VFW3A5txO89FpB3wH+CXqrrCj89r8Q4cKeFfH2VyUUoXRvXsGOxwjDHNiD/JIl9ELq88EJErgH1+XLcK6CcivUQkCmcf74VVyrwNTHTftxNOs1SmW/4t4HlV9acWY4DHP9rGkZIy7rlkQLBDMcY0M/70WdwCvCQi/3CPs4FqZ3V7U9UyEZkFLMbpj3hGVTeIyBwgVVUXuq9dLCIZOM1b96hqgYhcC5wPxIvINPctp6lqel2+XEuSU3SM5z7fwVUjE+nfpW2wwzHGNDOiWrUboYaCIm3c8iG5/7bH49HU1NRghxE0s99Yy5tf7mbp3eNJ7Ngq2OEYY5oIEUlTVY+vcj6boUTkDyLSQVUPq+ohEekoIr9rmDBNQ9iad5hXU7O4dkxPSxTGmIDwp8/iG96T4dw5EZcGLiRTVw+/v5nYyHBum9gn2KEYY5opf5JFuIhEVx6ISCwQXUt504jWZBXy3/W53Hx+b+Lb2P8sxpjA8KeD+0XgAxF51j2eDswLXEimLh5avIm41lHcdJ7tRWWMCRx/Vp19SETWAhfiTLR7D+gZ6MCMb2k7D/DZ1gJ+dVkKbaL9yfvGGFM//q46m4szi/s7OPtZbAxYRMZv72fkEhkuTPEkBjsUY0wzV+OfoyLSH2ci3TVAAfAKztDZiY0Um/Fh6cY8RveKo63tfmeMCbDaahabcGoR31LVc1X1UZyJcyYEZO0/ypa8w0wa2CXYoRhjWoDaksV3cJqfPhSRJ0XkAqpfHNAEwdJNeQBMGtjZR0ljjDl9NSYLVX1LVb8HDASWAXcCXUTkcRG5uJHiMzX4YFMevTu1plen1sEOxRjTAvjs4FbVI6r6kqpehrNybDpQ7RappnEcOV7Gim0FTLRahTGmkdRpD25V3a+q/1LVSYEKyPj22dZ9lJRXcIElC2NMI6lTsjChYemmPNpER+BJjgt2KMaYFsKSRROjqizdlMf5/TsRFWH/8xljGof92jQxG/YcJO/QcRsya4xpVJYsmpilm/IQgQkDbM9xY0zjsWTRxHywKY9hiR3oZCvMGmMakSWLJiT/0HHWZBXaRDxjTKMLaLIQkckisllEtopItXMzRGSKiGSIyAYRme91/gYR2eI+bghknE3Fss02a9sYExwBW9daRMKBx4CLgGxglYgsVNUMrzL9gHuBcap6QEQ6u+fjgF8DHkCBNPfaA4GKtylYuimPLu2iGdytXbBDMca0MIGsWYwGtqpqpqqWAAuAK6qUuRl4rDIJqGqee/4SYIk7CfAAsASYHMBYQ15JWQWfbNnHpIGdEbEluowxjSuQyaI7kOV1nO2e89Yf6C8in4nIChGZXIdrEZEZIpIqIqn5+fkNGHroWbVjP4ePl9mQWWNMUAQyWVT3569WOY4A+gETcPbNeEpEOvh5Lao6V1U9qupJSGjeQ0k/2JhHVEQY4/rGBzsUY0wLFMhkkQ0keR0nAnuqKfNvVS1V1e3AZpzk4c+1LcqHm/M4p3c8raJs+1RjTOMLZLJYBfQTkV4iEoWz697CKmXeBiYCiEgnnGapTGAxcLGIdBSRjsDF7rkWKTP/MNv3HeGCQTYKyhgTHAH7M1VVy0RkFs6PfDjwjKpuEJE5QKqqLuTrpJCBswvfPapaACAiv8VJOABzVHV/oGINdZUbHU0cYMnCGBMconpKV0CT5PF4NDU1NdhhBMT3n1zBvsPHef/O8cEOxRjTzIhImqp6fJWzGdwh7mBxKSu377eNjowxQWXJIsR98tU+yiqUC2zIrDEmiCxZhLilm/JoHxvJyB4dgh2KMaYFs2QRwg4cKWHZ5jzG908gItz+pzLGBI/9AoWotJ0H+OYjn3CwuJSpZyX5vsAYYwLIZniFGFXlqU+28+B7m+jaIYY3Zo5laKI1QRljgsuSRQgpPFrC3a+t4X8b87hkcBceunoY7WMjgx2WMcZYsggVq3cdYNb81eQdKua+y1KYPi7ZVpc1xoQMSxZBpqo889kOHvjvRrq0i+G1W8YyPMmanYwxocWSRZDd8/paXk/L5qKULvz56mG0b2XNTsaY0GPJIojWZRfxelo2N5/Xi59fOsianYwxIcuGzgbREx9to21MBLdf0M8ShTEmpFmyCJLt+46waH0O143pSdsYa3oyxoQ2SxZBMvfjbUSGhzF9XK9gh2KMMT5ZsgiCvQeLeSNtN1M8iSS0jQ52OMYY45MliyB4+tPtlFVUMOO8PsEOxRhj/GLJopEVHS3lpRU7uWxoN3rEtwp2OMYY4xdLFo3shRU7OFJSzi3jrVZhjGk6AposRGSyiGwWka0iMrua16eJSL6IpLuPm7xee0hENojIRhF5RJrB2NJjJeU8+9kOJgxIIKVbu2CHY4wxfgvYpDwRCQceAy4CsoFVIrJQVTOqFH1FVWdVuXYsMA4Y6p76FBgPLAtUvI3htbQsCo6UcOuEvsEOxRhj6iSQNYvRwFZVzVTVEmABcIWf1yoQA0QB0UAksDcgUTaS0vIK/vVRJqN6duSs5I7BDscYY+okkMmiO5DldZztnqvqOyKyVkReF5EkAFVdDnwI5LiPxaq6seqFIjJDRFJFJDU/P7/hv0ED+s/aHHYXHmPm+D42W9sY0+QEMllU94uoVY7fAZJVdSjwP2AegIj0BQYBiTgJZpKInH/Km6nOVVWPqnoSEhIaNPiGpKo8vmwb/bu0YdLAzsEOxxhj6iyQySIb8N4PNBHY411AVQtU9bh7+CQwyn1+JbBCVQ+r6mHgv8CYAMYaUEs35bF57yFuGd+HsDCrVRhjmp5AJotVQD8R6SUiUcBUYKF3ARHp6nV4OVDZ1LQLGC8iESISidO5fUozVFPx+LJtdO8Qy7eGdQt2KMYYUy8BGw2lqmUiMgtYDIQDz6jqBhGZA6Sq6kLgdhG5HCgD9gPT3MtfByYB63Cart5T1XcCFWsgrdqxn9SdB7j/WylEhtu0FmNM0ySqVbsRmiaPx6OpqanBDuMkB46UcM2TK9h7sJjPZk+iVZRtH2KMCS0ikqaqHl/l7NcrQA4cKeEHT31B5r4jPHm9xxKFMaZJs3aRACg8WsK1T3/B1vzDzL1uFOP7h+5ILWOM8YcliwZWeNSpUWzZ6ySKCQNsqKwxpumzZNGAKmsUW/Ye5l/XW6IwxjQfliwaSGWi+CrXSRQTLVEYY5oRSxYNoOho6deJ4jpLFMaY5seG6PhQUaF8tCWf46Xl1b6uCv9cto2vcg/zxHUjmWjLeRhjmiFLFj4sWp/DrPmray0TFR7G49eOZNLALo0UlTHGNC5LFj68uyaHzm2jeW76aGpaLLZTm2gS2kY3bmDGGNOILFnU4sjxMj7cnMfUs5JsZztjTItmHdy1WLopj+NlFVx6ZlffhY0xphmzZFGLRetySGgbjSc5LtihGGNMUFmyqMHREqcJ6htDziDc9qAwxrRwlixqsHRTHsWl1gRljDFgyaJG/1mbQ6c20ZxlTVDGGGPJojqVTVCXnmlNUMYYA5YsqmVNUMYYczJLFtVYtM6aoIwxxltAk4WITBaRzSKyVURmV/P6NBHJF5F093GT12s9ROR9EdkoIhkikhzIWCsdLSlj6SYbBWWMMd4CNoNbRMKBx4CLgGxglYgsVNWMKkVfUdVZ1bzF88DvVXWJiLQBKgIVq7cPN+VbE5QxxlQRyJrFaGCrqmaqagmwALjCnwtFJAWIUNUlAKp6WFWPBi7Ur1U2QY3uZU1QxhhTKZDJojuQ5XWc7Z6r6jsislZEXheRJPdcf6BQRN4UkdUi8ie3phJQx0rKWbopj8lDulgTlDHGeAlksqju11arHL8DJKvqUOB/wDz3fARwHnA3cBbQG5h2ygeIzBCRVBFJzc/PP+2AP9ycx7HScmuCMsaYKgKZLLKBJK/jRGCPdwFVLVDV4+7hk8Aor2tXu01YZcDbwMiqH6Cqc1XVo6qehISE0w74P+ty6NQmirN7xZ/2exljTHMSyGSxCugnIr1EJAqYCiz0LiAi3n/CXw5s9Lq2o4hUZoBJQNWO8QZ1rKScpRvzuGSwjYIyxpiqAjYaSlXLRGQWsBgIB55R1Q0iMgdIVdWFwO0icjlQBuzHbWpS1XIRuRv4QEQESMOpeQRMZRPUN60JyhhjThHQzY9UdRGwqMq5+7ye3wvcW8O1S4ChgYzP23/W5RDfOspGQRljTDVsBjdeTVBDziAi3G6JMcZUZb+MwDJrgjLGmFpZssBpgoprHcXZ1gRljDHVavHJorjUmYh3yWBrgjLGmJq0+F/Hg8dKuXBQF64Y3i3YoRhjTMgK6GiopqBzuxgeuWZEsMMwxpiQ1uJrFsYYY3yzZGGMMcYnSxbGGGN8smRhjDHGJ0sWxhhjfLJkYYwxxidLFsYYY3yyZGGMMcYnUa2602nTJCL5wM7TeItOwL4GCqehWWz1Y7HVj8VWP001tp6q6nOr0WaTLE6XiKSqqifYcVTHYqsfi61+LLb6ae6xWTOUMcYYnyxZGGOM8cmSxdfmBjuAWlhs9WOx1Y/FVj/NOjbrszDGGOOT1SyMMcb4ZMnCGGOMTy0+WYjIZBHZLCJbRWR2sOPxJiI7RGSdiKSLSGoIxPOMiOSJyHqvc3EiskREtrj/7Rgicd0vIrvde5cuIpc2dlxuHEki8qGIbBSRDSJyh3s+FO5bTbEF/d6JSIyIrBSRNW5sv3HP9xKRL9z79oqIRIVQbM+JyHav+za8sWPzijFcRFaLyLvu8enfN1VtsQ8gHNgG9AaigDVASrDj8opvB9Ap2HF4xXM+MBJY73XuIWC2+3w28GCIxHU/cHcI3LOuwEj3eVvgKyAlRO5bTbEF/d4BArRxn0cCXwBjgFeBqe75J4CZIRTbc8DVwf7/nBvXXcB84F33+LTvW0uvWYwGtqpqpqqWAAuAK4IcU8hS1Y+B/VVOXwHMc5/PA77dqEFRY1whQVVzVPVL9/khYCPQndC4bzXFFnTqOOweRroPBSYBr7vng3XfaootJIhIIvBN4Cn3WGiA+9bSk0V3IMvrOJsQ+cfiUuB9EUkTkRnBDqYGXVQ1B5wfH6BzkOPxNktE1rrNVI3ezFOViCQDI3D+Eg2p+1YlNgiBe+c2paQDecASnFaAQlUtc4sE7d9r1dhUtfK+/d69b38VkehgxAb8DfgpUOEex9MA962lJwup5lzI/IUAjFPVkcA3gNtE5PxgB9SEPA70AYYDOcDDwQxGRNoAbwA/UdWDwYylqmpiC4l7p6rlqjocSMRpBRhUXbHGjcr90CqxicgQ4F5gIHAWEAf8rLHjEpHLgDxVTfM+XU3ROt+3lp4ssoEkr+NEYE+QYjmFqu5x/5sHvIXzDybU7BWRrgDuf/OCHA8AqrrX/QddATxJEO+diETi/Bi/pKpvuqdD4r5VF1so3Ts3nkJgGU6/QAcRiXBfCvq/V6/YJrvNeqqqx4FnCc59GwdcLiI7cJrVJ+HUNE77vrX0ZLEK6OeOFIgCpgILgxwTACLSWkTaVj4HLgbW135VUCwEbnCf3wD8O4ixnFD5Q+y6kiDdO7e9+Glgo6r+xeuloN+3mmILhXsnIgki0sF9HgtciNOn8iFwtVssWPetutg2eSV/wekTaPT7pqr3qmqiqibj/J4tVdUf0BD3Ldi99sF+AJfijALZBvwi2PF4xdUbZ3TWGmBDKMQGvIzTLFGKUyu7Eac99ANgi/vfuBCJ6wVgHbAW54e5a5Du2bk4Vf61QLr7uDRE7ltNsQX93gFDgdVuDOuB+9zzvYGVwFbgNSA6hGJb6t639cCLuCOmgvUAJvD1aKjTvm+23IcxxhifWnozlDHGGD9YsjDGGOOTJQtjjDE+WbIwxhjjkyULY4wxPlmyMKYORKTca1XRdGnAlYpFJNl75VxjQkmE7yLGGC/H1FnmwZgWxWoWxjQAcfYeedDd52CliPR1z/cUkQ/cxeU+EJEe7vkuIvKWuyfCGhEZ675VuIg86e6T8L47Q9iYoLNkYUzdxFZphvqe12sHVXU08A+c9Xhwnz+vqkOBl4BH3POPAB+p6jCcvTg2uOf7AY+p6mCgEPhOgL+PMX6xGdzG1IGIHFbVNtWc3wFMUtVMd3G+XFWNF5F9OMtllLrnc1S1k4jkA4nqLDpX+R7JOMtd93OPfwZEqurvAv/NjKmd1SyMaThaw/OaylTnuNfzcqxf0YQISxbGNJzvef13ufv8c5zVPwF+AHzqPv8AmAknNtJp11hBGlMf9leLMXUT6+6QVuk9Va0cPhstIl/g/BF2jXvuduAZEbkHyAemu+fvAOaKyI04NYiZOCvnGhOSrM/CmAbg9ll4VHVfsGMxJhCsGcoYY4xPVrMwxhjjk9UsjDHG+GTJwhhjjE+WLIwxxvhkycIYY4xPliyMMcb49P+HATODdw0MLAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "# from keras import regularizers kernel_regularizer=regularizers.l2(0.01), \n",
    "from keras.optimizers import Adam\n",
    "\n",
    "network = models.Sequential()\n",
    "\n",
    "network.add(layers.Dense(16, input_shape=(8,)))\n",
    "network.add(layers.Dense(32, activation=\"relu\"))\n",
    "network.add(layers.Dense(64, activation=\"relu\"))\n",
    "network.add(layers.Dense(32, activation=\"relu\"))\n",
    "network.add(layers.Dense(32, activation=\"relu\"))\n",
    "network.add(layers.Dense(16, activation=\"sigmoid\"))\n",
    "network.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Adam = Adam(lr=0.05)\n",
    "network.compile(optimizer=Adam(lr=0.0004),\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['acc'])\n",
    "\n",
    "network.summary()\n",
    "\n",
    "history = network.fit(x_train, y_train,\n",
    "                      epochs=40, verbose=1, batch_size=3)\n",
    "\n",
    "loss_and_metrics = network.evaluate(x_test, y_test)\n",
    "print('loss and metrics', loss_and_metrics)\n",
    "\n",
    "# print('prediction: ', network.predict(test_data))\n",
    "\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "all_labels = dataDF.action.values\n",
    "\n",
    "encoder = LabelBinarizer()\n",
    "all_labels = encoder.fit_transform(all_labels)\n",
    "    \n",
    "# create an array of shape 30706, 9 = number of records by the features\n",
    "all_data = np.array([[0 for x in range(8)] for y in range(len(dataDF))])\n",
    "for i in range(len(dataDF)):\n",
    "    all_data[i] = [dataDF.delta.values[i],\n",
    "                       dataDF.theta.values[i],\n",
    "                       dataDF.alphaLow.values[i],\n",
    "                       dataDF.alphaHigh.values[i],\n",
    "                       dataDF.betaLow.values[i],\n",
    "                       dataDF.betaHigh.values[i],\n",
    "                       dataDF.gammaLow.values[i],\n",
    "                       dataDF.gammaMid.values[i]]\n",
    "    \n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "scaler = MinMaxScaler()\n",
    "stan_scaler = StandardScaler()\n",
    "\n",
    "all_data = scaler.fit_transform(all_data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold 1/10.............................................\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 5,425\n",
      "Trainable params: 5,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1335 samples, validate on 334 samples\n",
      "Epoch 1/40\n",
      "1335/1335 [==============================] - 2s 1ms/step - loss: 0.6628 - acc: 0.6352 - val_loss: 1.0159 - val_acc: 0.0000e+00\n",
      "Epoch 2/40\n",
      "1335/1335 [==============================] - 1s 606us/step - loss: 0.6474 - acc: 0.6412 - val_loss: 0.9422 - val_acc: 0.1497\n",
      "Epoch 3/40\n",
      "1335/1335 [==============================] - 1s 685us/step - loss: 0.6428 - acc: 0.6569 - val_loss: 0.9218 - val_acc: 0.1527\n",
      "Epoch 4/40\n",
      "1335/1335 [==============================] - 1s 763us/step - loss: 0.6402 - acc: 0.6607 - val_loss: 0.9141 - val_acc: 0.1527\n",
      "Epoch 5/40\n",
      "1335/1335 [==============================] - 1s 644us/step - loss: 0.6393 - acc: 0.6599 - val_loss: 0.9070 - val_acc: 0.1527\n",
      "Epoch 6/40\n",
      "1335/1335 [==============================] - 1s 590us/step - loss: 0.6379 - acc: 0.6592 - val_loss: 0.9163 - val_acc: 0.1527\n",
      "Epoch 7/40\n",
      "1335/1335 [==============================] - 1s 569us/step - loss: 0.6380 - acc: 0.6599 - val_loss: 0.9182 - val_acc: 0.1527\n",
      "Epoch 8/40\n",
      "1335/1335 [==============================] - 1s 574us/step - loss: 0.6365 - acc: 0.6599 - val_loss: 0.9154 - val_acc: 0.1587\n",
      "Epoch 9/40\n",
      "1335/1335 [==============================] - 1s 618us/step - loss: 0.6360 - acc: 0.6607 - val_loss: 0.9268 - val_acc: 0.1527\n",
      "Epoch 10/40\n",
      "1335/1335 [==============================] - 1s 627us/step - loss: 0.6353 - acc: 0.6584 - val_loss: 0.9189 - val_acc: 0.1587\n",
      "Epoch 11/40\n",
      "1335/1335 [==============================] - 1s 617us/step - loss: 0.6341 - acc: 0.6599 - val_loss: 0.9272 - val_acc: 0.1587\n",
      "Epoch 12/40\n",
      "1335/1335 [==============================] - 1s 618us/step - loss: 0.6328 - acc: 0.6607 - val_loss: 0.9943 - val_acc: 0.1527\n",
      "Epoch 13/40\n",
      "1335/1335 [==============================] - 1s 600us/step - loss: 0.6312 - acc: 0.6592 - val_loss: 1.0141 - val_acc: 0.1497\n",
      "Epoch 14/40\n",
      "1335/1335 [==============================] - 1s 622us/step - loss: 0.6294 - acc: 0.6592 - val_loss: 0.9748 - val_acc: 0.1557\n",
      "Epoch 15/40\n",
      "1335/1335 [==============================] - 1s 627us/step - loss: 0.6284 - acc: 0.6599 - val_loss: 0.8758 - val_acc: 0.1617\n",
      "Epoch 16/40\n",
      "1335/1335 [==============================] - 1s 704us/step - loss: 0.6254 - acc: 0.6622 - val_loss: 0.8547 - val_acc: 0.1587\n",
      "Epoch 17/40\n",
      "1335/1335 [==============================] - 1s 621us/step - loss: 0.6248 - acc: 0.6622 - val_loss: 0.8422 - val_acc: 0.1737\n",
      "Epoch 18/40\n",
      "1335/1335 [==============================] - 1s 636us/step - loss: 0.6217 - acc: 0.6689 - val_loss: 0.9151 - val_acc: 0.1587\n",
      "Epoch 19/40\n",
      "1335/1335 [==============================] - 1s 604us/step - loss: 0.6184 - acc: 0.6607 - val_loss: 0.9493 - val_acc: 0.1587\n",
      "Epoch 20/40\n",
      "1335/1335 [==============================] - 1s 637us/step - loss: 0.6162 - acc: 0.6592 - val_loss: 0.8077 - val_acc: 0.4611\n",
      "Epoch 21/40\n",
      "1335/1335 [==============================] - 1s 609us/step - loss: 0.6162 - acc: 0.6667 - val_loss: 0.9013 - val_acc: 0.1587\n",
      "Epoch 22/40\n",
      "1335/1335 [==============================] - 1s 625us/step - loss: 0.6134 - acc: 0.6562 - val_loss: 0.8070 - val_acc: 0.2216\n",
      "Epoch 23/40\n",
      "1335/1335 [==============================] - 1s 627us/step - loss: 0.6118 - acc: 0.6652 - val_loss: 0.8878 - val_acc: 0.1557\n",
      "Epoch 24/40\n",
      "1335/1335 [==============================] - 1s 622us/step - loss: 0.6127 - acc: 0.6667 - val_loss: 0.8178 - val_acc: 0.1766\n",
      "Epoch 25/40\n",
      "1335/1335 [==============================] - 1s 683us/step - loss: 0.6092 - acc: 0.6652 - val_loss: 0.9434 - val_acc: 0.1737\n",
      "Epoch 26/40\n",
      "1335/1335 [==============================] - 1s 619us/step - loss: 0.6091 - acc: 0.6652 - val_loss: 0.8311 - val_acc: 0.4521\n",
      "Epoch 27/40\n",
      "1335/1335 [==============================] - 1s 615us/step - loss: 0.6073 - acc: 0.6734 - val_loss: 0.7523 - val_acc: 0.5659\n",
      "Epoch 28/40\n",
      "1335/1335 [==============================] - 1s 625us/step - loss: 0.6075 - acc: 0.6719 - val_loss: 0.7173 - val_acc: 0.5689\n",
      "Epoch 29/40\n",
      "1335/1335 [==============================] - 1s 604us/step - loss: 0.6048 - acc: 0.6809 - val_loss: 0.8572 - val_acc: 0.1796\n",
      "Epoch 30/40\n",
      "1335/1335 [==============================] - 1s 553us/step - loss: 0.6039 - acc: 0.6824 - val_loss: 0.7394 - val_acc: 0.5240\n",
      "Epoch 31/40\n",
      "1335/1335 [==============================] - 1s 472us/step - loss: 0.6041 - acc: 0.6719 - val_loss: 0.8804 - val_acc: 0.1766\n",
      "Epoch 32/40\n",
      "1335/1335 [==============================] - 1s 590us/step - loss: 0.6001 - acc: 0.6734 - val_loss: 0.7883 - val_acc: 0.4880\n",
      "Epoch 33/40\n",
      "1335/1335 [==============================] - 1s 632us/step - loss: 0.6026 - acc: 0.6809 - val_loss: 0.7866 - val_acc: 0.5569\n",
      "Epoch 34/40\n",
      "1335/1335 [==============================] - 1s 627us/step - loss: 0.5989 - acc: 0.6749 - val_loss: 0.8073 - val_acc: 0.4641\n",
      "Epoch 35/40\n",
      "1335/1335 [==============================] - 1s 680us/step - loss: 0.5999 - acc: 0.6764 - val_loss: 0.7563 - val_acc: 0.5449\n",
      "Epoch 36/40\n",
      "1335/1335 [==============================] - 1s 644us/step - loss: 0.5970 - acc: 0.6727 - val_loss: 0.6935 - val_acc: 0.6138\n",
      "Epoch 37/40\n",
      "1335/1335 [==============================] - 1s 661us/step - loss: 0.5988 - acc: 0.6854 - val_loss: 0.7940 - val_acc: 0.4910\n",
      "Epoch 38/40\n",
      "1335/1335 [==============================] - 1s 624us/step - loss: 0.5971 - acc: 0.6839 - val_loss: 0.7723 - val_acc: 0.5120\n",
      "Epoch 39/40\n",
      "1335/1335 [==============================] - 1s 631us/step - loss: 0.5971 - acc: 0.6764 - val_loss: 0.6944 - val_acc: 0.5719\n",
      "Epoch 40/40\n",
      "1335/1335 [==============================] - 1s 597us/step - loss: 0.5957 - acc: 0.6929 - val_loss: 0.7827 - val_acc: 0.2904\n",
      "187/187 [==============================] - 0s 34us/step\n",
      "Average accuracy of model on the dev set =  0.4973262032483988\n",
      "Training on fold 2/10.............................................\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 5,425\n",
      "Trainable params: 5,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1335 samples, validate on 334 samples\n",
      "Epoch 1/40\n",
      "1335/1335 [==============================] - 2s 1ms/step - loss: 0.6618 - acc: 0.6187 - val_loss: 0.9683 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/40\n",
      "1335/1335 [==============================] - 1s 685us/step - loss: 0.6461 - acc: 0.6352 - val_loss: 0.9476 - val_acc: 0.0000e+00\n",
      "Epoch 3/40\n",
      "1335/1335 [==============================] - 1s 728us/step - loss: 0.6424 - acc: 0.6360 - val_loss: 0.9159 - val_acc: 0.0359\n",
      "Epoch 4/40\n",
      "1335/1335 [==============================] - 1s 678us/step - loss: 0.6394 - acc: 0.6479 - val_loss: 0.9210 - val_acc: 0.1198\n",
      "Epoch 5/40\n",
      "1335/1335 [==============================] - 1s 641us/step - loss: 0.6359 - acc: 0.6599 - val_loss: 0.8713 - val_acc: 0.1497\n",
      "Epoch 6/40\n",
      "1335/1335 [==============================] - 1s 613us/step - loss: 0.6330 - acc: 0.6599 - val_loss: 0.8420 - val_acc: 0.1766\n",
      "Epoch 7/40\n",
      "1335/1335 [==============================] - 1s 604us/step - loss: 0.6327 - acc: 0.6614 - val_loss: 0.8886 - val_acc: 0.1557\n",
      "Epoch 8/40\n",
      "1335/1335 [==============================] - 1s 700us/step - loss: 0.6299 - acc: 0.6607 - val_loss: 0.8766 - val_acc: 0.1497\n",
      "Epoch 9/40\n",
      "1335/1335 [==============================] - 1s 674us/step - loss: 0.6288 - acc: 0.6607 - val_loss: 0.9065 - val_acc: 0.1557\n",
      "Epoch 10/40\n",
      "1335/1335 [==============================] - 1s 666us/step - loss: 0.6273 - acc: 0.6607 - val_loss: 0.8602 - val_acc: 0.1557\n",
      "Epoch 11/40\n",
      "1335/1335 [==============================] - 1s 690us/step - loss: 0.6264 - acc: 0.6629 - val_loss: 0.9244 - val_acc: 0.1557\n",
      "Epoch 12/40\n",
      "1335/1335 [==============================] - 1s 717us/step - loss: 0.6240 - acc: 0.6614 - val_loss: 0.8430 - val_acc: 0.1707\n",
      "Epoch 13/40\n",
      "1335/1335 [==============================] - 1s 707us/step - loss: 0.6229 - acc: 0.6629 - val_loss: 0.8734 - val_acc: 0.1707\n",
      "Epoch 14/40\n",
      "1335/1335 [==============================] - 1s 810us/step - loss: 0.6203 - acc: 0.6622 - val_loss: 0.8429 - val_acc: 0.1707\n",
      "Epoch 15/40\n",
      "1335/1335 [==============================] - 1s 706us/step - loss: 0.6171 - acc: 0.6622 - val_loss: 0.8663 - val_acc: 0.1707\n",
      "Epoch 16/40\n",
      "1335/1335 [==============================] - 1s 763us/step - loss: 0.6143 - acc: 0.6659 - val_loss: 0.7525 - val_acc: 0.1707\n",
      "Epoch 17/40\n",
      "1335/1335 [==============================] - 1s 587us/step - loss: 0.6126 - acc: 0.6622 - val_loss: 0.8407 - val_acc: 0.1707\n",
      "Epoch 18/40\n",
      "1335/1335 [==============================] - 1s 579us/step - loss: 0.6087 - acc: 0.6659 - val_loss: 0.7655 - val_acc: 0.2575\n",
      "Epoch 19/40\n",
      "1335/1335 [==============================] - 1s 605us/step - loss: 0.6073 - acc: 0.6816 - val_loss: 0.7675 - val_acc: 0.2695\n",
      "Epoch 20/40\n",
      "1335/1335 [==============================] - 1s 622us/step - loss: 0.6072 - acc: 0.6742 - val_loss: 0.7849 - val_acc: 0.2545\n",
      "Epoch 21/40\n",
      "1335/1335 [==============================] - 1s 624us/step - loss: 0.6038 - acc: 0.6779 - val_loss: 0.7705 - val_acc: 0.5599\n",
      "Epoch 22/40\n",
      "1335/1335 [==============================] - 1s 678us/step - loss: 0.6027 - acc: 0.6809 - val_loss: 0.7390 - val_acc: 0.6437\n",
      "Epoch 23/40\n",
      "1335/1335 [==============================] - 1s 643us/step - loss: 0.6004 - acc: 0.6884 - val_loss: 0.7704 - val_acc: 0.3263\n",
      "Epoch 24/40\n",
      "1335/1335 [==============================] - 1s 625us/step - loss: 0.6017 - acc: 0.6959 - val_loss: 0.7585 - val_acc: 0.5808\n",
      "Epoch 25/40\n",
      "1335/1335 [==============================] - 1s 623us/step - loss: 0.5979 - acc: 0.6936 - val_loss: 0.7398 - val_acc: 0.6377\n",
      "Epoch 26/40\n",
      "1335/1335 [==============================] - 1s 606us/step - loss: 0.5979 - acc: 0.6974 - val_loss: 0.7277 - val_acc: 0.6557\n",
      "Epoch 27/40\n",
      "1335/1335 [==============================] - 1s 589us/step - loss: 0.5950 - acc: 0.6996 - val_loss: 0.7106 - val_acc: 0.6108\n",
      "Epoch 28/40\n",
      "1335/1335 [==============================] - 1s 680us/step - loss: 0.5931 - acc: 0.6936 - val_loss: 0.5740 - val_acc: 0.7725\n",
      "Epoch 29/40\n",
      "1335/1335 [==============================] - 1s 689us/step - loss: 0.5950 - acc: 0.6951 - val_loss: 0.6985 - val_acc: 0.6587\n",
      "Epoch 30/40\n",
      "1335/1335 [==============================] - 1s 671us/step - loss: 0.5928 - acc: 0.6974 - val_loss: 0.7671 - val_acc: 0.5868\n",
      "Epoch 31/40\n",
      "1335/1335 [==============================] - 1s 635us/step - loss: 0.5934 - acc: 0.7056 - val_loss: 0.7486 - val_acc: 0.5629\n",
      "Epoch 32/40\n",
      "1335/1335 [==============================] - 1s 653us/step - loss: 0.5892 - acc: 0.6989 - val_loss: 0.7525 - val_acc: 0.6018\n",
      "Epoch 33/40\n",
      "1335/1335 [==============================] - 1s 628us/step - loss: 0.5898 - acc: 0.7041 - val_loss: 0.6317 - val_acc: 0.7246\n",
      "Epoch 34/40\n",
      "1335/1335 [==============================] - 1s 638us/step - loss: 0.5870 - acc: 0.7041 - val_loss: 0.7309 - val_acc: 0.6198\n",
      "Epoch 35/40\n",
      "1335/1335 [==============================] - 1s 671us/step - loss: 0.5888 - acc: 0.7034 - val_loss: 0.7334 - val_acc: 0.6497\n",
      "Epoch 36/40\n",
      "1335/1335 [==============================] - 1s 619us/step - loss: 0.5852 - acc: 0.7056 - val_loss: 0.7696 - val_acc: 0.6168\n",
      "Epoch 37/40\n",
      "1335/1335 [==============================] - 1s 704us/step - loss: 0.5852 - acc: 0.7116 - val_loss: 0.7051 - val_acc: 0.6467\n",
      "Epoch 38/40\n",
      "1335/1335 [==============================] - 1s 646us/step - loss: 0.5840 - acc: 0.7154 - val_loss: 0.7883 - val_acc: 0.6138\n",
      "Epoch 39/40\n",
      "1335/1335 [==============================] - 1s 641us/step - loss: 0.5850 - acc: 0.7094 - val_loss: 0.6863 - val_acc: 0.6527\n",
      "Epoch 40/40\n",
      "1335/1335 [==============================] - 1s 655us/step - loss: 0.5844 - acc: 0.7079 - val_loss: 0.7415 - val_acc: 0.5689\n",
      "187/187 [==============================] - 0s 30us/step\n",
      "Average accuracy of model on the dev set =  0.4705882353339603\n",
      "Training on fold 3/10.............................................\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 5,425\n",
      "Trainable params: 5,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1335 samples, validate on 334 samples\n",
      "Epoch 1/40\n",
      "1335/1335 [==============================] - 2s 1ms/step - loss: 0.6566 - acc: 0.6352 - val_loss: 0.9717 - val_acc: 0.0000e+00\n",
      "Epoch 2/40\n",
      "1335/1335 [==============================] - 1s 711us/step - loss: 0.6429 - acc: 0.6479 - val_loss: 0.9858 - val_acc: 0.1317\n",
      "Epoch 3/40\n",
      "1335/1335 [==============================] - 1s 659us/step - loss: 0.6384 - acc: 0.6584 - val_loss: 0.8832 - val_acc: 0.1557\n",
      "Epoch 4/40\n",
      "1335/1335 [==============================] - 1s 608us/step - loss: 0.6359 - acc: 0.6607 - val_loss: 0.9180 - val_acc: 0.1557\n",
      "Epoch 5/40\n",
      "1335/1335 [==============================] - 1s 607us/step - loss: 0.6341 - acc: 0.6599 - val_loss: 0.9037 - val_acc: 0.1557\n",
      "Epoch 6/40\n",
      "1335/1335 [==============================] - 1s 652us/step - loss: 0.6330 - acc: 0.6614 - val_loss: 0.8682 - val_acc: 0.1557\n",
      "Epoch 7/40\n",
      "1335/1335 [==============================] - 1s 675us/step - loss: 0.6316 - acc: 0.6599 - val_loss: 0.9543 - val_acc: 0.1527\n",
      "Epoch 8/40\n",
      "1335/1335 [==============================] - 1s 717us/step - loss: 0.6327 - acc: 0.6592 - val_loss: 0.9003 - val_acc: 0.1557\n",
      "Epoch 9/40\n",
      "1335/1335 [==============================] - 1s 675us/step - loss: 0.6308 - acc: 0.6599 - val_loss: 0.8828 - val_acc: 0.1557\n",
      "Epoch 10/40\n",
      "1335/1335 [==============================] - 1s 695us/step - loss: 0.6297 - acc: 0.6599 - val_loss: 0.8679 - val_acc: 0.1557\n",
      "Epoch 11/40\n",
      "1335/1335 [==============================] - 1s 711us/step - loss: 0.6293 - acc: 0.6592 - val_loss: 0.8834 - val_acc: 0.1527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/40\n",
      "1335/1335 [==============================] - 1s 673us/step - loss: 0.6278 - acc: 0.6592 - val_loss: 0.8930 - val_acc: 0.1527\n",
      "Epoch 13/40\n",
      "1335/1335 [==============================] - 1s 689us/step - loss: 0.6267 - acc: 0.6607 - val_loss: 0.9168 - val_acc: 0.1527\n",
      "Epoch 14/40\n",
      "1335/1335 [==============================] - 1s 691us/step - loss: 0.6259 - acc: 0.6599 - val_loss: 0.8789 - val_acc: 0.1527\n",
      "Epoch 15/40\n",
      "1335/1335 [==============================] - 1s 772us/step - loss: 0.6233 - acc: 0.6644 - val_loss: 0.8926 - val_acc: 0.1527\n",
      "Epoch 16/40\n",
      "1335/1335 [==============================] - 1s 749us/step - loss: 0.6226 - acc: 0.6607 - val_loss: 0.8666 - val_acc: 0.1527\n",
      "Epoch 17/40\n",
      "1335/1335 [==============================] - 1s 643us/step - loss: 0.6212 - acc: 0.6674 - val_loss: 0.8951 - val_acc: 0.1557\n",
      "Epoch 18/40\n",
      "1335/1335 [==============================] - 1s 725us/step - loss: 0.6197 - acc: 0.6652 - val_loss: 0.8552 - val_acc: 0.1707s - loss: 0.6197 - acc: 0.665\n",
      "Epoch 19/40\n",
      "1335/1335 [==============================] - 1s 771us/step - loss: 0.6183 - acc: 0.6667 - val_loss: 0.8250 - val_acc: 0.1707\n",
      "Epoch 20/40\n",
      "1335/1335 [==============================] - 1s 734us/step - loss: 0.6167 - acc: 0.6674 - val_loss: 0.9203 - val_acc: 0.1557\n",
      "Epoch 21/40\n",
      "1335/1335 [==============================] - 1s 692us/step - loss: 0.6146 - acc: 0.6667 - val_loss: 0.8743 - val_acc: 0.1677\n",
      "Epoch 22/40\n",
      "1335/1335 [==============================] - 1s 825us/step - loss: 0.6125 - acc: 0.6689 - val_loss: 0.9031 - val_acc: 0.1557\n",
      "Epoch 23/40\n",
      "1335/1335 [==============================] - 1s 769us/step - loss: 0.6098 - acc: 0.6727 - val_loss: 0.8340 - val_acc: 0.1557\n",
      "Epoch 24/40\n",
      "1335/1335 [==============================] - 1s 735us/step - loss: 0.6093 - acc: 0.6644 - val_loss: 0.7512 - val_acc: 0.3353\n",
      "Epoch 25/40\n",
      "1335/1335 [==============================] - 1s 696us/step - loss: 0.6082 - acc: 0.6801 - val_loss: 0.7373 - val_acc: 0.5569\n",
      "Epoch 26/40\n",
      "1335/1335 [==============================] - 1s 575us/step - loss: 0.6048 - acc: 0.6824 - val_loss: 0.8661 - val_acc: 0.1766\n",
      "Epoch 27/40\n",
      "1335/1335 [==============================] - 1s 569us/step - loss: 0.6022 - acc: 0.6764 - val_loss: 0.7710 - val_acc: 0.5509\n",
      "Epoch 28/40\n",
      "1335/1335 [==============================] - 1s 562us/step - loss: 0.6040 - acc: 0.6891 - val_loss: 0.8678 - val_acc: 0.1737\n",
      "Epoch 29/40\n",
      "1335/1335 [==============================] - 1s 552us/step - loss: 0.6012 - acc: 0.6899 - val_loss: 0.7394 - val_acc: 0.6108\n",
      "Epoch 30/40\n",
      "1335/1335 [==============================] - 1s 558us/step - loss: 0.6019 - acc: 0.6772 - val_loss: 0.7689 - val_acc: 0.5120\n",
      "Epoch 31/40\n",
      "1335/1335 [==============================] - 1s 556us/step - loss: 0.5980 - acc: 0.6869 - val_loss: 0.6935 - val_acc: 0.7246\n",
      "Epoch 32/40\n",
      "1335/1335 [==============================] - 1s 602us/step - loss: 0.5984 - acc: 0.6801 - val_loss: 0.7382 - val_acc: 0.6168\n",
      "Epoch 33/40\n",
      "1335/1335 [==============================] - 1s 721us/step - loss: 0.5976 - acc: 0.6831 - val_loss: 0.7045 - val_acc: 0.6587\n",
      "Epoch 34/40\n",
      "1335/1335 [==============================] - 1s 558us/step - loss: 0.5994 - acc: 0.6876 - val_loss: 0.8584 - val_acc: 0.1707\n",
      "Epoch 35/40\n",
      "1335/1335 [==============================] - 1s 537us/step - loss: 0.5993 - acc: 0.6966 - val_loss: 0.7418 - val_acc: 0.6347\n",
      "Epoch 36/40\n",
      "1335/1335 [==============================] - 1s 642us/step - loss: 0.5965 - acc: 0.6929 - val_loss: 0.7856 - val_acc: 0.5150\n",
      "Epoch 37/40\n",
      "1335/1335 [==============================] - 1s 627us/step - loss: 0.5962 - acc: 0.6876 - val_loss: 0.6560 - val_acc: 0.7455\n",
      "Epoch 38/40\n",
      "1335/1335 [==============================] - 1s 666us/step - loss: 0.5966 - acc: 0.7011 - val_loss: 0.7279 - val_acc: 0.5868\n",
      "Epoch 39/40\n",
      "1335/1335 [==============================] - 1s 613us/step - loss: 0.5937 - acc: 0.6891 - val_loss: 0.8983 - val_acc: 0.1737\n",
      "Epoch 40/40\n",
      "1335/1335 [==============================] - 1s 612us/step - loss: 0.5940 - acc: 0.6929 - val_loss: 0.7479 - val_acc: 0.5868\n",
      "187/187 [==============================] - 0s 38us/step\n",
      "Average accuracy of model on the dev set =  0.4937611408996497\n",
      "Training on fold 4/10.............................................\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_26 (Dense)             (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 5,425\n",
      "Trainable params: 5,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1336 samples, validate on 335 samples\n",
      "Epoch 1/40\n",
      "1336/1336 [==============================] - 2s 2ms/step - loss: 0.6587 - acc: 0.6355 - val_loss: 0.9938 - val_acc: 0.0000e+00\n",
      "Epoch 2/40\n",
      "1336/1336 [==============================] - 1s 745us/step - loss: 0.6505 - acc: 0.6355 - val_loss: 0.9918 - val_acc: 0.0000e+00\n",
      "Epoch 3/40\n",
      "1336/1336 [==============================] - 1s 857us/step - loss: 0.6450 - acc: 0.6527 - val_loss: 1.0012 - val_acc: 0.1194\n",
      "Epoch 4/40\n",
      "1336/1336 [==============================] - 1s 767us/step - loss: 0.6421 - acc: 0.6572 - val_loss: 0.9315 - val_acc: 0.1493\n",
      "Epoch 5/40\n",
      "1336/1336 [==============================] - 1s 870us/step - loss: 0.6403 - acc: 0.6579 - val_loss: 0.9165 - val_acc: 0.1522\n",
      "Epoch 6/40\n",
      "1336/1336 [==============================] - 1s 774us/step - loss: 0.6391 - acc: 0.6572 - val_loss: 0.9382 - val_acc: 0.1522\n",
      "Epoch 7/40\n",
      "1336/1336 [==============================] - 1s 782us/step - loss: 0.6387 - acc: 0.6564 - val_loss: 0.9407 - val_acc: 0.1522\n",
      "Epoch 8/40\n",
      "1336/1336 [==============================] - 1s 695us/step - loss: 0.6378 - acc: 0.6579 - val_loss: 0.9539 - val_acc: 0.1522\n",
      "Epoch 9/40\n",
      "1336/1336 [==============================] - 1s 635us/step - loss: 0.6376 - acc: 0.6579 - val_loss: 0.9629 - val_acc: 0.1522\n",
      "Epoch 10/40\n",
      "1336/1336 [==============================] - 1s 557us/step - loss: 0.6367 - acc: 0.6579 - val_loss: 0.9841 - val_acc: 0.1463\n",
      "Epoch 11/40\n",
      "1336/1336 [==============================] - 1s 687us/step - loss: 0.6363 - acc: 0.6572 - val_loss: 0.9079 - val_acc: 0.1522\n",
      "Epoch 12/40\n",
      "1336/1336 [==============================] - 1s 776us/step - loss: 0.6351 - acc: 0.6587 - val_loss: 0.9270 - val_acc: 0.1522\n",
      "Epoch 13/40\n",
      "1336/1336 [==============================] - 1s 742us/step - loss: 0.6342 - acc: 0.6572 - val_loss: 0.9539 - val_acc: 0.1522\n",
      "Epoch 14/40\n",
      "1336/1336 [==============================] - 1s 659us/step - loss: 0.6342 - acc: 0.6572 - val_loss: 0.8976 - val_acc: 0.1672\n",
      "Epoch 15/40\n",
      "1336/1336 [==============================] - 1s 607us/step - loss: 0.6328 - acc: 0.6587 - val_loss: 0.9219 - val_acc: 0.1522\n",
      "Epoch 16/40\n",
      "1336/1336 [==============================] - 1s 626us/step - loss: 0.6322 - acc: 0.6602 - val_loss: 0.9374 - val_acc: 0.1522\n",
      "Epoch 17/40\n",
      "1336/1336 [==============================] - 1s 641us/step - loss: 0.6321 - acc: 0.6647 - val_loss: 0.9442 - val_acc: 0.1552\n",
      "Epoch 18/40\n",
      "1336/1336 [==============================] - 1s 573us/step - loss: 0.6304 - acc: 0.6639 - val_loss: 0.9164 - val_acc: 0.1672\n",
      "Epoch 19/40\n",
      "1336/1336 [==============================] - 1s 691us/step - loss: 0.6303 - acc: 0.6647 - val_loss: 0.9075 - val_acc: 0.1672\n",
      "Epoch 20/40\n",
      "1336/1336 [==============================] - 1s 694us/step - loss: 0.6291 - acc: 0.6639 - val_loss: 0.8970 - val_acc: 0.1552\n",
      "Epoch 21/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1336/1336 [==============================] - 1s 581us/step - loss: 0.6293 - acc: 0.6669 - val_loss: 0.9579 - val_acc: 0.1552\n",
      "Epoch 22/40\n",
      "1336/1336 [==============================] - 1s 551us/step - loss: 0.6287 - acc: 0.6632 - val_loss: 0.9141 - val_acc: 0.1672\n",
      "Epoch 23/40\n",
      "1336/1336 [==============================] - 1s 545us/step - loss: 0.6275 - acc: 0.6684 - val_loss: 0.9636 - val_acc: 0.1522\n",
      "Epoch 24/40\n",
      "1336/1336 [==============================] - 1s 744us/step - loss: 0.6265 - acc: 0.6669 - val_loss: 0.9056 - val_acc: 0.1701\n",
      "Epoch 25/40\n",
      "1336/1336 [==============================] - 1s 613us/step - loss: 0.6257 - acc: 0.6654 - val_loss: 0.9186 - val_acc: 0.1701\n",
      "Epoch 26/40\n",
      "1336/1336 [==============================] - 1s 609us/step - loss: 0.6253 - acc: 0.6669 - val_loss: 0.9371 - val_acc: 0.1701\n",
      "Epoch 27/40\n",
      "1336/1336 [==============================] - 1s 676us/step - loss: 0.6253 - acc: 0.6677 - val_loss: 0.8767 - val_acc: 0.1701\n",
      "Epoch 28/40\n",
      "1336/1336 [==============================] - 1s 653us/step - loss: 0.6227 - acc: 0.6699 - val_loss: 0.8451 - val_acc: 0.1731\n",
      "Epoch 29/40\n",
      "1336/1336 [==============================] - 1s 602us/step - loss: 0.6209 - acc: 0.6669 - val_loss: 1.0183 - val_acc: 0.1224\n",
      "Epoch 30/40\n",
      "1336/1336 [==============================] - 1s 646us/step - loss: 0.6231 - acc: 0.6684 - val_loss: 0.8714 - val_acc: 0.1731\n",
      "Epoch 31/40\n",
      "1336/1336 [==============================] - 1s 614us/step - loss: 0.6208 - acc: 0.6699 - val_loss: 0.8857 - val_acc: 0.1731\n",
      "Epoch 32/40\n",
      "1336/1336 [==============================] - 1s 682us/step - loss: 0.6196 - acc: 0.6654 - val_loss: 0.8037 - val_acc: 0.1761\n",
      "Epoch 33/40\n",
      "1336/1336 [==============================] - 1s 602us/step - loss: 0.6200 - acc: 0.6662 - val_loss: 0.8538 - val_acc: 0.1731\n",
      "Epoch 34/40\n",
      "1336/1336 [==============================] - 1s 709us/step - loss: 0.6183 - acc: 0.6684 - val_loss: 0.7810 - val_acc: 0.1791\n",
      "Epoch 35/40\n",
      "1336/1336 [==============================] - 1s 631us/step - loss: 0.6187 - acc: 0.6684 - val_loss: 0.9437 - val_acc: 0.1731\n",
      "Epoch 36/40\n",
      "1336/1336 [==============================] - 1s 608us/step - loss: 0.6170 - acc: 0.6699 - val_loss: 0.8829 - val_acc: 0.1731\n",
      "Epoch 37/40\n",
      "1336/1336 [==============================] - 1s 644us/step - loss: 0.6169 - acc: 0.6684 - val_loss: 0.9503 - val_acc: 0.1731\n",
      "Epoch 38/40\n",
      "1336/1336 [==============================] - 1s 622us/step - loss: 0.6158 - acc: 0.6684 - val_loss: 0.8806 - val_acc: 0.1672\n",
      "Epoch 39/40\n",
      "1336/1336 [==============================] - 1s 604us/step - loss: 0.6152 - acc: 0.6662 - val_loss: 0.8531 - val_acc: 0.1731\n",
      "Epoch 40/40\n",
      "1336/1336 [==============================] - 1s 771us/step - loss: 0.6135 - acc: 0.6692 - val_loss: 0.7653 - val_acc: 0.2388\n",
      "185/185 [==============================] - 0s 29us/step\n",
      "Average accuracy of model on the dev set =  0.5000505853138518\n",
      "Training on fold 5/10.............................................\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_32 (Dense)             (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 5,425\n",
      "Trainable params: 5,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1336 samples, validate on 335 samples\n",
      "Epoch 1/40\n",
      "1336/1336 [==============================] - 2s 2ms/step - loss: 0.7030 - acc: 0.5374 - val_loss: 1.0470 - val_acc: 0.0000e+00\n",
      "Epoch 2/40\n",
      "1336/1336 [==============================] - 1s 728us/step - loss: 0.6591 - acc: 0.6355 - val_loss: 0.9510 - val_acc: 0.0000e+00\n",
      "Epoch 3/40\n",
      "1336/1336 [==============================] - 1s 807us/step - loss: 0.6569 - acc: 0.6355 - val_loss: 0.9785 - val_acc: 0.0000e+00\n",
      "Epoch 4/40\n",
      "1336/1336 [==============================] - 1s 757us/step - loss: 0.6553 - acc: 0.6355 - val_loss: 0.9437 - val_acc: 0.0000e+00\n",
      "Epoch 5/40\n",
      "1336/1336 [==============================] - 1s 791us/step - loss: 0.6547 - acc: 0.6355 - val_loss: 1.0430 - val_acc: 0.0000e+00\n",
      "Epoch 6/40\n",
      "1336/1336 [==============================] - 1s 868us/step - loss: 0.6545 - acc: 0.6355 - val_loss: 0.9854 - val_acc: 0.0000e+00\n",
      "Epoch 7/40\n",
      "1336/1336 [==============================] - 1s 680us/step - loss: 0.6528 - acc: 0.6355 - val_loss: 0.9347 - val_acc: 0.0000e+00\n",
      "Epoch 8/40\n",
      "1336/1336 [==============================] - 1s 586us/step - loss: 0.6525 - acc: 0.6362 - val_loss: 0.9606 - val_acc: 0.0746\n",
      "Epoch 9/40\n",
      "1336/1336 [==============================] - 1s 574us/step - loss: 0.6509 - acc: 0.6370 - val_loss: 1.0167 - val_acc: 0.0746\n",
      "Epoch 10/40\n",
      "1336/1336 [==============================] - 1s 671us/step - loss: 0.6497 - acc: 0.6392 - val_loss: 1.0470 - val_acc: 0.0746\n",
      "Epoch 11/40\n",
      "1336/1336 [==============================] - 1s 608us/step - loss: 0.6498 - acc: 0.6392 - val_loss: 0.9802 - val_acc: 0.1045\n",
      "Epoch 12/40\n",
      "1336/1336 [==============================] - 1s 674us/step - loss: 0.6490 - acc: 0.6430 - val_loss: 0.9618 - val_acc: 0.1343\n",
      "Epoch 13/40\n",
      "1336/1336 [==============================] - 1s 710us/step - loss: 0.6481 - acc: 0.6385 - val_loss: 0.8917 - val_acc: 0.1403\n",
      "Epoch 14/40\n",
      "1336/1336 [==============================] - 1s 588us/step - loss: 0.6493 - acc: 0.6445 - val_loss: 0.9855 - val_acc: 0.1075\n",
      "Epoch 15/40\n",
      "1336/1336 [==============================] - 1s 632us/step - loss: 0.6486 - acc: 0.6452 - val_loss: 0.9886 - val_acc: 0.1134\n",
      "Epoch 16/40\n",
      "1336/1336 [==============================] - 1s 646us/step - loss: 0.6473 - acc: 0.6430 - val_loss: 0.9757 - val_acc: 0.1403\n",
      "Epoch 17/40\n",
      "1336/1336 [==============================] - 1s 619us/step - loss: 0.6479 - acc: 0.6422 - val_loss: 0.9273 - val_acc: 0.1403\n",
      "Epoch 18/40\n",
      "1336/1336 [==============================] - 1s 621us/step - loss: 0.6475 - acc: 0.6415 - val_loss: 0.9572 - val_acc: 0.1403\n",
      "Epoch 19/40\n",
      "1336/1336 [==============================] - 1s 626us/step - loss: 0.6469 - acc: 0.6422 - val_loss: 0.9263 - val_acc: 0.1433\n",
      "Epoch 20/40\n",
      "1336/1336 [==============================] - 1s 585us/step - loss: 0.6466 - acc: 0.6437 - val_loss: 0.9604 - val_acc: 0.1433\n",
      "Epoch 21/40\n",
      "1336/1336 [==============================] - 1s 685us/step - loss: 0.6463 - acc: 0.6452 - val_loss: 0.9474 - val_acc: 0.1433\n",
      "Epoch 22/40\n",
      "1336/1336 [==============================] - 1s 626us/step - loss: 0.6457 - acc: 0.6452 - val_loss: 0.9504 - val_acc: 0.1433\n",
      "Epoch 23/40\n",
      "1336/1336 [==============================] - 1s 801us/step - loss: 0.6455 - acc: 0.6467 - val_loss: 0.9172 - val_acc: 0.1493\n",
      "Epoch 24/40\n",
      "1336/1336 [==============================] - 1s 620us/step - loss: 0.6451 - acc: 0.6437 - val_loss: 0.9599 - val_acc: 0.1433\n",
      "Epoch 25/40\n",
      "1336/1336 [==============================] - 1s 713us/step - loss: 0.6441 - acc: 0.6467 - val_loss: 0.9129 - val_acc: 0.1493\n",
      "Epoch 26/40\n",
      "1336/1336 [==============================] - 1s 700us/step - loss: 0.6440 - acc: 0.6467 - val_loss: 1.0335 - val_acc: 0.1433\n",
      "Epoch 27/40\n",
      "1336/1336 [==============================] - 1s 749us/step - loss: 0.6436 - acc: 0.6445 - val_loss: 0.9911 - val_acc: 0.1463\n",
      "Epoch 28/40\n",
      "1336/1336 [==============================] - 1s 634us/step - loss: 0.6443 - acc: 0.6452 - val_loss: 0.9363 - val_acc: 0.1493\n",
      "Epoch 29/40\n",
      "1336/1336 [==============================] - 1s 736us/step - loss: 0.6444 - acc: 0.6467 - val_loss: 0.9401 - val_acc: 0.1493\n",
      "Epoch 30/40\n",
      "1336/1336 [==============================] - 1s 709us/step - loss: 0.6435 - acc: 0.6467 - val_loss: 0.9539 - val_acc: 0.1493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/40\n",
      "1336/1336 [==============================] - 1s 662us/step - loss: 0.6430 - acc: 0.6452 - val_loss: 0.9211 - val_acc: 0.1493\n",
      "Epoch 32/40\n",
      "1336/1336 [==============================] - 1s 703us/step - loss: 0.6416 - acc: 0.6497 - val_loss: 1.0253 - val_acc: 0.1164\n",
      "Epoch 33/40\n",
      "1336/1336 [==============================] - 1s 817us/step - loss: 0.6425 - acc: 0.6460 - val_loss: 0.9259 - val_acc: 0.1493\n",
      "Epoch 34/40\n",
      "1336/1336 [==============================] - 1s 710us/step - loss: 0.6428 - acc: 0.6467 - val_loss: 0.9513 - val_acc: 0.1493\n",
      "Epoch 35/40\n",
      "1336/1336 [==============================] - 1s 789us/step - loss: 0.6417 - acc: 0.6475 - val_loss: 1.0046 - val_acc: 0.1463\n",
      "Epoch 36/40\n",
      "1336/1336 [==============================] - 1s 782us/step - loss: 0.6420 - acc: 0.6490 - val_loss: 0.9491 - val_acc: 0.1493\n",
      "Epoch 37/40\n",
      "1336/1336 [==============================] - 1s 763us/step - loss: 0.6414 - acc: 0.6490 - val_loss: 0.9801 - val_acc: 0.1463\n",
      "Epoch 38/40\n",
      "1336/1336 [==============================] - 1s 786us/step - loss: 0.6409 - acc: 0.6512 - val_loss: 0.9961 - val_acc: 0.1463\n",
      "Epoch 39/40\n",
      "1336/1336 [==============================] - 1s 803us/step - loss: 0.6411 - acc: 0.6504 - val_loss: 0.9786 - val_acc: 0.1463\n",
      "Epoch 40/40\n",
      "1336/1336 [==============================] - 1s 720us/step - loss: 0.6408 - acc: 0.6504 - val_loss: 0.9998 - val_acc: 0.1194\n",
      "185/185 [==============================] - 0s 50us/step\n",
      "Average accuracy of model on the dev set =  0.5222026304454623\n",
      "Training on fold 6/10.............................................\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_38 (Dense)             (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 5,425\n",
      "Trainable params: 5,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1336 samples, validate on 335 samples\n",
      "Epoch 1/40\n",
      "1336/1336 [==============================] - 3s 2ms/step - loss: 0.6643 - acc: 0.6325 - val_loss: 0.9218 - val_acc: 0.0000e+00\n",
      "Epoch 2/40\n",
      "1336/1336 [==============================] - 1s 767us/step - loss: 0.6537 - acc: 0.6355 - val_loss: 1.0008 - val_acc: 0.0000e+00\n",
      "Epoch 3/40\n",
      "1336/1336 [==============================] - 1s 723us/step - loss: 0.6511 - acc: 0.6355 - val_loss: 1.0271 - val_acc: 0.0000e+00\n",
      "Epoch 4/40\n",
      "1336/1336 [==============================] - 1s 762us/step - loss: 0.6492 - acc: 0.6370 - val_loss: 0.9348 - val_acc: 0.1134\n",
      "Epoch 5/40\n",
      "1336/1336 [==============================] - 1s 850us/step - loss: 0.6481 - acc: 0.6422 - val_loss: 0.9623 - val_acc: 0.1463\n",
      "Epoch 6/40\n",
      "1336/1336 [==============================] - 1s 863us/step - loss: 0.6464 - acc: 0.6490 - val_loss: 1.0350 - val_acc: 0.0388\n",
      "Epoch 7/40\n",
      "1336/1336 [==============================] - 1s 853us/step - loss: 0.6465 - acc: 0.6482 - val_loss: 0.9804 - val_acc: 0.1493\n",
      "Epoch 8/40\n",
      "1336/1336 [==============================] - 1s 897us/step - loss: 0.6449 - acc: 0.6497 - val_loss: 0.9617 - val_acc: 0.1493\n",
      "Epoch 9/40\n",
      "1336/1336 [==============================] - 1s 894us/step - loss: 0.6448 - acc: 0.6497 - val_loss: 0.9880 - val_acc: 0.1493\n",
      "Epoch 10/40\n",
      "1336/1336 [==============================] - 1s 922us/step - loss: 0.6437 - acc: 0.6497 - val_loss: 0.9310 - val_acc: 0.1493\n",
      "Epoch 11/40\n",
      "1336/1336 [==============================] - 1s 915us/step - loss: 0.6433 - acc: 0.6497 - val_loss: 0.9311 - val_acc: 0.1493\n",
      "Epoch 12/40\n",
      "1336/1336 [==============================] - 1s 908us/step - loss: 0.6431 - acc: 0.6497 - val_loss: 0.9685 - val_acc: 0.1493\n",
      "Epoch 13/40\n",
      "1336/1336 [==============================] - 1s 911us/step - loss: 0.6429 - acc: 0.6504 - val_loss: 0.9647 - val_acc: 0.1493\n",
      "Epoch 14/40\n",
      "1336/1336 [==============================] - 1s 963us/step - loss: 0.6415 - acc: 0.6504 - val_loss: 0.9877 - val_acc: 0.1493\n",
      "Epoch 15/40\n",
      "1336/1336 [==============================] - 1s 866us/step - loss: 0.6409 - acc: 0.6512 - val_loss: 0.9330 - val_acc: 0.1493\n",
      "Epoch 16/40\n",
      "1336/1336 [==============================] - 1s 863us/step - loss: 0.6400 - acc: 0.6534 - val_loss: 0.9223 - val_acc: 0.1493\n",
      "Epoch 17/40\n",
      "1336/1336 [==============================] - 1s 949us/step - loss: 0.6399 - acc: 0.6549 - val_loss: 0.9295 - val_acc: 0.1493\n",
      "Epoch 18/40\n",
      "1336/1336 [==============================] - 1s 886us/step - loss: 0.6390 - acc: 0.6534 - val_loss: 0.8947 - val_acc: 0.1493\n",
      "Epoch 19/40\n",
      "1336/1336 [==============================] - 1s 857us/step - loss: 0.6388 - acc: 0.6549 - val_loss: 0.9489 - val_acc: 0.1493\n",
      "Epoch 20/40\n",
      "1336/1336 [==============================] - 1s 892us/step - loss: 0.6377 - acc: 0.6564 - val_loss: 0.9642 - val_acc: 0.1493\n",
      "Epoch 21/40\n",
      "1336/1336 [==============================] - 1s 848us/step - loss: 0.6369 - acc: 0.6579 - val_loss: 0.9093 - val_acc: 0.1493\n",
      "Epoch 22/40\n",
      "1336/1336 [==============================] - 1s 880us/step - loss: 0.6371 - acc: 0.6587 - val_loss: 0.9790 - val_acc: 0.1522\n",
      "Epoch 23/40\n",
      "1336/1336 [==============================] - 1s 862us/step - loss: 0.6353 - acc: 0.6587 - val_loss: 0.9068 - val_acc: 0.1582\n",
      "Epoch 24/40\n",
      "1336/1336 [==============================] - 1s 869us/step - loss: 0.6355 - acc: 0.6579 - val_loss: 0.9680 - val_acc: 0.1522\n",
      "Epoch 25/40\n",
      "1336/1336 [==============================] - 1s 889us/step - loss: 0.6342 - acc: 0.6587 - val_loss: 0.9783 - val_acc: 0.1522\n",
      "Epoch 26/40\n",
      "1336/1336 [==============================] - 1s 886us/step - loss: 0.6338 - acc: 0.6594 - val_loss: 1.0187 - val_acc: 0.1522\n",
      "Epoch 27/40\n",
      "1336/1336 [==============================] - 1s 892us/step - loss: 0.6340 - acc: 0.6602 - val_loss: 0.9397 - val_acc: 0.1701\n",
      "Epoch 28/40\n",
      "1336/1336 [==============================] - 1s 834us/step - loss: 0.6333 - acc: 0.6572 - val_loss: 0.9554 - val_acc: 0.1701\n",
      "Epoch 29/40\n",
      "1336/1336 [==============================] - 1s 783us/step - loss: 0.6323 - acc: 0.6594 - val_loss: 0.9100 - val_acc: 0.1582\n",
      "Epoch 30/40\n",
      "1336/1336 [==============================] - 1s 783us/step - loss: 0.6315 - acc: 0.6587 - val_loss: 0.9558 - val_acc: 0.1552\n",
      "Epoch 31/40\n",
      "1336/1336 [==============================] - 1s 862us/step - loss: 0.6322 - acc: 0.6594 - val_loss: 0.9240 - val_acc: 0.1731\n",
      "Epoch 32/40\n",
      "1336/1336 [==============================] - 1s 941us/step - loss: 0.6307 - acc: 0.6609 - val_loss: 0.9954 - val_acc: 0.1701\n",
      "Epoch 33/40\n",
      "1336/1336 [==============================] - 1s 876us/step - loss: 0.6324 - acc: 0.6557 - val_loss: 0.8863 - val_acc: 0.1701\n",
      "Epoch 34/40\n",
      "1336/1336 [==============================] - 1s 874us/step - loss: 0.6294 - acc: 0.6572 - val_loss: 0.9941 - val_acc: 0.1701\n",
      "Epoch 35/40\n",
      "1336/1336 [==============================] - 1s 950us/step - loss: 0.6290 - acc: 0.6624 - val_loss: 0.8715 - val_acc: 0.1761\n",
      "Epoch 36/40\n",
      "1336/1336 [==============================] - 1s 940us/step - loss: 0.6299 - acc: 0.6624 - val_loss: 0.8699 - val_acc: 0.1731\n",
      "Epoch 37/40\n",
      "1336/1336 [==============================] - 1s 997us/step - loss: 0.6292 - acc: 0.6587 - val_loss: 0.9287 - val_acc: 0.1701\n",
      "Epoch 38/40\n",
      "1336/1336 [==============================] - 1s 1ms/step - loss: 0.6282 - acc: 0.6602 - val_loss: 0.9761 - val_acc: 0.1701\n",
      "Epoch 39/40\n",
      "1336/1336 [==============================] - 1s 1ms/step - loss: 0.6296 - acc: 0.6609 - val_loss: 0.9814 - val_acc: 0.1701\n",
      "Epoch 40/40\n",
      "1336/1336 [==============================] - 1s 1ms/step - loss: 0.6281 - acc: 0.6617 - val_loss: 0.9319 - val_acc: 0.1851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 0s 49us/step\n",
      "Average accuracy of model on the dev set =  0.5261598496351328\n",
      "Training on fold 7/10.............................................\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_44 (Dense)             (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 5,425\n",
      "Trainable params: 5,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1336 samples, validate on 335 samples\n",
      "Epoch 1/40\n",
      "1336/1336 [==============================] - 3s 2ms/step - loss: 0.6659 - acc: 0.6250 - val_loss: 0.9481 - val_acc: 0.0000e+00\n",
      "Epoch 2/40\n",
      "1336/1336 [==============================] - 1s 1ms/step - loss: 0.6543 - acc: 0.6355 - val_loss: 0.9694 - val_acc: 0.0000e+00\n",
      "Epoch 3/40\n",
      "1336/1336 [==============================] - 1s 1ms/step - loss: 0.6514 - acc: 0.6355 - val_loss: 0.9570 - val_acc: 0.0836\n",
      "Epoch 4/40\n",
      "1336/1336 [==============================] - 1s 1ms/step - loss: 0.6494 - acc: 0.6422 - val_loss: 0.9060 - val_acc: 0.1463\n",
      "Epoch 5/40\n",
      "1336/1336 [==============================] - 1s 1ms/step - loss: 0.6474 - acc: 0.6452 - val_loss: 0.9936 - val_acc: 0.1403\n",
      "Epoch 6/40\n",
      "1336/1336 [==============================] - 1s 956us/step - loss: 0.6451 - acc: 0.6467 - val_loss: 0.9803 - val_acc: 0.1403\n",
      "Epoch 7/40\n",
      "1336/1336 [==============================] - 1s 995us/step - loss: 0.6442 - acc: 0.6482 - val_loss: 0.9827 - val_acc: 0.1493\n",
      "Epoch 8/40\n",
      "1336/1336 [==============================] - 1s 971us/step - loss: 0.6432 - acc: 0.6482 - val_loss: 0.9802 - val_acc: 0.1493\n",
      "Epoch 9/40\n",
      "1336/1336 [==============================] - 1s 920us/step - loss: 0.6397 - acc: 0.6534 - val_loss: 1.0045 - val_acc: 0.1403\n",
      "Epoch 10/40\n",
      "1336/1336 [==============================] - 1s 1ms/step - loss: 0.6407 - acc: 0.6512 - val_loss: 0.9291 - val_acc: 0.1522\n",
      "Epoch 11/40\n",
      "1336/1336 [==============================] - 1s 1ms/step - loss: 0.6390 - acc: 0.6527 - val_loss: 0.9565 - val_acc: 0.1522\n",
      "Epoch 12/40\n",
      "1336/1336 [==============================] - 1s 945us/step - loss: 0.6382 - acc: 0.6557 - val_loss: 1.0083 - val_acc: 0.1493\n",
      "Epoch 13/40\n",
      "1336/1336 [==============================] - 1s 925us/step - loss: 0.6379 - acc: 0.6557 - val_loss: 0.9362 - val_acc: 0.1522\n",
      "Epoch 14/40\n",
      "1336/1336 [==============================] - 1s 973us/step - loss: 0.6375 - acc: 0.6572 - val_loss: 0.9183 - val_acc: 0.1522\n",
      "Epoch 15/40\n",
      "1336/1336 [==============================] - 1s 917us/step - loss: 0.6372 - acc: 0.6564 - val_loss: 0.9204 - val_acc: 0.1522\n",
      "Epoch 16/40\n",
      "1336/1336 [==============================] - 1s 854us/step - loss: 0.6363 - acc: 0.6564 - val_loss: 0.9960 - val_acc: 0.1522\n",
      "Epoch 17/40\n",
      "1336/1336 [==============================] - 1s 752us/step - loss: 0.6363 - acc: 0.6549 - val_loss: 0.9304 - val_acc: 0.1552\n",
      "Epoch 18/40\n",
      "1336/1336 [==============================] - 1s 869us/step - loss: 0.6355 - acc: 0.6572 - val_loss: 0.9211 - val_acc: 0.1522\n",
      "Epoch 19/40\n",
      "1336/1336 [==============================] - 1s 848us/step - loss: 0.6344 - acc: 0.6587 - val_loss: 0.9824 - val_acc: 0.1522\n",
      "Epoch 20/40\n",
      "1336/1336 [==============================] - 1s 831us/step - loss: 0.6352 - acc: 0.6579 - val_loss: 0.9820 - val_acc: 0.1522\n",
      "Epoch 21/40\n",
      "1336/1336 [==============================] - 1s 826us/step - loss: 0.6340 - acc: 0.6579 - val_loss: 0.8922 - val_acc: 0.1701\n",
      "Epoch 22/40\n",
      "1336/1336 [==============================] - 1s 829us/step - loss: 0.6334 - acc: 0.6609 - val_loss: 0.8302 - val_acc: 0.1761\n",
      "Epoch 23/40\n",
      "1336/1336 [==============================] - 1s 762us/step - loss: 0.6342 - acc: 0.6549 - val_loss: 0.9621 - val_acc: 0.1522\n",
      "Epoch 24/40\n",
      "1336/1336 [==============================] - 1s 787us/step - loss: 0.6332 - acc: 0.6572 - val_loss: 0.9138 - val_acc: 0.1403\n",
      "Epoch 25/40\n",
      "1336/1336 [==============================] - 1s 769us/step - loss: 0.6337 - acc: 0.6542 - val_loss: 0.8590 - val_acc: 0.1403\n",
      "Epoch 26/40\n",
      "1336/1336 [==============================] - 1s 779us/step - loss: 0.6323 - acc: 0.6572 - val_loss: 0.9519 - val_acc: 0.1522\n",
      "Epoch 27/40\n",
      "1336/1336 [==============================] - 1s 808us/step - loss: 0.6315 - acc: 0.6564 - val_loss: 0.9361 - val_acc: 0.1522\n",
      "Epoch 28/40\n",
      "1336/1336 [==============================] - 1s 797us/step - loss: 0.6310 - acc: 0.6572 - val_loss: 0.8412 - val_acc: 0.1701\n",
      "Epoch 29/40\n",
      "1336/1336 [==============================] - 1s 764us/step - loss: 0.6320 - acc: 0.6534 - val_loss: 0.9582 - val_acc: 0.1522\n",
      "Epoch 30/40\n",
      "1336/1336 [==============================] - 1s 758us/step - loss: 0.6311 - acc: 0.6572 - val_loss: 0.9656 - val_acc: 0.1522\n",
      "Epoch 31/40\n",
      "1336/1336 [==============================] - 1s 718us/step - loss: 0.6314 - acc: 0.6594 - val_loss: 0.8520 - val_acc: 0.1701\n",
      "Epoch 32/40\n",
      "1336/1336 [==============================] - 1s 777us/step - loss: 0.6315 - acc: 0.6587 - val_loss: 0.8418 - val_acc: 0.2000\n",
      "Epoch 33/40\n",
      "1336/1336 [==============================] - 1s 845us/step - loss: 0.6308 - acc: 0.6602 - val_loss: 0.9377 - val_acc: 0.1522\n",
      "Epoch 34/40\n",
      "1336/1336 [==============================] - 1s 779us/step - loss: 0.6288 - acc: 0.6587 - val_loss: 0.9278 - val_acc: 0.1522\n",
      "Epoch 35/40\n",
      "1336/1336 [==============================] - 1s 791us/step - loss: 0.6292 - acc: 0.6579 - val_loss: 0.8521 - val_acc: 0.1672\n",
      "Epoch 36/40\n",
      "1336/1336 [==============================] - 1s 733us/step - loss: 0.6286 - acc: 0.6564 - val_loss: 0.9272 - val_acc: 0.1552\n",
      "Epoch 37/40\n",
      "1336/1336 [==============================] - 1s 715us/step - loss: 0.6277 - acc: 0.6624 - val_loss: 0.9015 - val_acc: 0.0507\n",
      "Epoch 38/40\n",
      "1336/1336 [==============================] - 1s 787us/step - loss: 0.6301 - acc: 0.6557 - val_loss: 0.8870 - val_acc: 0.1672\n",
      "Epoch 39/40\n",
      "1336/1336 [==============================] - 1s 893us/step - loss: 0.6286 - acc: 0.6564 - val_loss: 0.8546 - val_acc: 0.1701\n",
      "Epoch 40/40\n",
      "1336/1336 [==============================] - 1s 1ms/step - loss: 0.6273 - acc: 0.6572 - val_loss: 0.9104 - val_acc: 0.1522\n",
      "185/185 [==============================] - 0s 45us/step\n",
      "Average accuracy of model on the dev set =  0.535164040965478\n",
      "Training on fold 8/10.............................................\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_50 (Dense)             (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 5,425\n",
      "Trainable params: 5,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1336 samples, validate on 335 samples\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1336/1336 [==============================] - 3s 2ms/step - loss: 0.6577 - acc: 0.6355 - val_loss: 0.9612 - val_acc: 0.0000e+00\n",
      "Epoch 2/40\n",
      "1336/1336 [==============================] - 1s 757us/step - loss: 0.6552 - acc: 0.6355 - val_loss: 0.9943 - val_acc: 0.0000e+00\n",
      "Epoch 3/40\n",
      "1336/1336 [==============================] - 1s 779us/step - loss: 0.6537 - acc: 0.6355 - val_loss: 0.9798 - val_acc: 0.0000e+00\n",
      "Epoch 4/40\n",
      "1336/1336 [==============================] - 1s 863us/step - loss: 0.6516 - acc: 0.6347 - val_loss: 0.9710 - val_acc: 0.0448\n",
      "Epoch 5/40\n",
      "1336/1336 [==============================] - 1s 816us/step - loss: 0.6500 - acc: 0.6430 - val_loss: 0.9431 - val_acc: 0.1582\n",
      "Epoch 6/40\n",
      "1336/1336 [==============================] - 1s 845us/step - loss: 0.6485 - acc: 0.6460 - val_loss: 0.9381 - val_acc: 0.1582\n",
      "Epoch 7/40\n",
      "1336/1336 [==============================] - 1s 758us/step - loss: 0.6473 - acc: 0.6460 - val_loss: 0.9031 - val_acc: 0.1612\n",
      "Epoch 8/40\n",
      "1336/1336 [==============================] - 1s 834us/step - loss: 0.6466 - acc: 0.6460 - val_loss: 0.9347 - val_acc: 0.1582\n",
      "Epoch 9/40\n",
      "1336/1336 [==============================] - 1s 771us/step - loss: 0.6460 - acc: 0.6460 - val_loss: 0.9192 - val_acc: 0.1612\n",
      "Epoch 10/40\n",
      "1336/1336 [==============================] - 1s 859us/step - loss: 0.6444 - acc: 0.6460 - val_loss: 0.9091 - val_acc: 0.1582\n",
      "Epoch 11/40\n",
      "1336/1336 [==============================] - 1s 845us/step - loss: 0.6439 - acc: 0.6460 - val_loss: 0.9575 - val_acc: 0.1582\n",
      "Epoch 12/40\n",
      "1336/1336 [==============================] - 1s 794us/step - loss: 0.6431 - acc: 0.6460 - val_loss: 0.9521 - val_acc: 0.1582\n",
      "Epoch 13/40\n",
      "1336/1336 [==============================] - 1s 841us/step - loss: 0.6422 - acc: 0.6460 - val_loss: 0.9473 - val_acc: 0.1582\n",
      "Epoch 14/40\n",
      "1336/1336 [==============================] - 1s 804us/step - loss: 0.6411 - acc: 0.6475 - val_loss: 0.9048 - val_acc: 0.1612\n",
      "Epoch 15/40\n",
      "1336/1336 [==============================] - 1s 829us/step - loss: 0.6404 - acc: 0.6504 - val_loss: 0.9590 - val_acc: 0.1582\n",
      "Epoch 16/40\n",
      "1336/1336 [==============================] - 1s 827us/step - loss: 0.6404 - acc: 0.6504 - val_loss: 0.9369 - val_acc: 0.1612\n",
      "Epoch 17/40\n",
      "1336/1336 [==============================] - 1s 867us/step - loss: 0.6387 - acc: 0.6512 - val_loss: 0.9989 - val_acc: 0.1612\n",
      "Epoch 18/40\n",
      "1336/1336 [==============================] - 1s 844us/step - loss: 0.6390 - acc: 0.6534 - val_loss: 0.8998 - val_acc: 0.1672\n",
      "Epoch 19/40\n",
      "1336/1336 [==============================] - 1s 879us/step - loss: 0.6384 - acc: 0.6534 - val_loss: 0.9481 - val_acc: 0.1612\n",
      "Epoch 20/40\n",
      "1336/1336 [==============================] - 1s 929us/step - loss: 0.6381 - acc: 0.6557 - val_loss: 0.9777 - val_acc: 0.1552\n",
      "Epoch 21/40\n",
      "1336/1336 [==============================] - 1s 842us/step - loss: 0.6374 - acc: 0.6519 - val_loss: 0.9898 - val_acc: 0.1552\n",
      "Epoch 22/40\n",
      "1336/1336 [==============================] - 1s 780us/step - loss: 0.6371 - acc: 0.6497 - val_loss: 0.9141 - val_acc: 0.1642\n",
      "Epoch 23/40\n",
      "1336/1336 [==============================] - 1s 800us/step - loss: 0.6364 - acc: 0.6564 - val_loss: 0.9489 - val_acc: 0.1612\n",
      "Epoch 24/40\n",
      "1336/1336 [==============================] - 1s 917us/step - loss: 0.6367 - acc: 0.6542 - val_loss: 0.9077 - val_acc: 0.1672\n",
      "Epoch 25/40\n",
      "1336/1336 [==============================] - 1s 823us/step - loss: 0.6366 - acc: 0.6534 - val_loss: 0.9137 - val_acc: 0.1672\n",
      "Epoch 26/40\n",
      "1336/1336 [==============================] - 1s 838us/step - loss: 0.6358 - acc: 0.6519 - val_loss: 0.9063 - val_acc: 0.1612\n",
      "Epoch 27/40\n",
      "1336/1336 [==============================] - 1s 756us/step - loss: 0.6354 - acc: 0.6542 - val_loss: 0.8996 - val_acc: 0.1672\n",
      "Epoch 28/40\n",
      "1336/1336 [==============================] - 1s 829us/step - loss: 0.6341 - acc: 0.6564 - val_loss: 1.0078 - val_acc: 0.1552\n",
      "Epoch 29/40\n",
      "1336/1336 [==============================] - 1s 862us/step - loss: 0.6352 - acc: 0.6519 - val_loss: 0.8834 - val_acc: 0.1672\n",
      "Epoch 30/40\n",
      "1336/1336 [==============================] - 1s 858us/step - loss: 0.6338 - acc: 0.6534 - val_loss: 0.9407 - val_acc: 0.1672\n",
      "Epoch 31/40\n",
      "1336/1336 [==============================] - 1s 829us/step - loss: 0.6341 - acc: 0.6527 - val_loss: 0.9535 - val_acc: 0.1672\n",
      "Epoch 32/40\n",
      "1336/1336 [==============================] - 1s 836us/step - loss: 0.6329 - acc: 0.6542 - val_loss: 0.9566 - val_acc: 0.1552\n",
      "Epoch 33/40\n",
      "1336/1336 [==============================] - 1s 815us/step - loss: 0.6325 - acc: 0.6542 - val_loss: 0.8943 - val_acc: 0.1612\n",
      "Epoch 34/40\n",
      "1336/1336 [==============================] - 1s 848us/step - loss: 0.6327 - acc: 0.6549 - val_loss: 0.9531 - val_acc: 0.1672\n",
      "Epoch 35/40\n",
      "1336/1336 [==============================] - 1s 789us/step - loss: 0.6325 - acc: 0.6549 - val_loss: 0.8683 - val_acc: 0.1701\n",
      "Epoch 36/40\n",
      "1336/1336 [==============================] - 1s 812us/step - loss: 0.6316 - acc: 0.6527 - val_loss: 0.8745 - val_acc: 0.1672\n",
      "Epoch 37/40\n",
      "1336/1336 [==============================] - 1s 832us/step - loss: 0.6309 - acc: 0.6542 - val_loss: 0.9563 - val_acc: 0.1672\n",
      "Epoch 38/40\n",
      "1336/1336 [==============================] - 1s 768us/step - loss: 0.6316 - acc: 0.6572 - val_loss: 0.8877 - val_acc: 0.1612\n",
      "Epoch 39/40\n",
      "1336/1336 [==============================] - 1s 617us/step - loss: 0.6316 - acc: 0.6527 - val_loss: 0.9150 - val_acc: 0.1642\n",
      "Epoch 40/40\n",
      "1336/1336 [==============================] - 1s 702us/step - loss: 0.6299 - acc: 0.6549 - val_loss: 0.9722 - val_acc: 0.1642\n",
      "185/185 [==============================] - 0s 58us/step\n",
      "Average accuracy of model on the dev set =  0.5412415087573561\n",
      "Training on fold 9/10.............................................\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_56 (Dense)             (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 5,425\n",
      "Trainable params: 5,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1336 samples, validate on 335 samples\n",
      "Epoch 1/40\n",
      "1336/1336 [==============================] - 3s 2ms/step - loss: 0.7048 - acc: 0.5397 - val_loss: 0.9541 - val_acc: 0.0000e+00\n",
      "Epoch 2/40\n",
      "1336/1336 [==============================] - 1s 847us/step - loss: 0.6588 - acc: 0.6355 - val_loss: 0.9784 - val_acc: 0.0000e+00\n",
      "Epoch 3/40\n",
      "1336/1336 [==============================] - 1s 795us/step - loss: 0.6546 - acc: 0.6362 - val_loss: 0.9924 - val_acc: 0.0866\n",
      "Epoch 4/40\n",
      "1336/1336 [==============================] - 1s 891us/step - loss: 0.6528 - acc: 0.6392 - val_loss: 0.9490 - val_acc: 0.1313\n",
      "Epoch 5/40\n",
      "1336/1336 [==============================] - 1s 826us/step - loss: 0.6515 - acc: 0.6415 - val_loss: 0.8899 - val_acc: 0.1642\n",
      "Epoch 6/40\n",
      "1336/1336 [==============================] - 1s 904us/step - loss: 0.6512 - acc: 0.6437 - val_loss: 0.9261 - val_acc: 0.1672\n",
      "Epoch 7/40\n",
      "1336/1336 [==============================] - 1s 900us/step - loss: 0.6490 - acc: 0.6460 - val_loss: 0.9646 - val_acc: 0.1672\n",
      "Epoch 8/40\n",
      "1336/1336 [==============================] - 1s 817us/step - loss: 0.6491 - acc: 0.6437 - val_loss: 0.9434 - val_acc: 0.1672\n",
      "Epoch 9/40\n",
      "1336/1336 [==============================] - 1s 874us/step - loss: 0.6492 - acc: 0.6475 - val_loss: 1.0226 - val_acc: 0.1642\n",
      "Epoch 10/40\n",
      "1336/1336 [==============================] - 1s 927us/step - loss: 0.6486 - acc: 0.6460 - val_loss: 0.9517 - val_acc: 0.1672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/40\n",
      "1336/1336 [==============================] - 1s 851us/step - loss: 0.6482 - acc: 0.6475 - val_loss: 0.9370 - val_acc: 0.1672\n",
      "Epoch 12/40\n",
      "1336/1336 [==============================] - 1s 839us/step - loss: 0.6471 - acc: 0.6475 - val_loss: 0.9655 - val_acc: 0.1672\n",
      "Epoch 13/40\n",
      "1336/1336 [==============================] - 1s 881us/step - loss: 0.6472 - acc: 0.6460 - val_loss: 0.9233 - val_acc: 0.1672\n",
      "Epoch 14/40\n",
      "1336/1336 [==============================] - 1s 952us/step - loss: 0.6459 - acc: 0.6467 - val_loss: 1.0374 - val_acc: 0.1672\n",
      "Epoch 15/40\n",
      "1336/1336 [==============================] - 1s 854us/step - loss: 0.6457 - acc: 0.6490 - val_loss: 0.9051 - val_acc: 0.1672\n",
      "Epoch 16/40\n",
      "1336/1336 [==============================] - 1s 891us/step - loss: 0.6451 - acc: 0.6460 - val_loss: 0.9777 - val_acc: 0.1672 - loss: 0.6547 - acc: 0. - ETA: 0s - loss: 0.6504 - acc: 0.\n",
      "Epoch 17/40\n",
      "1336/1336 [==============================] - 1s 975us/step - loss: 0.6451 - acc: 0.6482 - val_loss: 1.0266 - val_acc: 0.1672\n",
      "Epoch 18/40\n",
      "1336/1336 [==============================] - 1s 839us/step - loss: 0.6452 - acc: 0.6475 - val_loss: 0.9634 - val_acc: 0.1672\n",
      "Epoch 19/40\n",
      "1336/1336 [==============================] - 1s 854us/step - loss: 0.6443 - acc: 0.6475 - val_loss: 0.9177 - val_acc: 0.1701\n",
      "Epoch 20/40\n",
      "1336/1336 [==============================] - 1s 983us/step - loss: 0.6435 - acc: 0.6497 - val_loss: 0.9080 - val_acc: 0.1672\n",
      "Epoch 21/40\n",
      "1336/1336 [==============================] - 1s 845us/step - loss: 0.6437 - acc: 0.6490 - val_loss: 0.9019 - val_acc: 0.1701\n",
      "Epoch 22/40\n",
      "1336/1336 [==============================] - 1s 694us/step - loss: 0.6423 - acc: 0.6497 - val_loss: 1.0130 - val_acc: 0.1672\n",
      "Epoch 23/40\n",
      "1336/1336 [==============================] - 1s 672us/step - loss: 0.6418 - acc: 0.6519 - val_loss: 0.8909 - val_acc: 0.1761\n",
      "Epoch 24/40\n",
      "1336/1336 [==============================] - 1s 645us/step - loss: 0.6415 - acc: 0.6534 - val_loss: 0.9008 - val_acc: 0.1731\n",
      "Epoch 25/40\n",
      "1336/1336 [==============================] - 1s 664us/step - loss: 0.6412 - acc: 0.6497 - val_loss: 0.8796 - val_acc: 0.1761\n",
      "Epoch 26/40\n",
      "1336/1336 [==============================] - 1s 811us/step - loss: 0.6404 - acc: 0.6512 - val_loss: 0.9429 - val_acc: 0.1701\n",
      "Epoch 27/40\n",
      "1336/1336 [==============================] - 1s 780us/step - loss: 0.6400 - acc: 0.6512 - val_loss: 0.8881 - val_acc: 0.1761\n",
      "Epoch 28/40\n",
      "1336/1336 [==============================] - 1s 746us/step - loss: 0.6391 - acc: 0.6557 - val_loss: 0.9190 - val_acc: 0.1731\n",
      "Epoch 29/40\n",
      "1336/1336 [==============================] - 1s 1ms/step - loss: 0.6381 - acc: 0.6542 - val_loss: 0.9516 - val_acc: 0.1731\n",
      "Epoch 30/40\n",
      "1336/1336 [==============================] - 1s 1ms/step - loss: 0.6373 - acc: 0.6557 - val_loss: 0.8730 - val_acc: 0.1761\n",
      "Epoch 31/40\n",
      "1336/1336 [==============================] - 1s 808us/step - loss: 0.6369 - acc: 0.6564 - val_loss: 0.9354 - val_acc: 0.1284\n",
      "Epoch 32/40\n",
      "1336/1336 [==============================] - 1s 754us/step - loss: 0.6360 - acc: 0.6557 - val_loss: 0.9001 - val_acc: 0.1284\n",
      "Epoch 33/40\n",
      "1336/1336 [==============================] - 1s 956us/step - loss: 0.6362 - acc: 0.6572 - val_loss: 0.8785 - val_acc: 0.1791\n",
      "Epoch 34/40\n",
      "1336/1336 [==============================] - 1s 649us/step - loss: 0.6362 - acc: 0.6587 - val_loss: 0.9189 - val_acc: 0.1254\n",
      "Epoch 35/40\n",
      "1336/1336 [==============================] - 1s 901us/step - loss: 0.6351 - acc: 0.6572 - val_loss: 0.9769 - val_acc: 0.1313\n",
      "Epoch 36/40\n",
      "1336/1336 [==============================] - 1s 708us/step - loss: 0.6332 - acc: 0.6579 - val_loss: 0.9676 - val_acc: 0.1284\n",
      "Epoch 37/40\n",
      "1336/1336 [==============================] - 1s 634us/step - loss: 0.6342 - acc: 0.6579 - val_loss: 0.9752 - val_acc: 0.1284\n",
      "Epoch 38/40\n",
      "1336/1336 [==============================] - 1s 756us/step - loss: 0.6324 - acc: 0.6572 - val_loss: 0.8644 - val_acc: 0.1881\n",
      "Epoch 39/40\n",
      "1336/1336 [==============================] - 1s 680us/step - loss: 0.6322 - acc: 0.6579 - val_loss: 0.9513 - val_acc: 0.1731\n",
      "Epoch 40/40\n",
      "1336/1336 [==============================] - ETA: 0s - loss: 0.6332 - acc: 0.655 - 1s 725us/step - loss: 0.6329 - acc: 0.6557 - val_loss: 0.8727 - val_acc: 0.2000\n",
      "185/185 [==============================] - 0s 41us/step\n",
      "Average accuracy of model on the dev set =  0.5393618215444325\n",
      "Training on fold 10/10.............................................\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_62 (Dense)             (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 5,425\n",
      "Trainable params: 5,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1336 samples, validate on 335 samples\n",
      "Epoch 1/40\n",
      "1336/1336 [==============================] - 2s 2ms/step - loss: 0.6890 - acc: 0.5561 - val_loss: 0.9488 - val_acc: 0.0000e+00\n",
      "Epoch 2/40\n",
      "1336/1336 [==============================] - 1s 735us/step - loss: 0.6578 - acc: 0.6355 - val_loss: 0.8960 - val_acc: 0.0000e+00\n",
      "Epoch 3/40\n",
      "1336/1336 [==============================] - 1s 680us/step - loss: 0.6541 - acc: 0.6332 - val_loss: 0.8852 - val_acc: 0.0806\n",
      "Epoch 4/40\n",
      "1336/1336 [==============================] - 1s 767us/step - loss: 0.6519 - acc: 0.6355 - val_loss: 0.9466 - val_acc: 0.1522\n",
      "Epoch 5/40\n",
      "1336/1336 [==============================] - 1s 823us/step - loss: 0.6496 - acc: 0.6445 - val_loss: 0.9233 - val_acc: 0.1642\n",
      "Epoch 6/40\n",
      "1336/1336 [==============================] - 1s 776us/step - loss: 0.6502 - acc: 0.6445 - val_loss: 0.9226 - val_acc: 0.1701\n",
      "Epoch 7/40\n",
      "1336/1336 [==============================] - 1s 994us/step - loss: 0.6487 - acc: 0.6467 - val_loss: 0.9202 - val_acc: 0.1701\n",
      "Epoch 8/40\n",
      "1336/1336 [==============================] - 1s 1ms/step - loss: 0.6485 - acc: 0.6452 - val_loss: 0.9350 - val_acc: 0.1701\n",
      "Epoch 9/40\n",
      "1336/1336 [==============================] - 1s 889us/step - loss: 0.6479 - acc: 0.6460 - val_loss: 0.9211 - val_acc: 0.1701\n",
      "Epoch 10/40\n",
      "1336/1336 [==============================] - 1s 847us/step - loss: 0.6464 - acc: 0.6422 - val_loss: 0.9425 - val_acc: 0.1701\n",
      "Epoch 11/40\n",
      "1336/1336 [==============================] - 1s 840us/step - loss: 0.6478 - acc: 0.6460 - val_loss: 0.8876 - val_acc: 0.1701\n",
      "Epoch 12/40\n",
      "1336/1336 [==============================] - 1s 964us/step - loss: 0.6456 - acc: 0.6460 - val_loss: 0.9364 - val_acc: 0.1701\n",
      "Epoch 13/40\n",
      "1336/1336 [==============================] - 1s 768us/step - loss: 0.6454 - acc: 0.6475 - val_loss: 0.9184 - val_acc: 0.1701\n",
      "Epoch 14/40\n",
      "1336/1336 [==============================] - 1s 866us/step - loss: 0.6442 - acc: 0.6475 - val_loss: 0.8652 - val_acc: 0.1940\n",
      "Epoch 15/40\n",
      "1336/1336 [==============================] - 1s 810us/step - loss: 0.6450 - acc: 0.6497 - val_loss: 0.9490 - val_acc: 0.1701\n",
      "Epoch 16/40\n",
      "1336/1336 [==============================] - 1s 814us/step - loss: 0.6439 - acc: 0.6482 - val_loss: 0.9448 - val_acc: 0.1701\n",
      "Epoch 17/40\n",
      "1336/1336 [==============================] - 1s 843us/step - loss: 0.6440 - acc: 0.6482 - val_loss: 0.8968 - val_acc: 0.1701\n",
      "Epoch 18/40\n",
      "1336/1336 [==============================] - 1s 744us/step - loss: 0.6424 - acc: 0.6497 - val_loss: 0.9310 - val_acc: 0.1731\n",
      "Epoch 19/40\n",
      "1336/1336 [==============================] - 1s 842us/step - loss: 0.6414 - acc: 0.6512 - val_loss: 0.8842 - val_acc: 0.1940\n",
      "Epoch 20/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1336/1336 [==============================] - 1s 805us/step - loss: 0.6413 - acc: 0.6527 - val_loss: 0.9307 - val_acc: 0.1701\n",
      "Epoch 21/40\n",
      "1336/1336 [==============================] - 1s 813us/step - loss: 0.6412 - acc: 0.6527 - val_loss: 0.9158 - val_acc: 0.1731\n",
      "Epoch 22/40\n",
      "1336/1336 [==============================] - 1s 862us/step - loss: 0.6405 - acc: 0.6527 - val_loss: 0.9076 - val_acc: 0.1731\n",
      "Epoch 23/40\n",
      "1336/1336 [==============================] - 1s 927us/step - loss: 0.6383 - acc: 0.6504 - val_loss: 0.8575 - val_acc: 0.2000\n",
      "Epoch 24/40\n",
      "1336/1336 [==============================] - 1s 824us/step - loss: 0.6390 - acc: 0.6512 - val_loss: 0.9350 - val_acc: 0.1731\n",
      "Epoch 25/40\n",
      "1336/1336 [==============================] - 1s 774us/step - loss: 0.6379 - acc: 0.6504 - val_loss: 0.8795 - val_acc: 0.1940\n",
      "Epoch 26/40\n",
      "1336/1336 [==============================] - 1s 763us/step - loss: 0.6388 - acc: 0.6542 - val_loss: 0.8901 - val_acc: 0.2000\n",
      "Epoch 27/40\n",
      "1336/1336 [==============================] - 1s 853us/step - loss: 0.6377 - acc: 0.6504 - val_loss: 0.9333 - val_acc: 0.1910\n",
      "Epoch 28/40\n",
      "1336/1336 [==============================] - 1s 937us/step - loss: 0.6360 - acc: 0.6534 - val_loss: 0.8455 - val_acc: 0.2030\n",
      "Epoch 29/40\n",
      "1336/1336 [==============================] - 1s 792us/step - loss: 0.6380 - acc: 0.6572 - val_loss: 0.9564 - val_acc: 0.1881\n",
      "Epoch 30/40\n",
      "1336/1336 [==============================] - 1s 891us/step - loss: 0.6377 - acc: 0.6504 - val_loss: 0.9214 - val_acc: 0.1910\n",
      "Epoch 31/40\n",
      "1336/1336 [==============================] - 1s 1ms/step - loss: 0.6362 - acc: 0.6534 - val_loss: 0.9746 - val_acc: 0.1881\n",
      "Epoch 32/40\n",
      "1336/1336 [==============================] - 1s 873us/step - loss: 0.6366 - acc: 0.6534 - val_loss: 0.8935 - val_acc: 0.1910\n",
      "Epoch 33/40\n",
      "1336/1336 [==============================] - 1s 940us/step - loss: 0.6355 - acc: 0.6527 - val_loss: 0.9248 - val_acc: 0.1910\n",
      "Epoch 34/40\n",
      "1336/1336 [==============================] - 1s 826us/step - loss: 0.6350 - acc: 0.6542 - val_loss: 0.9871 - val_acc: 0.1910\n",
      "Epoch 35/40\n",
      "1336/1336 [==============================] - 1s 811us/step - loss: 0.6351 - acc: 0.6542 - val_loss: 0.9164 - val_acc: 0.1940\n",
      "Epoch 36/40\n",
      "1336/1336 [==============================] - 1s 804us/step - loss: 0.6348 - acc: 0.6557 - val_loss: 0.9154 - val_acc: 0.1940\n",
      "Epoch 37/40\n",
      "1336/1336 [==============================] - 1s 882us/step - loss: 0.6327 - acc: 0.6557 - val_loss: 0.8068 - val_acc: 0.2000\n",
      "Epoch 38/40\n",
      "1336/1336 [==============================] - 1s 825us/step - loss: 0.6350 - acc: 0.6549 - val_loss: 0.9168 - val_acc: 0.1910\n",
      "Epoch 39/40\n",
      "1336/1336 [==============================] - 1s 800us/step - loss: 0.6346 - acc: 0.6542 - val_loss: 0.8722 - val_acc: 0.2000\n",
      "Epoch 40/40\n",
      "1336/1336 [==============================] - 1s 790us/step - loss: 0.6340 - acc: 0.6549 - val_loss: 0.8982 - val_acc: 0.1940\n",
      "185/185 [==============================] - 0s 34us/step\n",
      "Average accuracy of model on the dev set =  0.5421823961870194\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, random_state=12)\n",
    "avg_loss = []\n",
    "avg_acc = []\n",
    "# Loop through the indices the split() method returns\n",
    "for index, (train_index, test_index) in enumerate(skf.split(all_data, labels)):\n",
    "    print(\"Training on fold \" + str(index + 1) + \"/10.............................................\")\n",
    "    # Generate batches from indices\n",
    "    x_train, x_test = all_data[train_index], all_data[test_index]\n",
    "    # use one-hot vectors as labels\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "\n",
    "    network = models.Sequential()\n",
    "    \n",
    "\n",
    "    network.add(layers.Dense(16, input_shape=(8,)))\n",
    "    network.add(layers.Dense(32, activation=\"relu\"))\n",
    "    network.add(layers.Dense(64, activation=\"relu\"))\n",
    "    network.add(layers.Dense(32, activation=\"relu\"))\n",
    "    network.add(layers.Dense(16, activation=\"sigmoid\"))\n",
    "    network.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Adam = Adam(lr=0.05)\n",
    "    network.compile(optimizer=Adam(lr=0.00038),\n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=['acc'])\n",
    "\n",
    "    network.summary()\n",
    "\n",
    "    history = network.fit(x_train, y_train, validation_split=0.2,\n",
    "                          epochs=40, verbose=1, batch_size=3)\n",
    "\n",
    "    loss, accuracy = network.evaluate(x_test, y_test)\n",
    "\n",
    "    # evaluate and store the accuracy\n",
    "#     loss, accuracy = model.evaluate(xtest_imagelist, ytest, verbose=1)\n",
    "    avg_loss.append(loss)\n",
    "    avg_acc.append(accuracy)\n",
    "\n",
    "    # cross validation score\n",
    "    print(\"Average accuracy of model on the dev set = \", np.mean(avg_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
