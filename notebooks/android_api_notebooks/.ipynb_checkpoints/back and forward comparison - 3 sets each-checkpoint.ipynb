{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "rest_android = pd.read_csv(\"../../data_files/data_from_android_api/rest/rest_25_mins.csv\")\n",
    "\n",
    "# forward_android1 = pd.read_csv(\"../../data_files/data_from_android_api/forward/forward_5mins_1.csv\")\n",
    "# forward_android2 = pd.read_csv(\"../../data_files/data_from_android_api/forward/forward_5mins_2.csv\")\n",
    "forward_android3 = pd.read_csv(\"../../data_files/data_from_android_api/forward/forward_5mins_3.csv\")\n",
    "forward_android4 = pd.read_csv(\"../../data_files/data_from_android_api/forward/forward_5mins_4.csv\")\n",
    "forward_android5 = pd.read_csv(\"../../data_files/data_from_android_api/forward/forward_5mins_5.csv\")\n",
    "\n",
    "back1 = pd.read_csv('../../data_files/data_from_android_api/back/back_5mins_1.csv')\n",
    "back2 = pd.read_csv('../../data_files/data_from_android_api/back/back_5mins_2.csv')\n",
    "back3 = pd.read_csv('../../data_files/data_from_android_api/back/back_5mins_3.csv')\n",
    "\n",
    "# forward = pd.concat([forward_android1, forward_android2, forward_android3, \n",
    "#                      forward_android4, forward_android5])\n",
    "\n",
    "forward = pd.concat([forward_android5, forward_android4])\n",
    "back = pd.concat([back1, back2, back3])\n",
    "\n",
    "dataDF = pd.concat([forward, back])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKAAAAJCCAYAAAD3Bb8PAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAIABJREFUeJzs3X+sXeV95/vPN9jU0Ck/Ak7kYqhh6rbQQMAx4Cp1ykBKDGkDkRKVKI19I26dH3A1I+VelUZq8VBSUSmZSKiBijQuTpSGEmZSSCDDWGCUkqQEEwg/B+FSN5yAiGOIA6LQwDz3j7MMB3Ps88N+OMfweklbZ+9nP2utZ1tbAr219lrVWgsAAAAA9PKGmV4AAAAAAK9tAhQAAAAAXQlQAAAAAHQlQAEAAADQlQAFAAAAQFcCFAAAAABdCVAAAAAAdCVAAQAAANCVAAUAAABAV3NmegGvlkMPPbQtWrRoppcBAAAA8Jpxxx13/KS1Nn+iea+bALVo0aJs3LhxppcBAAAA8JpRVf86mXl+ggcAAABAVwIUAAAAAF0JUAAAAAB09bq5BhQAAADAeH7+859nZGQkzz777EwvZdaaN29eFi5cmLlz505rewEKAAAAeF0bGRnJL/3SL2XRokWpqplezqzTWsvWrVszMjKSI488clr78BM8AAAA4HXt2WefzSGHHCI+7URV5ZBDDtmtM8QEKAAAAOB1T3zatd399xGgAAAAAOjKNaAAAAAAxlh0wfV7dH+bL3n3xHM2b87v/d7v5d577532cW655ZZ8+tOfzje+8Y1p76MXZ0ABAAAA0JUABQAAADALPP/881m1alWOO+64vO9978szzzyTiy66KCeeeGLe8pa3ZPXq1WmtJUk2bdqUd77znXnrW9+aJUuW5J//+Z9ftq/bb789J5xwQh5++OGZ+CivIEABAAAAzAIPPvhgVq9enbvvvjsHHHBALrvsspx//vm5/fbbc++99+bf/u3fXvx53Qc/+MGcd955+cEPfpDvfOc7WbBgwYv7+c53vpOPfvSjufbaa3PUUUfN1Md5GQEKAAAAYBY4/PDD8/a3vz1J8od/+Ie59dZbs2HDhpx88sk59thjc/PNN+e+++7LU089lR/96Ed573vfmySZN29e9t9//yTJAw88kNWrV+frX/96jjjiiBn7LDuaMEBV1byq+l5V/aCq7quq/zqMX1lV/1JVdw2P44fxqqpLq2pTVd1dVUvG7GtVVT00PFaNGX9bVd0zbHNpDff2q6o3VtX6Yf76qjp4omMAAAAA7I2GHPKy1x//+MdzzTXX5J577skf/dEf5dlnn33xZ3jjWbBgQebNm5c777yz93KnZDJnQD2X5NTW2luTHJ9kRVUtG977/1prxw+Pu4axM5IsHh6rk1yejMakJBcmOTnJSUku3B6Uhjmrx2y3Yhi/IMlNrbXFSW4aXu/0GAAAAAB7qx/+8If57ne/myT5yle+kt/+7d9Okhx66KF5+umnc8011yRJDjjggCxcuDD/8A//kCR57rnn8swzzyRJDjrooFx//fX55Cc/mVtuueXV/xA7MWeiCW00qz09vJw7PHae2pKzknxx2O6fquqgqlqQ5JQk61trTyRJVa3PaMy6JckBrbXvDuNfTHJ2km8O+zpl2O+6JLck+eOdHaO19tgkPzcAAADAuDZf8u4ZOe7RRx+ddevW5SMf+UgWL16cj33sY3nyySdz7LHHZtGiRTnxxBNfnPulL30pH/nIR/Jnf/ZnmTt3br761a+++N6b3/zmfP3rX88ZZ5yRtWvX5uSTT56Jj/MyEwaoJKmqfZLckeRXk3yutXZbVX0syaeq6s8ynJ3UWnsuyWFJHhmz+cgwtqvxkXHGk+TN26NSa+2xqnrTML6zfQlQAAAAwF5n0aJFuf/++18xfvHFF+fiiy9+xfjixYtz8803v2zsqKOOyimnnJIkOeKII3Lfffd1Wet0TOoi5K21F1prxydZmOSkqnpLkj9J8htJTkzyxoyemZQkNd4upjG+K5PapqpWV9XGqtq4ZcuWCXYJAAAAQA9Tugtea+2nGf0Z3IrW2mNt1HNJ/jaj13VKRs9GOnzMZguTPDrB+MJxxpPk8eHnexn+/niCY+y43itaa0tba0vnz58/lY8KAAAAwB4ymbvgza+qg4bn+yV5Z5L/PSYMVUav2XTvsMl1SVYOd6pblmTb8DO6G5OcXlUHDxcfPz3JjcN7T1XVsmFfK5NcO2Zf2++Wt2qH8fGOAQAAAMAsM5lrQC1Ism64DtQbklzdWvtGVd1cVfMz+nO4u5J8dJh/Q5Izk2xK8kySDydJa+2JqvrzJLcP8y7afkHyJB9LcmWS/TJ68fFvDuOXJLm6qs5N8sMk79/VMQAAAACYfSZzF7y7k5wwzvipO5nfkpy3k/fWJlk7zvjGJG8ZZ3xrktOmcgwAAAAAZpcpXQMKAAAAAKZqMj/BAwAAAHj9WHPgHt7ftgmnXHrppbn88suzZMmSfPnLX96zx5+CK6+8Mhs3bsxf/dVf7dH9ClAA7Hl7+j/Yu2MS/7EHAICZdtlll+Wb3/xmjjzyyAnnPv/885kzZ/eTTmstrbW84Q39fyDnJ3gAAAAAM+ijH/1oHn744bznPe/JZz7zmZx99tk57rjjsmzZstx9991JkjVr1mT16tU5/fTTs3Llypx55pkvvnfCCSfkoosuSpL86Z/+af7mb/4mTz/9dE477bQsWbIkxx57bK699tokyebNm3P00Ufn4x//eJYsWZJHHnkkf/u3f5tf+7Vfy+/8zu/k29/+dpfPKEABAAAAzKC//uu/zi//8i9nw4YN2bx5c0444YTcfffd+Yu/+IusXLnyxXl33HFHrr322vzd3/1d3vGOd+Qf//Ef87Of/Sxz5sx5MRzdeuutWb58eebNm5evfe1r+f73v58NGzbkE5/4REbv6ZY8+OCDWblyZe68887su+++ufDCC/Ptb38769evz/3339/lMwpQAAAAALPErbfemg996ENJklNPPTVbt27Ntm2jl5V4z3vek/322y9Jsnz58nzrW9/Krbfemne/+915+umn88wzz2Tz5s359V//9bTW8slPfjLHHXdc3vnOd+ZHP/pRHn/88STJr/zKr2TZsmVJkttuuy2nnHJK5s+fn3333Td/8Ad/0OVzuQYUAAAAwCyx/SylsaoqSfKLv/iLL46deOKJ2bhxY4466qj87u/+bn7yk5/k85//fN72trclSb785S9ny5YtueOOOzJ37twsWrQozz777Cv2M3b/PTkDCgAAAGCWeMc73vHiXfBuueWWHHrooTnggANeMW/ffffN4YcfnquvvjrLli3L8uXL8+lPfzrLly9Pkmzbti1vetObMnfu3GzYsCH/+q//Ou7xTj755Nxyyy3ZunVrfv7zn+erX/1ql8/lDCgAAGCPWHTB9TO9hCTJ5kvePdNLAPZ2M3gn5TVr1uTDH/5wjjvuuOy///5Zt27dTucuX748N910U/bff/8sX748IyMjLwaoD37wg/n93//9LF26NMcff3x+4zd+Y9x9LFiwIGvWrMlv/dZvZcGCBVmyZEleeOGFPf65arxTu16Lli5d2jZu3DjTywB4fVhz4Eyv4CUz+D8PAK83AhSwt3rggQdy9NFHz/QyZr3x/p2q6o7W2tKJtvUTPAAAAAC6EqAAAAAA6EqAAgAAAF73Xi+XKJqu3f33EaAAAACA17V58+Zl69atItROtNaydevWzJs3b9r7cBc8AAAA4HVt4cKFGRkZyZYtW2Z6KbPWvHnzsnDhwmlvL0ABAAAAr2tz587NkUceOdPLeE3zEzwAAAAAuhKgAAAAAOhKgAIAAACgKwEKAAAAgK4EKAAAAAC6chc8gNeIRRdcP9NLeNHmeTO9AgAAYDZxBhQAAAAAXQlQAAAAAHQlQAEAAADQlQAFAAAAQFcCFAAAAABdCVAAAAAAdCVAAQAAANCVAAUAAABAVwIUAAAAAF0JUAAAAAB0JUABAAAA0JUABQAAAEBXAhQAAAAAXQlQAAAAAHQlQAEAAADQlQAFAAAAQFcCFAAAAABdCVAAAAAAdCVAAQAAANDVnJleAADw6lt0wfUzvYQkyeZL3j3TSwAA4FXgDCgAAAAAuhKgAAAAAOhKgAIAAACgKwEKAAAAgK4EKAAAAAC6EqAAAAAA6EqAAgAAAKCrOTO9AAAAgD1qzYEzvYKXrNk20ysAmBWcAQUAAABAVwIUAAAAAF0JUAAAAAB0JUABAAAA0JUABQAAAEBXAhQAAAAAXQlQAAAAAHQlQAEAAADQlQAFAAAAQFcCFAAAAABdCVAAAAAAdCVAAQAAANCVAAUAAABAVwIUAAAAAF0JUAAAAAB0JUABAAAA0NWEAaqq5lXV96rqB1V1X1X912H8yKq6raoeqqq/r6p9h/FfGF5vGt5fNGZffzKMP1hV7xozvmIY21RVF4wZn/IxAAAAAJhdJnMG1HNJTm2tvTXJ8UlWVNWyJH+Z5LOttcVJnkxy7jD/3CRPttZ+Nclnh3mpqmOSnJPkN5OsSHJZVe1TVfsk+VySM5Ick+QDw9xM9RgAAAAAzD4TBqg26unh5dzh0ZKcmuSaYXxdkrOH52cNrzO8f1pV1TB+VWvtudbavyTZlOSk4bGptfZwa+3fk1yV5Kxhm6keAwAAAIBZZlLXgBrOVLoryY+TrE/yz0l+2lp7fpgykuSw4flhSR5JkuH9bUkOGTu+wzY7Gz9kGscAAAAAYJaZVIBqrb3QWjs+ycKMnrF09HjThr/jnYnU9uD4ro7xMlW1uqo2VtXGLVu2jLMJAAAAAL3Nmcrk1tpPq+qWJMuSHFRVc4YzkBYmeXSYNpLk8CQjVTUnyYFJnhgzvt3YbcYb/8k0jrHjeq9IckWSLF269BWBCgCYYWsOnOkVvGTNtpleAQDAa9Zk7oI3v6oOGp7vl+SdSR5IsiHJ+4Zpq5JcOzy/bnid4f2bW2ttGD9nuIPdkUkWJ/lektuTLB7ueLdvRi9Uft2wzVSPAQAAAMAsM5kzoBYkWTfcre4NSa5urX2jqu5PclVVXZzkziRfGOZ/IcmXqmpTRs9KOidJWmv3VdXVSe5P8nyS81prLyRJVZ2f5MYk+yRZ21q7b9jXH0/lGAAAAADMPhMGqNba3UlOGGf84YxeD2rH8WeTvH8n+/pUkk+NM35Dkhv2xDEAAAAAmF0mdRFyAAAAAJguAQoAAACArgQoAAAAALoSoAAAAADoSoACAAAAoCsBCgAAAICuBCgAAAAAuhKgAAAAAOhqzkwvAAAAJmXNgTO9gpes2TbTKwCAvYozoAAAAADoSoACAAAAoCsBCgAAAICuBCgAAAAAuhKgAAAAAOhKgAIAAACgKwEKAAAAgK4EKAAAAAC6EqAAAAAA6EqAAgAAAKArAQoAAACArgQoAAAAALoSoAAAAADoas5MLwDYtUUXXD/TS0iSbL7k3TO9BAAAAPZSzoACAAAAoCtnQAGTs+bAmV7BS9Zsm+kVAACwG2bLWf6JM/3h1eIMKAAAAAC6EqAAAAAA6EqAAgAAAKArAQoAAACArgQoAAAAALoSoAAAAADoSoACAAAAoCsBCgAAAICuBCgAAAAAuhKgAAAAAOhKgAIAAACgKwEKAAAAgK4EKAAAAAC6EqAAAAAA6EqAAgAAAKCrOTO9AAAAZq9FF1w/00t40eZ5M70CAGC6nAEFAAAAQFcCFAAAAABdCVAAAAAAdCVAAQAAANCVi5ADAADw+rXmwJlewUvWbJvpFUA3zoACAAAAoCsBCgAAAICuBCgAAAAAuhKgAAAAAOhKgAIAAACgKwEKAAAAgK4EKAAAAAC6EqAAAAAA6EqAAgAAAKArAQoAAACArgQoAAAAALoSoAAAAADoSoACAAAAoCsBCgAAAICuBCgAAAAAuhKgAAAAAOhKgAIAAACgKwEKAAAAgK4EKAAAAAC6EqAAAAAA6GrCAFVVh1fVhqp6oKruq6r/PIyvqaofVdVdw+PMMdv8SVVtqqoHq+pdY8ZXDGObquqCMeNHVtVtVfVQVf19Ve07jP/C8HrT8P6iiY4BAAAAwOwymTOgnk/yidba0UmWJTmvqo4Z3vtsa+344XFDkgzvnZPkN5OsSHJZVe1TVfsk+VySM5Ick+QDY/bzl8O+Fid5Msm5w/i5SZ5srf1qks8O83Z6jGn/KwAAAADQzYQBqrX2WGvt+8Pzp5I8kOSwXWxyVpKrWmvPtdb+JcmmJCcNj02ttYdba/+e5KokZ1VVJTk1yTXD9uuSnD1mX+uG59ckOW2Yv7NjAAAAADDLTOkaUMNP4E5IctswdH5V3V1Va6vq4GHssCSPjNlsZBjb2fghSX7aWnt+h/GX7Wt4f9swf2f7AgAAAGCWmXSAqqr/kOS/J/kvrbWfJbk8yX9McnySx5J8ZvvUcTZv0xifzr52XPPqqtpYVRu3bNkyziYAAAAA9DapAFVVczMan77cWvsfSdJae7y19kJr7f8k+Xxe+gncSJLDx2y+MMmjuxj/SZKDqmrODuMv29fw/oFJntjFvl6mtXZFa21pa23p/PnzJ/NRAQAAANjDJnMXvEryhSQPtNb+25jxBWOmvTfJvcPz65KcM9zB7sgki5N8L8ntSRYPd7zbN6MXEb+utdaSbEjyvmH7VUmuHbOvVcPz9yW5eZi/s2MAAAAAMMvMmXhK3p7kQ0nuqaq7hrFPZvQudsdn9Kdvm5N8JElaa/dV1dVJ7s/oHfTOa629kCRVdX6SG5Psk2Rta+2+YX9/nOSqqro4yZ0ZDV4Z/n6pqjZl9MyncyY6BgAAAACzy4QBqrV2a8a/5tINu9jmU0k+Nc74DeNt11p7OOPcxa619myS90/lGAAAAADMLlO6Cx4AAAAATJUABQAAAEBXAhQAAAAAXQlQAAAAAHQlQAEAAADQlQAFAAAAQFcCFAAAAABdCVAAAAAAdCVAAQAAANCVAAUAAABAVwIUAAAAAF0JUAAAAAB0JUABAAAA0JUABQAAAEBXAhQAAAAAXQlQAAAAAHQlQAEAAADQlQAFAAAAQFcCFAAAAABdCVAAAAAAdCVAAQAAANCVAAUAAABAVwIUAAAAAF0JUAAAAAB0JUABAAAA0JUABQAAAEBXAhQAAAAAXQlQAAAAAHQlQAEAAADQlQAFAAAAQFcCFAAAAABdCVAAAAAAdCVAAQAAANCVAAUAAABAVwIUAAAAAF0JUAAAAAB0JUABAAAA0JUABQAAAEBXAhQAAAAAXQlQAAAAAHQlQAEAAADQlQAFAAAAQFcCFAAAAABdCVAAAAAAdCVAAQAAANCVAAUAAABAVwIUAAAAAF0JUAAAAAB0JUABAAAA0JUABQAAAEBXAhQAAAAAXQlQAAAAAHQlQAEAAADQlQAFAAAAQFcCFAAAAABdCVAAAAAAdCVAAQAAANCVAAUAAABAVwIUAAAAAF0JUAAAAAB0JUABAAAA0JUABQAAAEBXAhQAAAAAXQlQAAAAAHQlQAEAAADQlQAFAAAAQFcTBqiqOryqNlTVA1V1X1X952H8jVW1vqoeGv4ePIxXVV1aVZuq6u6qWjJmX6uG+Q9V1aox42+rqnuGbS6tqpruMQAAAACYXSZzBtTzST7RWjs6ybIk51XVMUkuSHJTa21xkpuG10lyRpLFw2N1ksuT0ZiU5MIkJyc5KcmF24PSMGf1mO1WDONTOgYAAAAAs8+EAaq19lhr7fvD86eSPJDksCRnJVk3TFuX5Ozh+VlJvthG/VOSg6pqQZJ3JVnfWnuitfZkkvVJVgzvHdBa+25rrSX54g77msoxAAAAAJhlpnQNqKpalOSEJLcleXNr7bFkNFIledMw7bAkj4zZbGQY29X4yDjjmcYxAAAAAJhlJh2gquo/JPnvSf5La+1nu5o6zlibxvgulzOZbapqdVVtrKqNW7ZsmWCXAAAAAPQwqQBVVXMzGp++3Fr7H8Pw49t/9jb8/fEwPpLk8DGbL0zy6ATjC8cZn84xXqa1dkVrbWlrben8+fMn81EBAAAA2MMmcxe8SvKFJA+01v7bmLeuS7L9Tnarklw7ZnzlcKe6ZUm2DT+fuzHJ6VV18HDx8dOT3Di891RVLRuOtXKHfU3lGAAAAADMMnMmMeftST6U5J6qumsY+2SSS5JcXVXnJvlhkvcP792Q5Mwkm5I8k+TDSdJae6Kq/jzJ7cO8i1prTwzPP5bkyiT7Jfnm8MhUjwEAAADA7DNhgGqt3Zrxr7mUJKeNM78lOW8n+1qbZO044xuTvGWc8a1TPQYAAAAAs8uU7oIHAAAAAFMlQAEAAADQlQAFAAAAQFcCFAAAAABdCVAAAAAAdCVAAQAAANCVAAUAAABAVwIUAAAAAF0JUAAAAAB0JUABAAAA0JUABQAAAEBXAhQAAAAAXQlQAAAAAHQlQAEAAADQlQAFAAAAQFcCFAAAAABdCVAAAAAAdCVAAQAAANCVAAUAAABAVwIUAAAAAF0JUAAAAAB0JUABAAAA0JUABQAAAEBXAhQAAAAAXQlQAAAAAHQlQAEAAADQlQAFAAAAQFcCFAAAAABdCVAAAAAAdCVAAQAAANCVAAUAAABAVwIUAAAAAF0JUAAAAAB0JUABAAAA0JUABQAAAEBXAhQAAAAAXQlQAAAAAHQlQAEAAADQlQAFAAAAQFcCFAAAAABdCVAAAAAAdCVAAQAAANCVAAUAAABAVwIUAAAAAF0JUAAAAAB0JUABAAAA0JUABQAAAEBXAhQAAAAAXQlQAAAAAHQlQAEAAADQlQAFAAAAQFcCFAAAAABdCVAAAAAAdCVAAQAAANCVAAUAAABAVwIUAAAAAF0JUAAAAAB0JUABAAAA0JUABQAAAEBXAhQAAAAAXQlQAAAAAHQlQAEAAADQlQAFAAAAQFcCFAAAAABdCVAAAAAAdCVAAQAAANDVhAGqqtZW1Y+r6t4xY2uq6kdVddfwOHPMe39SVZuq6sGqeteY8RXD2KaqumDM+JFVdVtVPVRVf19V+w7jvzC83jS8v2iiYwAAAAAw+0zmDKgrk6wYZ/yzrbXjh8cNSVJVxyQ5J8lvDttcVlX7VNU+ST6X5IwkxyT5wDA3Sf5y2NfiJE8mOXcYPzfJk621X03y2WHeTo8xtY8NAAAAwKtlwgDVWvtWkicmub+zklzVWnuutfYvSTYlOWl4bGqtPdxa+/ckVyU5q6oqyalJrhm2X5fk7DH7Wjc8vybJacP8nR0DAAAAgFlod64BdX5V3T38RO/gYeywJI+MmTMyjO1s/JAkP22tPb/D+Mv2Nby/bZi/s30BAAAAMAtNN0BdnuQ/Jjk+yWNJPjOM1zhz2zTGp7OvV6iq1VW1sao2btmyZbwpAAAAAHQ2rQDVWnu8tfZCa+3/JPl8XvoJ3EiSw8dMXZjk0V2M/yTJQVU1Z4fxl+1reP/AjP4UcGf7Gm+dV7TWlrbWls6fP386HxUAAACA3TStAFVVC8a8fG+S7XfIuy7JOcMd7I5MsjjJ95LcnmTxcMe7fTN6EfHrWmstyYYk7xu2X5Xk2jH7WjU8f1+Sm4f5OzsGAAAAALPQnIkmVNVXkpyS5NCqGklyYZJTqur4jP70bXOSjyRJa+2+qro6yf1Jnk9yXmvthWE/5ye5Mck+Sda21u4bDvHHSa6qqouT3JnkC8P4F5J8qao2ZfTMp3MmOgYAAAAAs8+EAaq19oFxhr8wztj2+Z9K8qlxxm9IcsM44w9nnLvYtdaeTfL+qRwDAAAAgNlnd+6CBwAAAAATEqAAAAAA6EqAAgAAAKArAQoAAACArgQoAAAAALoSoAAAAADoSoACAAAAoCsBCgAAAICuBCgAAAAAuhKgAAAAAOhKgAIAAACgKwEKAAAAgK4EKAAAAAC6EqAAAAAA6EqAAgAAAKArAQoAAACArgQoAAAAALoSoAAAAADoSoACAAAAoCsBCgAAAICuBCgAAAAAuhKgAAAAAOhKgAIAAACgKwEKAAAAgK4EKAAAAAC6EqAAAAAA6EqAAgAAAKArAQoAAACArgQoAAAAALqaM9MLYIatOXCmV/CSNdtmegUAAABAB86AAgAAAKArAQoAAACArgQoAAAAALoSoAAAAADoSoACAAAAoCsBCgAAAICuBCgAAAAAuhKgAAAAAOhKgAIAAACgKwEKAAAAgK4EKAAAAAC6EqAAAAAA6EqAAgAAAKArAQoAAACArgQoAAAAALoSoAAAAADoSoACAAAAoCsBCgAAAICuBCgAAAAAuhKgAAAAAOhKgAIAAACgKwEKAAAAgK4EKAAAAAC6EqAAAAAA6EqAAgAAAKArAQoAAACArgQoAAAAALoSoAAAAADoSoACAAAAoKs5M72A16NFF1w/00t40eZ5M70CAAAA4LXOGVAAAAAAdCVAAQAAANCVAAUAAABAVwIUAAAAAF0JUAAAAAB0JUABAAAA0NWEAaqq1lbVj6vq3jFjb6yq9VX10PD34GG8qurSqtpUVXdX1ZIx26wa5j9UVavGjL+tqu4Ztrm0qmq6xwAAAABg9pnMGVBXJlmxw9gFSW5qrS1OctPwOknOSLJ4eKxOcnkyGpOSXJjk5CQnJblwe1Aa5qwes92K6RwDAAAAgNlpwgDVWvtWkid2GD4rybrh+bokZ48Z/2Ib9U9JDqqqBUnelWR9a+2J1tqTSdYnWTG8d0Br7buttZbkizvsayrHAAAAAGAWmu41oN7cWnssSYa/bxrGD0vyyJh5I8PYrsZHxhmfzjEAAAAAmIX29EXIa5yxNo3x6RzjlROrVlfVxqrauGXLlgl2CwAAAEAP0w1Qj2//2dvw98fD+EiSw8fMW5jk0QnGF44zPp1jvEJr7YrW2tLW2tL58+dP6QMCAAAAsGdMN0Bdl2T7nexWJbl2zPjK4U51y5JsG34+d2OS06vq4OHi46cnuXF476mqWjbc/W7lDvuayjEAAAAAmIXmTDShqr6S5JQkh1bVSEbvZndJkqur6twkP0zy/mH6DUnOTLIpyTNJPpwkrbUnqurPk9w+zLuotbb9wuYfy+id9vZL8s3hkakeAwAAAIDZacIA1Vr7wE7eOm2cuS3JeTvZz9oka8cZ35jkLeOMb53qMQAAAAAxOKlHAAARXElEQVSYffb0RcgBAAAA4GUEKAAAAAC6EqAAAAAA6EqAAgAAAKArAQoAAACArgQoAAAAALoSoAAAAADoSoACAAAAoCsBCgAAAICuBCgAAAAAuhKgAAAAAOhKgAIAAACgKwEKAAAAgK4EKAAAAAC6EqAAAAAA6EqAAgAAAKArAQoAAACArgQoAAAAALoSoAAAAADoas5MLwAAAABg1ltz4Eyv4CVrts30CqbMGVAAAAAAdCVAAQAAANCVAAUAAABAVwIUAAAAAF0JUAAAAAB0JUABAAAA0JUABQAAAEBXAhQAAAAAXQlQAAAAAHQlQAEAAADQlQAFAAAAQFcCFAAAAABdCVAAAAAAdCVAAQAAANCVAAUAAABAVwIUAAAAAF0JUAAAAAB0JUABAAAA0JUABQAAAEBXAhQAAAAAXQlQAAAAAHQlQAEAAADQlQAFAAAAQFcCFAAAAABdCVAAAAAAdCVAAQAAANCVAAUAAABAVwIUAAAAAF0JUAAAAAB0JUABAAAA0JUABQAAAEBXAhQAAAAAXQlQAAAAAHQ1Z6YXAAAAALAziy64fqaXkCTZPG+mV7B3cwYUAAAAAF0JUAAAAAB0JUABAAAA0JUABQAAAEBXAhQAAAAAXQlQAAAAAHQlQAEAAADQlQAFAAAAQFcCFAAAAABdCVAAAAAAdCVAAQAAANCVAAUAAABAV7sVoKpqc1XdU1V3VdXGYeyNVbW+qh4a/h48jFdVXVpVm6rq7qpaMmY/q4b5D1XVqjHjbxv2v2nYtnZ1DAAAAABmnz1xBtR/aq0d31pbOry+IMlNrbXFSW4aXifJGUkWD4/VSS5PRmNSkguTnJzkpCQXjglKlw9zt2+3YoJjAAAAADDL9PgJ3llJ1g3P1yU5e8z4F9uof0pyUFUtSPKuJOtba0+01p5Msj7JiuG9A1pr322ttSRf3GFf4x0DAAAAgFlmdwNUS/K/quqOqlo9jL25tfZYkgx/3zSMH5bkkTHbjgxjuxofGWd8V8cAAAAAYJaZs5vbv7219mhVvSnJ+qr637uYW+OMtWmMT9oQxVYnyRFHHDGVTQEAAADYQ3brDKjW2qPD3x8n+VpGr+H0+PDzuQx/fzxMH0ly+JjNFyZ5dILxheOMZxfH2HF9V7TWlrbWls6fP3+6HxMAAACA3TDtAFVVv1hVv7T9eZLTk9yb5Lok2+9ktyrJtcPz65KsHO6GtyzJtuHnczcmOb2qDh4uPn56khuH956qqmXD3e9W7rCv8Y4BAAAAwCyzOz/Be3OSr422ocxJ8nettf9ZVbcnubqqzk3ywyTvH+bfkOTMJJuSPJPkw0nSWnuiqv48ye3DvItaa08Mzz+W5Mok+yX55vBIkkt2cgwAAAAAZplpB6jW2sNJ3jrO+NYkp40z3pKct5N9rU2ydpzxjUneMtljAAAAADD77O5d8AAAAABglwQoAAAAALoSoAAAAADoSoACAAAAoCsBCgAAAICuBCgAAAAAuhKgAAAAAOhKgAIAAACgKwEKAAAAgK4EKAAAAAC6EqAAAAAA6EqAAgAAAKArAQoAAACArgQoAAAAALoSoAAAAADoSoACAAAAoCsBCgAAAICuBCgAAAAAuhKgAAAAAOhKgAIAAACgKwEKAAAAgK4EKAAAAAC6EqAAAAAA6EqAAgAAAKArAQoAAACArgQoAAAAALoSoAAAAADoSoACAAAAoCsBCgAAAICuBCgAAAAAuhKgAAAAAOhKgAIAAACgKwEKAAAAgK4EKAAAAAC6EqAAAAAA6EqAAgAAAKArAQoAAACArgQoAAAAALoSoAAAAADoSoACAAAAoCsBCgAAAICuBCgAAAAAuhKgAAAAAOhKgAIAAACgKwEKAAAAgK4EKAAAAAC6EqAAAAAA6EqAAgAAAKArAQoAAACArgQoAAAAALoSoAAAAADoSoACAAAAoCsBCgAAAICuBCgAAAAAuhKgAAAAAOhKgAIAAACgKwEKAAAAgK4EKAAAAAC6EqAAAAAA6EqAAgAAAKArAQoAAACArgQoAAAAALoSoAAAAADoSoACAAAAoCsBCgAAAICuBCgAAAAAutqrA1RVraiqB6tqU1VdMNPrAQAAAOCV9toAVVX7JPlckjOSHJPkA1V1zMyuCgAAAIAd7bUBKslJSTa11h5urf17kquSnDXDawIAAABgB3tzgDosySNjXo8MYwAAAADMItVam+k1TEtVvT/Ju1pr//fw+kNJTmqt/T9j5qxOsnp4+etJHnzVFzr7HZrkJzO9CPYKvitMhe8Lk+W7wlT4vjBZvitMhe8Lk+W7Mr5faa3Nn2jSnFdjJZ2MJDl8zOuFSR4dO6G1dkWSK17NRe1tqmpja23pTK+D2c93hanwfWGyfFeYCt8XJst3hanwfWGyfFd2z978E7zbkyyuqiOrat8k5yS5bobXBAAAAMAO9tozoFprz1fV+UluTLJPkrWttftmeFkAAAAA7GCvDVBJ0lq7IckNM72OvZyfKDJZvitMhe8Lk+W7wlT4vjBZvitMhe8Lk+W7shv22ouQAwAAALB32JuvAQUAAADAXkCAeo2rqjVV9f9O5v2q+r/+//buPtiqqg7j+PcJSGRQEDVHx/TOmGC+DDSahaLYaFNWShZGjZnXsZzSdGxCnalsmLQXpRobDV+HQHPMV3z7A8UUuCCIQpd7Ad9ImdTMqVSSRCX59cdaBzaHc7n3wj0v9/B8Zvawzt5rr7PO2T/W2mfttfeVtF/tamf1Imm4pPNy+gRJD/Vyf8dKE5O0RtJeO5qnLH+v48waW63iRNIMSRNz+mZJh3ZTxqb8Vn+SWiSt6EX+HvUvPs7NpZZxImld/nc/SXf3oIx1Pa2XNbfexqnt3HK8hKTLC+v2krRB0rX59XclfauLfZsy1jwAZUWtgAcVdg7DgfN2YP9WHCtmVmMR8e2IWFXvelhVteL+xbrXyg7GSUT8PSI8iGlm1fQi8KXC69OBTX84LSKuj4hbal6rOvIAVBOS9GNJz0l6FBiV1x0kabakpZLaJB1Sts9E4CjgNkntknaV9FNJT0laIelGSarDx7Hq+BVwkKR2YCowVNLdkp6VdFvpWEs6UtK8HDcPS9rXsdJcJN2Xj+9KSeeWbWvJMTFTUkeOkSGFLBdIWiaps9SmSDpa0hOS/pL/HdXN+5+Y83ZKmi5pl1zGvXn7BEnrJX1Y0mBJL/b5l2DdqnecFN5rrqSjcvocSc/ndTeVriZmx+dyX/QsmYYwsDw+qtG/KJma83ZKmpTXT5N0ak7PkjQ9p8+RdEUtvgDrkZrESYkKMwzye92Z3/sOSU+W2pq8/eeSlktaLGmf6n0FViTpsty/zJF0u6TJkr6Tj/VySfeU+hul2W7XSXo8t/3j83nFM5JmFMpcJ+nKHFOP5v5obt6n1E60KP1eWpaXY7qp55gcGx25jdlD0kckLc3bRyvNhDkgv/5rWT9pfaBB42U98EyhPZkE3Fkov3g30pG5nouA86v7bdVRRHhpogU4EugEhgC7A6uBycCfgYNznk8Bj+X0FGByTs8FjiqUNaKQvhU4pd6fz0ufxUkLsCKnTwDWAvuTBqUXAeOAQcATwN453yRgumOluZbSsQN2BVYAewJrgL1ynARwbM4zvdBerAEuyOnzgJtzendgYE6fBNxTiLOHyt57MPAyMDK/vgW4iPQXWl/K634NPAUcC4wHbq/3d7YzLjWOk7VAe2F5A5iYt88l/fDcL5c9IrdVbcC1Oc8M4K7cnh0KrK7397czL13Ex8U72r/k4zyx7L2+CswBBgD7AH8D9gW+DkzNeZYAi3P6D8Dn6v0deal6nLxU1qasK7xn6VxoMnBDTh8O/K9Ufq5XqbyrgJ/U+/vaGZbc1reT+p3dgBfycdqzkOcKNvcxM4A/AQImAP8Bjsh9wVJgTOF4npzTs4BHcj8yGmjP64cAg3P6YODp8pgpq2sHMD6nfwZcndMrSf3d90nnMmcABwKL6v39NtvSyPECnEo6n92f9Ju8lc3nLFPYfM5UjKOplWKtGZaBWLM5DpgVEe8ASHqA9CPvGOCuwgWhXXpQ1mckXUL6TzWC1Ig+2Oc1tkawJCJeAVCaFdUCvEU6CZuT42YA8FoX+ztW+q8LJZ2W0x8ldZxFL0fEwpz+I3AhqRMFuDf/uxT4Sk4PA2ZKOpjUaQ/axnuPIg00PZ9fzwTOj4irJa2W9HHgaOC3wPGkGGzr7Qe0PlHLOGmLiE3T1YtXIguOBuZFxBs5z13AyML2+yJiI7DKsxUaQnl8/Ijq9C/jSIPUHwCvS5oHfJLUblyk9PywVcAekvYFxpJi1RpDteLk4ojY9KwnVX6m0zjgdwARsUJSR2Hb+0Dp2XRLgc/28nPZ9hkH3B8R6wEklY7n4UozF4cDQ4GHC/s8GBEhqRN4PSI6874rSee27aTjOTvn7wTei4gNeZ+WvH4QcK2kMcAHbNm/bEHSMGB4RMzLq2aSLoJAGkA9lnQO8wvg86QBD5/L9L1GjpfZwOXA68AdlSpfIY5uBU7u1TfQT3gAqjlF2esPAW9FxJieFiBpMDCNdPXnZUlTSANZ1pzeK6Q/ILUNAlZGxNht7ehY6b8knUCafTI2It6RNJetj115e1J8XYqbUsxA6mAfj4jTJLWQrlJ3WYVtbGsjdbwbgEdJV6oGkK5mWQ01QJxUrFY324ttmm8Jrr/y+Hib6vQvFY91RLwqaQ/Sj7/5pAGKr5Fmwrzds49gNVCrOKlYzDa2bYg8JYEt2zGrrq6OyQzgyxGxXFIraeZsSant38iW/cBGNh+34vHclC8iNkoq5fkBabBgNOl31Lvb+RnaSJMDDgTuBy4lxbn/KEvfa9h4iYj38+2YPwQOA07pov7lbWBT8jOgms984DSl++F3IwX4O8BLkk6HTc9IGF1h37dJUxZhc8f9L0lDAT9Do7kUj3VXngP2ljQWQNIgSYdV2N+x0n8NA97MgwqHAJ+ukOeAUgwA3wAW9KDMV3O6tZu8zwItkj6WX58JlK78zCfdjrcoIv5JuuXrEAoPbrSaqXecVLIEGJ+fszGQdOuVNa7y+FhMdfqX+cAkSQMk7U2adbAkb1tEalPmk34UTsazEBpNreKkkgWkQUnyTLkjtqMM61sLgFOUnv84FPhiXr8b8JqkQaRb2qphGPBankl7JukCWEURsRZ4U9JxeVX5ucw3gRdyWW8AXwAWblWQ7ahGj5ffAJdGxL8rFRARbwFrJY3Lq6pV17rzAFSTiYhlpKl97cA9bD65OgM4R9Jy0g+4CRV2nwFcn2/Beg+4iTTV8D7SfcvWJHLjt1Dp4ZtTu8jzPukk7socN+2kWznBsdIsZpMe+tpBmpGyuEKeZ4Czcp4RwHXdlHkV8EtJC9m6Az5R0iulBfgEcDbp9uBO0pWl63PeJ0nPcJmfX3cAHYWrUFY7tY6TbkXEq6TbGZ4kzZBbRXp2lDWm8vi4hr7pX24otCmLSM/n6ACWA48Bl0TEP3LeNtJzx1YDy3I9PADVWKoVJz0xjTTY1UGapdKB25S6ioingAdI/5/vBZ4mHZPLSG3/HNKFrGqYRorFxaTbqf5b2DaqeC6TL/CfBUzN8TOG9BwoImJN3qd0LrOAdFfKm1Wq906rgeOlVL+VETGzm3LOBn6f+7P1fV/NxiCfy5uZWSX51qiHIuLwOlfFGli94kTS0IhYl2dAzSI9nHhWLetgZs1B0gBgUES8K+kg0oOCR+aLcVYnhXZ+CGkQ59x8sd1sK46X/sH3MJuZmVl/NEXSSaTbbx4hzXwwM9seQ4DH8206Ar7nwaeGcGO+JXIwMNODCdYNx0s/4BlQZmZmZmZmZmZWVX4GlJmZmZmZmZmZVZUHoMzMzMzMzMzMrKo8AGVmZmZmZmZmZlXlASgzMzMzMzMzM6sqD0CZmZmZmZmZmVlVeQDKzMzMzMzMzMyq6v+2c717RSIfLgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "u = [back1.delta.mean(), back1.theta.mean(), back1.alphaLow.mean(), \n",
    "     back1.betaHigh.mean(), back1.betaLow.mean(), back1.alphaHigh.mean(), \n",
    "     back1.gammaLow.mean(), back1.gammaMid.mean()]\n",
    "\n",
    "d = [forward.delta.mean(), forward.theta.mean(), forward.alphaLow.mean(), \n",
    "     forward.betaHigh.mean(), forward.betaLow.mean(), forward.alphaHigh.mean(), \n",
    "     forward.gammaLow.mean(), forward.gammaMid.mean()]\n",
    "\n",
    "\n",
    "index = ['delta', 'theta', 'alphaLow','alphaHigh', 'betaLow', 'betaHigh', 'gammaLow', 'gammaMid']\n",
    "\n",
    "df = pd.DataFrame({'back': u, 'forward': d}, index=index)\n",
    "ax = df.plot.bar(rot=0, figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# create an array of shape 30706, 9 = number of records by the features\n",
    "data = np.array([[0 for x in range(8)] for y in range(len(dataDF))])\n",
    "for i in range(len(dataDF)):\n",
    "    data[i] = [dataDF.delta.values[i],\n",
    "                       dataDF.theta.values[i],\n",
    "                       dataDF.alphaLow.values[i],\n",
    "                       dataDF.alphaHigh.values[i],\n",
    "                       dataDF.betaLow.values[i],\n",
    "                       dataDF.betaHigh.values[i],\n",
    "                       dataDF.gammaLow.values[i],\n",
    "                       dataDF.gammaMid.values[i]]\n",
    "    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "encoder = LabelBinarizer()\n",
    "labels = encoder.fit_transform(dataDF.action.values)\n",
    "\n",
    "# creating training and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, labels)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "scaler = MinMaxScaler()\n",
    "stan_scaler = StandardScaler()\n",
    "\n",
    "x_train = stan_scaler.fit_transform(x_train)\n",
    "x_test = stan_scaler.transform(x_test)\n",
    "\n",
    "all_data = dataDF.drop(['action'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.18211517 0.17171235 0.09686154 0.12006524 0.12216572 0.1008706\n",
      " 0.1069534  0.09925598]\n",
      "The score for Random Forest  0.6299212598425197\n",
      "1140\n",
      "Accuracy for x_test: 0.6299212598425197\n",
      "Cross Validation Accuracy: 0.63 (+/- 0.25)\n",
      "[0.39869281 0.45751634 0.50326797 0.61842105 0.69736842 0.72368421\n",
      " 0.67105263 0.74342105 0.81456954 0.65562914]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Random Forrest\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(x_train, y_train)\n",
    "\n",
    "print(rfc.feature_importances_)\n",
    "\n",
    "print(\"The score for Random Forest \", rfc.score(x_test, y_test))\n",
    "y_pred = rfc.predict(x_test)\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(len(y_train))\n",
    "print(\"Accuracy for x_test:\", metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "scores = cross_val_score(rfc, all_data, labels, cv=10, scoring='accuracy')\n",
    "print(\"Cross Validation Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "The score for XGBoost  0.6692913385826772\n",
      "Accuracy for x_test: 0.6692913385826772\n",
      "Accuracy: 66.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracy: 0.66 (+/- 0.32)\n",
      "[0.38562092 0.44444444 0.47712418 0.61842105 0.80263158 0.75\n",
      " 0.70394737 0.83552632 0.80794702 0.7615894 ]\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(x_train, y_train)\n",
    "\n",
    "# plot feature importance\n",
    "plot_importance(xgb)\n",
    "pyplot.show()\n",
    "print(xgb)\n",
    "print(\"The score for XGBoost \", xgb.score(x_test, y_test))\n",
    "y_pred = xgb.predict(x_test)\n",
    "\n",
    "print(\"Accuracy for x_test:\", metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = metrics.accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "\n",
    "scores = cross_val_score(xgb, all_data, labels, cv=10, scoring='accuracy')\n",
    "print(\"Cross Validation Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_set = [(x_train, y_train), (x_test, y_test)]\n",
    "eval_metric = [\"auc\",\"error\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Tuning and feature importance XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score for XGBoost  0.7615894039735099\n",
      "Accuracy for x_test: 0.7615894039735099\n",
      "Accuracy: 76.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracy: 0.65 (+/- 0.33)\n",
      "[0.35294118 0.49019608 0.43137255 0.59210526 0.76973684 0.73026316\n",
      " 0.77631579 0.79605263 0.82781457 0.7615894 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresh=0.031, n=8, Accuracy: 76.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresh=0.046, n=7, Accuracy: 76.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresh=0.068, n=6, Accuracy: 74.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresh=0.075, n=5, Accuracy: 74.83%\n",
      "Thresh=0.093, n=4, Accuracy: 75.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresh=0.101, n=3, Accuracy: 79.47%\n",
      "Thresh=0.197, n=2, Accuracy: 81.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresh=0.389, n=1, Accuracy: 81.46%\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "from numpy import sort\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "xgb = XGBClassifier(silent=True, \n",
    "                      scale_pos_weight=1,\n",
    "                      learning_rate=0.01,  \n",
    "                      colsample_bytree = 0.4,\n",
    "                      subsample = 0.3,\n",
    "                      objective='binary:logistic', \n",
    "                      n_estimators=1000, \n",
    "                      reg_alpha = 0.3,\n",
    "                      max_depth=4, \n",
    "                      gamma=10)\n",
    "xgb.fit(x_train, y_train)\n",
    "# plot feature importance\n",
    "plot_importance(xgb)\n",
    "pyplot.show()\n",
    "# print(xgb)\n",
    "print(\"The score for XGBoost \", xgb.score(x_test, y_test))\n",
    "y_pred = xgb.predict(x_test)\n",
    "\n",
    "print(\"Accuracy for x_test:\", metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = metrics.accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "\n",
    "scores = cross_val_score(xgb, all_data, labels, cv=10, scoring='accuracy')\n",
    "print(\"Cross Validation Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "print(scores)\n",
    "\n",
    "# Fit model using each importance as a threshold\n",
    "thresholds = sort(xgb.feature_importances_)\n",
    "for thresh in thresholds:\n",
    "\t# select features using threshold\n",
    "\tselection = SelectFromModel(xgb, threshold=thresh, prefit=True)\n",
    "\tselect_X_train = selection.transform(x_train)\n",
    "\t# train model\n",
    "\tselection_model = XGBClassifier(silent=True, \n",
    "                      scale_pos_weight=1,\n",
    "                      learning_rate=0.01,  \n",
    "                      colsample_bytree = 0.4,\n",
    "                      subsample = 0.3,\n",
    "                      objective='binary:logistic', \n",
    "                      n_estimators=1000, \n",
    "                      reg_alpha = 0.3,\n",
    "                      max_depth=4, \n",
    "                      gamma=10)\n",
    "\tselection_model.fit(select_X_train, y_train)\n",
    "\t# eval model\n",
    "\tselect_X_test = selection.transform(x_test)\n",
    "\ty_pred = selection_model.predict(select_X_test)\n",
    "\tpredictions = [round(value) for value in y_pred]\n",
    "\taccuracy = accuracy_score(y_test, predictions)\n",
    "\tprint(\"Thresh=%.3f, n=%d, Accuracy: %.2f%%\" % (thresh, select_X_train.shape[1], accuracy*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_175 (Dense)            (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_176 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_177 (Dense)            (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_178 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_179 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_180 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_181 (Dense)            (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 6,481\n",
      "Trainable params: 6,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "1370/1370 [==============================] - 4s 3ms/step - loss: 0.6781 - acc: 0.5781\n",
      "Epoch 2/40\n",
      "1370/1370 [==============================] - 2s 1ms/step - loss: 0.6553 - acc: 0.6029\n",
      "Epoch 3/40\n",
      "1370/1370 [==============================] - 2s 1ms/step - loss: 0.6476 - acc: 0.6285\n",
      "Epoch 4/40\n",
      "1370/1370 [==============================] - 2s 1ms/step - loss: 0.6455 - acc: 0.6175\n",
      "Epoch 5/40\n",
      "1370/1370 [==============================] - 2s 1ms/step - loss: 0.6421 - acc: 0.6190\n",
      "Epoch 6/40\n",
      "1370/1370 [==============================] - 2s 1ms/step - loss: 0.6413 - acc: 0.6263\n",
      "Epoch 7/40\n",
      "1370/1370 [==============================] - 2s 1ms/step - loss: 0.6388 - acc: 0.6307\n",
      "Epoch 8/40\n",
      "1370/1370 [==============================] - 2s 1ms/step - loss: 0.6358 - acc: 0.6299\n",
      "Epoch 9/40\n",
      "1370/1370 [==============================] - 2s 1ms/step - loss: 0.6320 - acc: 0.6321\n",
      "Epoch 10/40\n",
      "1370/1370 [==============================] - 2s 1ms/step - loss: 0.6255 - acc: 0.6358\n",
      "Epoch 11/40\n",
      "1370/1370 [==============================] - 2s 1ms/step - loss: 0.6216 - acc: 0.6467\n",
      "Epoch 12/40\n",
      "1370/1370 [==============================] - 1s 1ms/step - loss: 0.6166 - acc: 0.6438\n",
      "Epoch 13/40\n",
      "1370/1370 [==============================] - 2s 1ms/step - loss: 0.6078 - acc: 0.6606\n",
      "Epoch 14/40\n",
      "1370/1370 [==============================] - 2s 1ms/step - loss: 0.6051 - acc: 0.6693\n",
      "Epoch 15/40\n",
      "1370/1370 [==============================] - 2s 1ms/step - loss: 0.6007 - acc: 0.6679\n",
      "Epoch 16/40\n",
      "1370/1370 [==============================] - 2s 1ms/step - loss: 0.5965 - acc: 0.6701\n",
      "Epoch 17/40\n",
      "1370/1370 [==============================] - 2s 1ms/step - loss: 0.5936 - acc: 0.6650\n",
      "Epoch 18/40\n",
      "1370/1370 [==============================] - 2s 1ms/step - loss: 0.5898 - acc: 0.6679\n",
      "Epoch 19/40\n",
      "1370/1370 [==============================] - 2s 1ms/step - loss: 0.5895 - acc: 0.6701\n",
      "Epoch 20/40\n",
      "1370/1370 [==============================] - 2s 1ms/step - loss: 0.5893 - acc: 0.6693\n",
      "Epoch 21/40\n",
      "1370/1370 [==============================] - 2s 1ms/step - loss: 0.5817 - acc: 0.6715\n",
      "Epoch 22/40\n",
      "1370/1370 [==============================] - 2s 1ms/step - loss: 0.5786 - acc: 0.6766\n",
      "Epoch 23/40\n",
      "1370/1370 [==============================] - 2s 1ms/step - loss: 0.5809 - acc: 0.6825\n",
      "Epoch 24/40\n",
      "1370/1370 [==============================] - 2s 1ms/step - loss: 0.5798 - acc: 0.6774\n",
      "Epoch 25/40\n",
      "1370/1370 [==============================] - 2s 1ms/step - loss: 0.5739 - acc: 0.6905\n",
      "Epoch 26/40\n",
      "1370/1370 [==============================] - 2s 1ms/step - loss: 0.5753 - acc: 0.6891\n",
      "Epoch 27/40\n",
      "1370/1370 [==============================] - 2s 1ms/step - loss: 0.5691 - acc: 0.6883\n",
      "Epoch 28/40\n",
      "1370/1370 [==============================] - 2s 1ms/step - loss: 0.5703 - acc: 0.6861\n",
      "Epoch 29/40\n",
      "1370/1370 [==============================] - 2s 1ms/step - loss: 0.5713 - acc: 0.6898\n",
      "Epoch 30/40\n",
      "1370/1370 [==============================] - 2s 1ms/step - loss: 0.5718 - acc: 0.6927\n",
      "Epoch 31/40\n",
      "1370/1370 [==============================] - 2s 1ms/step - loss: 0.5689 - acc: 0.6861\n",
      "Epoch 32/40\n",
      "1370/1370 [==============================] - 2s 1ms/step - loss: 0.5625 - acc: 0.6832\n",
      "Epoch 33/40\n",
      "1370/1370 [==============================] - 2s 1ms/step - loss: 0.5633 - acc: 0.6869\n",
      "Epoch 34/40\n",
      "1370/1370 [==============================] - 2s 1ms/step - loss: 0.5649 - acc: 0.6876\n",
      "Epoch 35/40\n",
      "1370/1370 [==============================] - 2s 1ms/step - loss: 0.5649 - acc: 0.6803\n",
      "Epoch 36/40\n",
      "1370/1370 [==============================] - 2s 1ms/step - loss: 0.5595 - acc: 0.6964\n",
      "Epoch 37/40\n",
      "1370/1370 [==============================] - 2s 1ms/step - loss: 0.5585 - acc: 0.6942\n",
      "Epoch 38/40\n",
      "1370/1370 [==============================] - 2s 1ms/step - loss: 0.5651 - acc: 0.6825\n",
      "Epoch 39/40\n",
      "1370/1370 [==============================] - 2s 1ms/step - loss: 0.5594 - acc: 0.6964\n",
      "Epoch 40/40\n",
      "1370/1370 [==============================] - 2s 1ms/step - loss: 0.5588 - acc: 0.6759\n",
      "151/151 [==============================] - 1s 4ms/step\n",
      "loss and metrics [0.46885224880761656, 0.7947019839918377]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAIABJREFUeJzt3Xl8VNX5+PHPk52QhOxsCSTsm4AQUEDBXdAqVq2CtWqrUv1VW7W1Rdtvtda26vfbxbbUahVF3HexLkgVpAgIQfaEJUCAQEhCWJIAIdvz+2NucAhJZhIymUnyvF+veWXunXPvPHMh8+Scc885oqoYY4wxjQnydwDGGGMCnyULY4wxHlmyMMYY45ElC2OMMR5ZsjDGGOORJQtjjDEeWbIwHZ6IpImIikiIF2VvEZElrRGXMYHEkoVpU0QkV0QqRCSxzv41zhd+mn8iM6Z9s2Rh2qIdwPTaDRE5A+jkv3ACgzc1I2Oay5KFaYvmAje5bd8MvOheQES6iMiLIlIkIjtF5FciEuS8Fiwi/yci+0VkO3B5Pcc+JyL5IrJHRB4VkWBvAhORN0Vkn4gcFpHFIjLU7bVOIvJHJ57DIrJERDo5r50jIktF5JCI7BaRW5z9i0TkNrdznNQM5tSmfiQiW4Gtzr4nnXOUiMgqETnXrXywiDwoIttEpNR5PVVEZonIH+t8lg9E5B5vPrdp/yxZmLZoORAjIoOdL/HrgZfqlPkb0AXoA0zClVy+77x2O/At4EwgA7i2zrFzgCqgn1PmEuA2vPMx0B9IBr4GXnZ77f+A0cB4IB74OVAjIr2c4/4GJAEjgTVevh/AVcBZwBBne6VzjnjgFeBNEYlwXrsPV63sMiAG+AFw1PnM090SaiJwIfBqE+Iw7Zmq2sMebeYB5AIXAb8C/gBMBhYAIYACaUAwcBwY4nbcD4FFzvPPgTvcXrvEOTYE6Ooc28nt9enAQuf5LcASL2ONdc7bBdcfZseAEfWUewB4t4FzLAJuc9s+6f2d81/gIY6Dte8LbAamNlAuG7jYeX4X8JG//73tETgPa+M0bdVcYDGQTp0mKCARCAN2uu3bCfR0nvcAdtd5rVZvIBTIF5HafUF1ytfLqeX8DvgOrhpCjVs84UAEsK2eQ1Mb2O+tk2ITkZ/iqgn1wJVMYpwYPL3XHOBGXMn3RuDJ04jJtDPWDGXaJFXdiauj+zLgnTov7wcqcX3x1+oF7HGe5+P60nR/rdZuXDWLRFWNdR4xqjoUz24ApuKq+XTBVcsBECemcqBvPcftbmA/wBEg0m27Wz1lTkwd7fRP/AK4DohT1VjgsBODp/d6CZgqIiOAwcB7DZQzHZAlC9OW3YqrCeaI+05VrQbeAH4nItEi0htXW31tv8YbwI9FJEVE4oCZbsfmA58CfxSRGBEJEpG+IjLJi3iicSWaYlxf8L93O28NMBv4k4j0cDqax4lIOK5+jYtE5DoRCRGRBBEZ6Ry6BrhaRCJFpJ/zmT3FUAUUASEi8mtcNYtazwK/FZH+4jJcRBKcGPNw9XfMBd5W1WNefGbTQViyMG2Wqm5T1cwGXr4b11/l24EluDp6Zzuv/QuYD6zF1Qldt2ZyE65mrCxc7f1vAd29COlFXE1ae5xjl9d5/WfAelxfyAeAx4EgVd2Fq4b0U2f/GmCEc8yfgQqgAFcz0cs0bj6uzvItTizlnNxM9SdcyfJToAR4jpNvO54DnIErYRhzgqja4kfGGBcRmYirBpbm1IaMAaxmYYxxiEgo8BPgWUsUpi5LFsYYRGQwcAhXc9tf/ByOCUDWDGWMMcYjq1kYY4zxqN0MyktMTNS0tDR/h2GMMW3KqlWr9qtqkqdyPk0WIjIZ1yjQYFydZo/Vef3PwPnOZiSQ7AwiQkRuxjWlA8CjqjqnsfdKS0sjM7OhuyiNMcbUR0R2ei7lw2ThTH0wC7gYyANWisg8Vc2qLaOq97qVvxvXpG2ISDzwEK5J3hRY5Rx70FfxGmOMaZgv+yzGAjmqul1VK4DXcE2F0JDpfDPD5aXAAlU94CSIBbgmjDPGGOMHvkwWPTl55Gge30zkdhJnOoZ0XLOBen2siMwQkUwRySwqKmqRoI0xxpzKl30WUs++hu7TnQa85czp4/WxqvoM8AxARkbGKa9XVlaSl5dHeXm5dxG3AxEREaSkpBAaGurvUIwx7Ygvk0UeJ8/smQLsbaDsNOBHdY49r86xi5ocQF4e0dHRpKWl4TbddLulqhQXF5OXl0d6erq/wzHGtCO+bIZaCfQXkXQRCcOVEObVLSQiA4E4YJnb7vnAJSIS58wKeomzr0nKy8tJSEjoEIkCQERISEjoUDUpY0zr8FnNQlWrROQuXF/ywcBsVd0oIo8AmapamzimA6+p21ByVT0gIr/FlXAAHlHVA82Jo6Mkilod7fMaY1qHT8dZqOpHwEd19v26zvbDDRw7m2+mlDbGmIC1IKuAzmHBjOvb8i0Zuw8cZePew0we5s0s+b5j0334UHFxMSNHjmTkyJF069aNnj17ntiuqKjw6hzf//732bx5s48jNcY01+Fjldzx0ipuePYrps76ko/X51Nd03Jz7j0xfzN3vvw1h49Vttg5m6PdTPcRiBISElizZg0ADz/8MFFRUfzsZz87qUztYuhBQfXn7eeff97ncRpjmu+/W4uorlFuPzedBVkF3Pny1/RJ7MwPJ/XhqjN7Eh4S3OxzH6uo5rPsAlRh9a6DnDcwuQUjbxqrWfhBTk4Ow4YN44477mDUqFHk5+czY8YMMjIyGDp0KI888siJsueccw5r1qyhqqqK2NhYZs6cyYgRIxg3bhyFhYV+/BTGGICFm4qIjQxl5pTBfPbT85h1wygiw4P5xdvrmfjEQv61eDtlx6uad+7NhRytcI0o+Hqnfyew6DA1i998sJGsvSUtes4hPWJ46IqhzTo2KyuL559/nn/+858APPbYY8THx1NVVcX555/Ptddey5AhQ0465vDhw0yaNInHHnuM++67j9mzZzNz5sz6Tm+MaQU1NcoXWwqZ2D+J4CBXX8Xlw7tz2RndWJKzn6cWbeN3H2Xz94U5zL11LMNTYpt0/g/X5ZMYFUZSdASZfk4WVrPwk759+zJmzJgT26+++iqjRo1i1KhRZGdnk5WVdcoxnTp1YsqUKQCMHj2a3Nzc1grXGFOP9XsOs7+sggsGndw8JCKc2z+JV24/m/d+NAERePqL7U0699GKKj7bVMDkYd04Kz2eNbsPUVXtvwUMO0zNork1AF/p3Lnziedbt27lySefZMWKFcTGxnLjjTfWO1YiLCzsxPPg4GCqqppXtTUmEK3LO0REaDADukb7OxSvLdxciAhMHNDwDN8jU2O5ZlQKc5bmUlR6nKTocK/O/fmmQsora/jW8B4Ulh7nhaW5bNpXyrCeXVoq/CaxmkUAKCkpITo6mpiYGPLz85k/v8njD41psw4eqeDnb63lyr9/yfVPL6OgpO0MKl24qZAzU2OJ7xzWaLnpY1OpqlHeWpXn9bk/XJdPUnQ4Y9LiyegdB8AqPzZFWbIIAKNGjWLIkCEMGzaM22+/nQkTJvg7JGN8TlV55+s8LvzTF7z99R6+d3ZvjlVW87M311LTgree+kpR6XHW5h3mfC/uUOqXHM3Y9HheW7nLq8925HgVn28q5LJh3QgOEnrEdqJ7F//2W3SYZih/e/jhh08879ev34lbasHVvjl37tx6j1uyZMmJ54cOHTrxfNq0aUybNq3lAzWmFezYf4RfvbeeL3OKGZkayx+uPoPB3WMY3D2GB99dz+wvd3DbuX38HWajFm9xzXR9/iDvbme9YWwv7nl9Dcu2FzOhX2KjZf+TXcDxqhouH97jxL7RveP8ekeU1SyM6UCe/3IHv3hrHQuyCiivrPZ8QAurqKrhb59t5dK/LGbd7sP89qphvHPneAZ3jwFczTUXD+nKE59sbvG7F1va55sLSY4OZ2iPGK/KTx7WjdjIUF75apfHsh+uyyc5OvxE8xO4ksWeQ8fIP3ys2TGfDqtZGNNBlB2v4vFPNlFeWcPrmbvpFBrMpAFJXDK0KxcMSiY2svF299O1etdB7n9rHTmFZVw+vDsPfWsIyTERJ5URER6/ZjiX/mUxP3ltNR/cfQ4Roc0f1OYrVdU1LN5SxJRh3bye3iMiNNirju7S8koWbSnihrG9CAr65twZveMBV7/Ft4Z3Ov0P0UTtvmbhNj9hh9DRPq/x3qcb91FeWcMrt5/F3FvHcu3oFFbvPsh9b6xl9KP/4YZ/LeeFL3ewPu8wR5o5iKw+qsrcZblc9/QyjlVU8/wtY5h1w6hTEkWt+M5h/N93RrC1sIw/fJTdYnG0pFU7D1JaXnXKLbOe1HZ0v/11wx3dn2UXUlFVwxUjTp4LalD3aDqFBpOZ65+mqHZds4iIiKC4uLjDTFNeu55FRET9v4SmY3tvzV56xnbi7PQEgoJc4wB+c+VQ1u85zKdZ+/h0YwEPf/DN+J7uXSLomxRF36TO9E2Oom9SFP2So+jawJd8fY5VVPPLd9fzzuo9nD8wib9cfyZdIj0vzDVpQBI/mJDO7C93cN7AZK/7BVrLws1FhASJx76HuvolRzM2LZ5XV+xixrl9Tqo51Pr3uny6d4ngzNS4k/aHBgcxMjWWr3dZsmhxKSkp5OXl0ZGWXK1dKc8Yd0Wlx1mytYg7JvU96QsqKEgYkRrLiNRY7r90ELuKj5KVX8K2ojLncYS3v95z0nQV5/RL5M7z+jLewwyrO4uP8MO5q9hcUMq9Fw3g7gv61fvl2JCfTx7I0m37uf+ttXz8k4lej09oDYs2FzImLZ7oiKavSHnDWQ13dJeUV7J4SxHfG9e73ms1unccT32xjaMVVUSGte7Xd7tOFqGhobZinDHAv9ftpUbhqjNPWcr+JL0SIumVEHnSPlWlqPQ4OUVlfL3zIHOW7eS7z37FiJQu3HleXy4Z0u2UL7bPsgu45/U1BIkw+5YxXt1eWldEaDBPTjuTK/6+hJ+/tZbZt4xpkRaC6hol7+BRcgqdhFh4hG1FZURHhPD09zIIC2m8dX7PoWNs2lfKLy8b3Kz3nzysG13mhfLKil2nJIv/ZBVQUV3D5cPrn458dO84qmuUtbsPM65vQrPev7nadbIwxri8t2Yvg7vHNGt0tIiQHBNBckwE4/smctu5fXh39R6e/mIbd7z0NX2SOnPHxL5cdWZPgoOEJz/byl8/28rQHjH888bRpMZHen6TBgzsFs2DUwbx8AdZzF2+k5vGpTXrPNn5JcxamMPWgjJ27D9Chdu0GYlRYaTGR7JwcxFPLdrGTy7q3+i5Fm12TeB5/qCGR203praje+7yXPaXHScx6psa07/X5dMzthNnptY/h9SoXrWD8w5YsjDGtKwd+4+wdvchHpgyqEXOFxEazPSxvbguI5VPNuzjH4ty+Pnb6/jTgi2kxndiZe5Brh2dwqNXDWuRO5luHp/Gws1F/O7DbEb1imvydBfvfJ3Hg++up1NoMKN7x3PeoCSnL8bVH1N7F9jdr65m1sIcLh/ejX7JDSfVhZsKSY3vRN+kqGZ/phvOSmX2lzt4a1Ued0zqC8Dho5X8d2sR35+Q3mANqktkKP2To/wykrvd3w1lTEf3/po9iMCVI3t4LtwEwUHC5cO78++7z2HurWPpk9SZtXmH+d23h/G/1w5vsVteRYT//c5wYjqFcvU/lvLkf7ZyvMrzGJGKqhr+570N3PfGWkamxvLpvZN49uYMHpgymOsyUhndO+6k24UfumIIkeHBzHx7fYOjrMsrq/kyp5jzByafVpNYbUf3ayu+GdH9adY+KquVy89ofEW8jLQ4Vu082Oqj3C1ZGNOOqSrvr9nLWenxdO/im3vz3WdY3fDwpXz3rN4tfvdhcnQEH/74HC4d1o0//2cLU578L8u3FzdYPv/wMa5/Zhlzl+9kxsQ+vHTrWR47yBOjwvnlZYPJ3HmQl1fUP3BuxY4DHKusbpG7s6aflUpu8VGWOZ/jw/X5pMR1YnhK4zWnUb3iKCmvYltR2WnH0BSWLIxpx9bvOcyO/Ue4amTjHdstxVPn8OlIjo7gb9PP5IXvj6GyuoZpzyzn/jfXcvDIyUsUL9tWzBV/W8KWfaX847ujePCywYQEexfXtaNTmNAvgcc/3sS+w6dOaPj5pkLCQ4IY1+f0+wumDOtOl06uju5DRytYsnU/lw/v7jHRZqS5Bue19jxRliyMacfeW72XsOAgpnho2mhLzhuYzKf3TOLO8/ry7uo9rokIV+VRU6M8s3gbNz73FV06hfL+XRO4rImfW0T4/bfPoKqmhl+9t+GUQa6LNhcyvm9CizSx1XZ0f7pxH6+s2EVVjfKtMzw3FaYlRJLQOazV+y0sWRjTTlXXKB+s28v5g5Lo0qnp4wECWaewYH4xeRD//vE59E6I5KdvruXcJxby+482cenQrrx/1zmNdlI3pndCZ+69aAD/yS7g4w37TuzfXlRGbvHRJo/abswNZ6VSWa38ecEWeidEMqyn53mmRIRRveMsWRhjGlZRVcP6vMNelV26bT9FpcdbrQnKHwZ1i+HtO8bz6FXDAHjwskHMumEUUeGnd6PnreekM7RHDA/N28jho5WAa9Q2uGo2LaW2o7u2Y9vbvp7RvePYsf8IxWXHWywWTyxZGNNGqCr3vrGGK/6+hGf/63mJzvdW7yU6IiTgpspoaUFBwo1n9+bLmRcwY2LfFulcDwkO4vFrhnPgSAV/+Ng1P9WizYX0T446rXEj9bl5fBpBTbxbzR+LIfk0WYjIZBHZLCI5IjKzgTLXiUiWiGwUkVfc9j/h7MsWkb9KR5jcyZhGPL14Ox+uyyc9sTOPfpjNO41MRldeWc38jfuYMqxbQM7a2hYM69mF285N57WVu/lPVgFfbT/gk8R7+fDurPjlRQzq5t1U57WxhQUHsaoV54nyWbIQkWBgFjAFGAJMF5Ehdcr0Bx4AJqjqUOAeZ/94YAIwHBgGjAEm+SpWYwLd4i1FPPHJJi4f3p2Pf3Iu4/sm8PO31rFwU2G95f+TXUDZ8ap23QTVGu65cAC94iO569Wvqaiuada0Jd5wH8XtjYjQYIb1jGFVK85A68uaxVggR1W3q2oF8BowtU6Z24FZqnoQQFVr/+crEAGEAeFAKFDgw1iNCVi7io9y96urGdA1+sRgt6e/N5pB3aO58+VV9TZFvLd6L11jwjmrBW7x7Mg6hQXzh6vPoLyyhqjwEDLS4jwf1EpG945j3Z7DXg1QbAm+TBY9gd1u23nOPncDgAEi8qWILBeRyQCqugxYCOQ7j/mqGpgT2xvjQ0crqpgxNxOAp783+sRMo9ERobzw/bF0i4ngBy+sZEtB6YljDh2t4IsthVw5ogfBTZjl1dRvQr9E7r6gHzMm9iHUy/EarWF073gqqmrYsKd1VhT05Sev739p3fHpIUB/4DxgOvCsiMSKSD9gMJCCK8FcICITT3kDkRkikikimR1pGnLTMagq97+1ji0Fpfx1+pn0Tuh80uuJUeHMvfUswkOCuOm5FeQdPAq4RgJXVitTrQmqxfz0koH8+MLGJxhsbaOdTu7WWpfbl8kiD0h1204B9tZT5n1VrVTVHcBmXMnj28ByVS1T1TLgY+Dsum+gqs+oaoaqZiQlNW8GSGMC1TNOh/b9lw5i0oD6/3+nxkcy5wdjOVJRxU3PraC47Djvr95Lv+Qor9eGNm1TUnQ4vRMiydx5oFXez5fJYiXQX0TSRSQMmAbMq1PmPeB8ABFJxNUstR3YBUwSkRARCcXVuW3NUKbD+O/WIh53OrTvmNSn0bKDu8fw3M1j2HPoGN999itW5B7gqpE9OsTqkB3d6F5xrNp5qFWWU/ZZslDVKuAuYD6uL/o3VHWjiDwiIlc6xeYDxSKShauP4n5VLQbeArYB64G1wFpV/cBXsRoTSHYVH+WuV77p0PbmS39sejyzbhjF1kLX5HLWBNUxjE6LY3/ZcXYdOOrz9/Lpehaq+hHwUZ19v3Z7rsB9zsO9TDXwQ1/GZkwgOnK8/g5tb1w0pCuzbhjFtqKyFh84ZgLTaLfBeXX7tFqaLX5kTICoqKrhjpdWsbWwjNm3jGnWL//kYd18EJkJVAOSo4kODyFz50GuHpXi0/cKnPvAjOnAamqU+95Yw3+37uexq89osEPbGHdBQcKZveNa5Y4oq1kY42eqym8+2Mi/1+XzwJRBfCcj1fNBxjh+c+XQVplV2JKFMX72t89zmLPMtaLbD531mI3xVnqib/sqalkzlDF+9NLynfxpwRauGZXCzMmD/B2OMQ2yZGGMn3y0Pp//eX8DFwxK5rFrziDIpuYwAcyShTF+8GXOfu55bQ2jesUx64ZRATXnkDH1sf+hxrSy9XmHmfFiJumJnZl98xg6hdl6EybwWQe3Ma1kf9lxXvgylzlLc4mNDGPOD8bSJbJ9rY1t2i9LFsb42O4DR/nXf7fz+srdVFTXcOmQbjx42WC6dYnwd2jGeM2ShWl38g8f483MPC4d2o2B3aJb9NyV1TV8uC6fzQWlpCd2pm9SFP2SouqtIWzaV8I/F23jg3X5BAl8+8yezJjYl37JUS0akzGtwZKFCUgFJeVsKywjIy2esBDvutZyCst4ZvE23l29h8pq5cVlubx1x3jSWuA+9GMV1byRuZtnFm9nz6FjiID7RJ+JUWH0SYqib1IUfRI7s2x7MZ9vKiQyLJjvj0/j1nPT6d6l02nHYYy/WLIwAUdVmTF3FWt3HyI6PITzBiVzyZCunDcwieiIU/+CX7v7EE8t2sb8rH2EBQcxfWwvLh7SlR+/uprvzf6Kt+8YT3JM85p8Dh+t5MVluTy/NJcDRyoY1SuW31w5lEkDk9hz8Bjbispcj8IjbCsq4+MN+Rw6WklcZCj3XTyAm8b1JjYy7DSviDH+J60xD3pryMjI0MzMTH+HYVrAJxvyueOlr7n93HRKy6tYkFVA8ZEKQoOF8X0TuWRoVy4e3JXNBaU8tWgbS7cVExMRwk3j0rhlQhqJUeEArNl9iBv+tZxe8ZG8/sNxTZoSoaCknOeW7ODl5Ts5UlHN+QOTuPO8foxJi/M4ZfiBIxVEhgUTEWp3OZnAJyKrVDXDYzlLFiaQVFXXcMlfFhMkwic/OZeQ4CCqa5TVuw7yaVYB8zfuY2fxN3P3J0eHc9u56Uwf26veWsd/txbxgxdWcmZqHC/eOtbjF/iximqe/Gwrs5fsoKqmhitG9OCHE/syxFadM+2UJQvTJr2+che/eHs9/7xxdL3TbasqWwvL+E92AYmdw5l6Zg/CQxpPAB+s3cuPX1vNRYO78tR3RxHSwAC4RZsL+dV7G8g7eIxrRqXwkwv70yvB1oUw7Zu3ycL6LEzAKK+s5s8LtjIyNZZLh3att4yIMKBrNAO6en+X0xUjenDgSAUPzdvIg++u5/FrTl59rrC0nEc+yOLf6/Lpm9SZ12aczdl9Ek778xjTnliyMAHjxWW57Csp58/Xj2zx9aNvHp9G8ZEK/vrZVhKiwvnF5EHU1CivrtzFYx9v4nhlDfddPIAfTurjsaZiTEdkycIEhMPHKpm1cBuTBiQxrq9v/qq/96L+7C87zlOLtlGjysodB/h61yHG903g0auG0SfJxj8Y0xBLFiYgPLN4G4ePVXL/pQN99h4iwm+nDuPgkQqe/mI7cZGh/PE7I7h6VM8Wr8kY095YsjB+V1hSzuwluVw5ogfDenbx6XsFBwl/mTaSC9fmc8GgZOI72xgIY7xhycL43V8/30pltavPoDWEhwRz7WjfLm5vTHtjU5Qbv8rdf4TXVuxm+theLTIthzHGNyxZGL/644IthAYHcfeF/fwdijGmEZYsjN9s2HOYD9bu5dZz0kmOtum6jQlkPk0WIjJZRDaLSI6IzGygzHUikiUiG0XkFbf9vUTkUxHJdl5P82WspvU9MX8zsZGhzJjUx9+hGGM88FkHt4gEA7OAi4E8YKWIzFPVLLcy/YEHgAmqelBEkt1O8SLwO1VdICJRQI2vYjWt76vtxSzeUsSDlw0ipp45nYwxgcWXNYuxQI6qblfVCuA1YGqdMrcDs1T1IICqFgKIyBAgRFUXOPvLVPUopt2Yt3YvncOCuWlcmr9DMcZ4wZfJoiew2207z9nnbgAwQES+FJHlIjLZbf8hEXlHRFaLyP86NZWTiMgMEckUkcyioiKffAjT8lSVL7YUMb5fok3jbUwb4ctkUd+Q2LpT3IYA/YHzgOnAsyIS6+w/F/gZMAboA9xyyslUn1HVDFXNSEpKarnIjU/t2H+EvIPHmDjA/s2MaSt8mSzygFS37RRgbz1l3lfVSlXdAWzGlTzygNVOE1YV8B4wyoexmla0eIurFjipvyULY9oKXyaLlUB/EUkXkTBgGjCvTpn3gPMBRCQRV/PTdufYOBGp/Ta5AMjCtAuLt+4nLSHS1oowpg3xWbJwagR3AfOBbOANVd0oIo+IyJVOsflAsYhkAQuB+1W1WFWrcTVBfSYi63E1af3LV7Ga1nO8qppl24qtCcqYNsanc0Op6kfAR3X2/drtuQL3OY+6xy4AhvsyPtP6MnMPcqyymonWBGVMm2IjuE2rWryliNBg8dmaFcYY37BkYVrVF1uKyOgdT+dwm/DYmLbEkoVpNYUl5WzaV2r9Fca0QZYsTKtZvHU/ABMHJPo5EmNMU1myMK3miy1FJEaFM7hbjL9DMcY0kSUL0yqqa5QlW4uYOCCRoCBb79qYtsaShWkVG/Yc5uDRSiZZf4UxbZIlC9MqFm8pQgTO6Wf9Fca0RZYsTKtYvLWIYT26kBAV7u9QjDHNYMnC+FxJeSVf7zpkd0EZ04ZZsjA+tzRnP9U1alN8GNOGWbIwPvfFlv1EhYcwqnecv0MxxjSTx2QhIneJiP2Wm2ZRVRZvKWJ83wRCg+1vE2PaKm9+e7sBK0XkDRGZLCJ2k7zx2vb9R9hzyFbFM6at85gsVPVXuFavew7X0qZbReT3ItLXx7GZduDEqniWLIxp07xqF3DWndjnPKqAOOAtEXnCh7GZAKaqvJG5m417Dzda7ostRaQndiY13lbFM6Yt8zhPtIj8GLgZ2A88i2s1u0oRCQK2Aj/3bYgmEK3aeZCfv7VTjl6gAAAZGElEQVSOIIEfTEjn3osHnDLteHllNcu3F3N9RmoDZzHGtBXeLCqQCFytqjvdd6pqjYh8yzdhmUD3wtJcYiJCuHx4d55dsoOPN+zjkalDuXBw1xNlMnMPUl5Zw6SB1gRlTFvnTTPUR8CB2g0RiRaRswBUNdtXgZnAVVBSzicb9nFdRip/uHo4b90xjs7hwdw6J5M7X1rFvsPlgGvUdlhwEGf3sVXxjGnrvEkWTwFlbttHnH2mg3p5+U6qVblpXBoAGWnx/Pvuc7n/0oF8vqmQi/70BXOW5vLF5iIy0uKIDLNV8Yxp67xJFuJ0cAOu5ie8a74y7dDxqmpeWbGLCwYm0yvhm07rsJAgfnR+Pz69dyJn9orloXkb2Vxgq+IZ0154kyy2i8iPRSTUefwE2O7rwExg+nBdPvvLKrh5fFq9r/dO6MyLPxjLk9NGMq5PAleM6NG6ARpjfMKbGsIdwF+BXwEKfAbM8GVQJnDNWZpLn6TOjU41LiJMHdmTqSN7tmJkxhhf8pgsVLUQmNYKsZgAt3rXQdbmHeaRqUNttTtjOhhv5oaKEJEficg/RGR27cObkzvTg2wWkRwRmdlAmetEJEtENorIK3VeixGRPSLyd+8+jvGlOUtziQoP4epRKf4OxRjTyrzps5iLa36oS4EvgBSg1NNBIhIMzAKmAEOA6SIypE6Z/sADwARVHQrcU+c0v3Xe0/hZYWk5H67P59rRKUSF2/0NxnQ03iSLfqr6P8ARVZ0DXA6c4cVxY4EcVd2uqhXAa8DUOmVuB2ap6kE40eQFgIiMBroCn3rxXsbHXv1qN5XVyk3jevs7FGOMH3iTLCqdn4dEZBjQBUjz4riewG637Txnn7sBwAAR+VJElovIZABnKpE/Avc39gYiMkNEMkUks6ioyIuQTHNUVNXw8lc7mTQgiT5JUf4OxxjjB94ki2ec9Sx+BcwDsoDHvTiuvh5QrbMdgmtG2/OA6cCzIhIL/D/gI1XdTSNU9RlVzVDVjKQku5/fVz7ekE9h6XFuaeB2WWNM+9do47PzF36J00y0GOjThHPnAe4zyKUAe+sps1xVK4EdIrIZV/IYB5wrIv8PiALCRKRMVevtJDe+NWdpLmkJkTbNuDEdWKM1C2e09l3NPPdKoL+IpItIGK7bb+fVKfMecD6AiCTiapbarqrfVdVeqpoG/Ax40RKFf6zPO8zXuw7xvXFpdrusMR2YN81QC0TkZyKSKiLxtQ9PB6lqFa5EMx/IBt5Q1Y0i8oiIXOkUmw8Ui0gWsBDX9OfFzfwsxgdeWJpLZFgw38mw22WN6cjEbdqn+guI7Khnt6pqU5qkfC4jI0MzMzP9HUa7Ulx2nHGPfc51GSk8epU3N8AZY9oaEVmlqhmeynkzgju9ZUIybc1rK3dTUVXDzc7sssaYjsublfJuqm+/qr7Y8uGYQPHB2r3MWpjDuf0T6d812t/hGGP8zJuhuGPcnkcAFwJfA5Ys2qHK6hoe+3gTzy3ZwejecfzxOyP8HZIxJgB40wx1t/u2iHTBNQWIaWcKS8u56+XVrMg9wC3j03jwssGEhXhzD4Qxpr1rziQ/R3GNhTDtSGbuAf7fy19TWl7Fk9NG2vTixpiTeNNn8QHfjLwOwjUp4Bu+DMq0HlXlhaW5/O7DbFLiOvHirWMZ1C3G32EZYwKMNzWL/3N7XgXsVNU8H8VjWtHRiioeeGc976/Zy0WDu/Kn60cQExHq77CMMQHIm2SxC8hX1XIAEekkImmqmuvTyIzPlJZX8vJXu3huyQ72lx3n/ksHcuekvjZC2xjTIG+SxZvAeLftamffmPqLm0BVVHqc57/cwdzlOyktr+Kcfon847ujGJPmcUC+MaaD8yZZhDjrUQCgqhXOXE/Gz3YWH2HWwhxiI8Pom9SZvklR9E2KIq7zyf88uw8c5enF23gjM4/K6hqmDOvGHZP6Mjwl1k+RG2PaGm+SRZGIXKmq8wBEZCqw37dhGU827Svhe8+toLS8khp1rTlRK77zN8mj7HgVH2/YR5DANaNSmDGxj61JYYxpMm+SxR3Ay27rYOcB9Y7qNq1j9a6D3PL8SiJCg/jgrnPokxTFnoPH2FZU9s2j8AgLsgo4XlXDreek84MJ6XTrEuHv0I0xbZQ3g/K2AWeLSBSuiQc9rr9tfGdpzn5uezGTpOhwXrr1LFLjIwHolRBJr4RIzh+UfFJ5VUXEOq6NMafH4/BcEfm9iMSqapmqlopInIg82hrBtQXvrd7DuU98TtnxKp+/14KsAm55YSUpcZ1484fjTiSKxliiMMa0BG/mcpiiqodqN5xV8y7zXUhty+ItRew+cIy3V/l26Ml7q/dwx0urGNw9htdnjCM5xpqUjDGtx5tkESwi4bUbItIJCG+kfIeSvc/VKjdnWS41NY2vDdJcc5flcu8baxibFs/Lt511yt1Oxhjja94ki5eAz0TkVhG5FVgAzPFtWG1DRVUNOYWlpCVEsr3oCEtyWv4msX8syuF/3t/IhYOSef77Y4gKb850XsYYc3o8JgtVfQJ4FBiMa16oT4DePo6rTdhWVEZltXLXBf1JjApnztLcFj3/os2FPPHJZq4c0YOnbhxNRGhwi57fGGO85e380/uAGuAaXOtZZPssojYkO78EgOEpXbjhrF58vrmQncVHWuTcR45X8ct3N9A3qTP/+53hhAbbVOHGGP9p8BtIRAaIyK9FJBv4O7Ab162z56vq3xs6riPJzi8hLCSIPomd+e5ZvQgW4cVlO1vk3H9asIU9h47x+DXDCQ+xGoUxxr8a+3N1E65axBWqeo6q/g3XvFDGsWlfKQO6RhESHETXmAimnNGdNzJ3c+Q0b6Nds/sQz3+5g++d3ZsMm7fJGBMAGksW1+BqflooIv8SkQsBu2nfTXZ+CYPd1n64ZXxvSsureHf1nmafs7K6hplvryM5OoKfTx7YEmEaY8xpazBZqOq7qno9MAhYBNwLdBWRp0TkklaKL2AVlpazv6yCwd2/SRajesUxrGcMLy7LRbV5t9E+s3g7m/aV8turhhFta0sYYwKEN3dDHVHVl1X1W0AKsAaY6fPIAlx2vmt8xaDu0Sf2iQg3j0tjS0EZy7YVN/mc24rKePKzrVx+RncuHtK1xWI1xpjT1aRbbFT1gKo+raoX+CqgtmKTcyfUkO4nL0F6xYgexHcO4/km3kZbU6M88M56IkKCeOjKIS0VpjHGtAif3o8pIpNFZLOI5IhIvbUREblORLJEZKOIvOLsGykiy5x960Tkel/G2RzZ+SV07xJBbOTJo6kjQoOZPjaVz7IL2H3gqNfnez1zNyt2HOCXlw8mOdqm8jDGBBafJQsRCQZmAVNwDeabLiJD6pTpDzwATFDVocA9zktHgZucfZOBv4hIQK3Uk51felJ/hbsbz+6NiPDScu9uoy0oKef3H2Uzrk8C12WktmSYxhjTInxZsxgL5KjqdmelvdeAqXXK3A7MciYnRFULnZ9bVHWr83wvUAgk+TDWJjleVc22ojIGdYuu9/XuXTpx6dCuvLZyN8cqPN9t/ND7G6moquH3V59hs8QaYwKSL5NFT1wD+WrlOfvcDQAGiMiXIrJcRCbXPYmIjAXCgG31vDZDRDJFJLOoqKgFQ2/c1oIyqmq0wZoFwM3j0jh8rJL31zR+G+0nG/L5ZOM+7rloAOmJnVs6VGOMaRG+nJWuvj+R695PGgL0B87DdafVf0VkWO2U6CLSHZgL3KyqNXWORVWfAZ4ByMjI8M2Ur/XY5Mw021iyGJsez6Bu0bywNJfrx6SeVGPYXlTGp1kFfLpxH6t3H2Jw9xhuOzfd53EbY0xz+TJZ5AHuDfApwN56yixX1Upgh4hsxpU8VopIDPAh8CtVXe7DOJssO7+EiNCgRmsCIsIt49OY+c56lm8/QGRYMPM37uPTrAJyCssAGNYzhnsvGsC0sak295MxJqD5MlmsBPqLSDqwB5gG3FCnzHvAdOAFEUnE1Sy1XUTCgHeBF1X1TR/G2CzZ+SUM7BpNcFDj/QtTR/bksU828b3nvqKqRgkOEsamxXPjWb24aEhXUuI8r3RnjDGBwGfJQlWrROQuYD4QDMxW1Y0i8giQqarznNcuEZEsXPNO3a+qxSJyIzARSBCRW5xT3qKqa3wVr7dUlez8Ei4Z0s1j2U5hwTw4ZTBfbCnigkHJXDAo2RYuMsa0SdLcaSkCTUZGhmZmZvr8ffYdLufsP3zGw1cM4ZYJ1s9gjGnbRGSVqmZ4KmcN5U2Uvc81cruxzm1jjGlvLFk0Ue2CR4MsWRhjOhBLFk2UnV9Kz9hOdOlkM8IaYzoOSxZNlJ1fwuDu9Y/cNsaY9sqSRROUV1azvajM+iuMMR2OJYsm2FpQRo1a57YxpuOxZNEEtZ3bliyMMR2NJYsmyMovoVNoML3ibeS1MaZjsWTRBNn5JQzs5nmaD2OMaW8sWXhJVdm0r+EFj4wxpj2zZOGl/MPlHD5WyRC7bdYY0wFZsvCSjdw2xnRkliy8dCJZNLCUqjHGtGeWLLyUnV9KanwnoiNsmg9jTMdjycJL2ftKGNzNmqCMMR2TJQsvHKuoJnf/EbsTyhjTYVmy8MLmglJnmg/rrzDGdEyWLLxg03wYYzo6SxZe2JRfQuewYFLjbJoPY0zHZMnCC9n5pQzqHkOQTfNhjOmgLFl4oKpk7yux8RXGmA7NkoUHeQePUVpeZf0VxpgOzZKFB9a5bYwxliw8ysovQcSm+TDGdGw+TRYiMllENotIjojMbKDMdSKSJSIbReQVt/03i8hW53GzL+NsTNbeEtITO9M5PMRfIRhjjN/57BtQRIKBWcDFQB6wUkTmqWqWW5n+wAPABFU9KCLJzv544CEgA1BglXPsQV/F25Cs/BJGpsa29tsaY0xA8WXNYiyQo6rbVbUCeA2YWqfM7cCs2iSgqoXO/kuBBap6wHltATDZh7HW6/CxSvIOHmNID+uvMMZ0bL5MFj2B3W7bec4+dwOAASLypYgsF5HJTTgWEZkhIpkikllUVNSCobvUdm4Psc5tY0wH58tkUd8INq2zHQL0B84DpgPPikisl8eiqs+oaoaqZiQlJZ1muKfK2uskC6tZGGM6OF8mizwg1W07BdhbT5n3VbVSVXcAm3ElD2+O9bmNe0tIjAonOTqitd/aGGMCii+TxUqgv4iki0gYMA2YV6fMe8D5ACKSiKtZajswH7hEROJEJA64xNnXqrLySxhqtQpjjPHd3VCqWiUid+H6kg8GZqvqRhF5BMhU1Xl8kxSygGrgflUtBhCR3+JKOACPqOoBX8Van4qqGnIKSzlvYMs3bxljTFvj08EDqvoR8FGdfb92e67Afc6j7rGzgdm+jK8xWwtLqaxW69w2xhhsBHeDrHPbGGO+YcmiAVn5JXQKDSYtobO/QzHGGL+zZNGArL0lDOoeTbCtYWGMMZYs6qOqdieUMca4sWRRj9o1LIZ07+LvUIwxJiBYsqjHRuvcNsaYk1iyqEdWfglBAgO72hoWxhgDlizqlbW3hD5JUXQKC/Z3KMYYExAsWdQjO7/EBuMZY4wbSxZ1HDxSwZ5Dx+xOKGOMcWPJoo4Ta1hYsjDGmBMsWdSR5SSLwdYMZYwxJ1iyqCNrbwldY8JJjAr3dyjGGBMwLFnUkWWd28YYcwpLFm7KK6vJKSyz/gpjjKnDkoWbnMIyqmqUoT1smg9jjHFnycLNxr2HAawZyhhj6rBk4SZrbwmdw4LpFR/p71CMMSagWLJwk5VfwuDuMQTZGhbGGHMSSxaOmholO7/UOreNMaYeliwcuw8epex4lfVXGGNMPSxZOLKcNSzsTihjjDmVJQtHVn4JwUFC/65R/g7FGGMCjiULx8a9JfRLiiIi1NawMMaYuixZOLL2lljntjHGNMCnyUJEJovIZhHJEZGZ9bx+i4gUicga53Gb22tPiMhGEckWkb+KiM/uZy0uO86+knLr3DbGmAaE+OrEIhIMzAIuBvKAlSIyT1Wz6hR9XVXvqnPseGACMNzZtQSYBCzyRazZ+aWArWFhjDEN8WXNYiyQo6rbVbUCeA2Y6uWxCkQAYUA4EAoU+CRKICvfpvkwxpjG+DJZ9AR2u23nOfvqukZE1onIWyKSCqCqy4CFQL7zmK+q2XUPFJEZIpIpIplFRUXNDjRrbwk9ukQQ1zms2ecwxpj2zJfJor4+Bq2z/QGQpqrDgf8AcwBEpB8wGEjBlWAuEJGJp5xM9RlVzVDVjKSkpGYHutE6t40xplG+TBZ5QKrbdgqw172Aqhar6nFn81/AaOf5t4HlqlqmqmXAx8DZvgiyvLKabUVl1gRljDGN8GWyWAn0F5F0EQkDpgHz3AuISHe3zSuB2qamXcAkEQkRkVBcndunNEO1hNLyKr41vAdj0xN8cXpjjGkXfHY3lKpWichdwHwgGJitqhtF5BEgU1XnAT8WkSuBKuAAcItz+FvABcB6XE1Xn6jqB76IMyk6nL9OP9MXpzbGmHZDVOt2I7RNGRkZmpmZ6e8wjDGmTRGRVaqa4amcjeA2xhjjkSULY4wxHlmyMMYY45ElC2OMMR5ZsjDGGOORJQtjjDEeWbIwxhjjUbsZZyEiRcDO0zhFIrC/hcJpaRZb81hszWOxNU9bja23qnqcXK/dJIvTJSKZ3gxM8QeLrXkstuax2JqnvcdmzVDGGGM8smRhjDHGI0sW33jG3wE0wmJrHouteSy25mnXsVmfhTHGGI+sZmGMMcYjSxbGGGM86vDJQkQmi8hmEckRkZn+jsediOSKyHoRWSMifl+sQ0Rmi0ihiGxw2xcvIgtEZKvzMy5A4npYRPY4126NiFzW2nE5caSKyEIRyRaRjSLyE2d/IFy3hmLz+7UTkQgRWSEia53YfuPsTxeRr5zr9rqzCmegxPaCiOxwu24jWzs2txiDRWS1iPzb2T7966aqHfaBawW/bUAfIAxYCwzxd1xu8eUCif6Owy2eicAoYIPbvieAmc7zmcDjARLXw8DPAuCadQdGOc+jgS3AkAC5bg3F5vdrBwgQ5TwPBb4CzgbeAKY5+/8J3BlAsb0AXOvv/3NOXPcBrwD/drZP+7p19JrFWCBHVberagXwGjDVzzEFLFVdjGv5W3dTgTnO8znAVa0aFA3GFRBUNV9Vv3ael+JaS74ngXHdGorN79SlzNkMdR6Ka7nlt5z9/rpuDcUWEEQkBbgceNbZFlrgunX0ZNET2O22nUeA/LI4FPhURFaJyAx/B9OArqqaD64vHyDZz/G4u0tE1jnNVK3ezFOXiKQBZ+L6SzSgrlud2CAArp3TlLIGKAQW4GoFOKSqVU4Rv/2+1o1NVWuv2++c6/ZnEQn3R2zAX4CfAzXOdgItcN06erKQevYFzF8IwARVHQVMAX4kIhP9HVAb8hTQFxgJ5AN/9GcwIhIFvA3co6ol/oylrnpiC4hrp6rVqjoSSMHVCjC4vmKtG5XzpnViE5FhwAPAIGAMEA/8orXjEpFvAYWqusp9dz1Fm3zdOnqyyANS3bZTgL1+iuUUqrrX+VkIvIvrFybQFIhIdwDnZ6Gf4wFAVQucX+ga4F/48dqJSCiuL+OXVfUdZ3dAXLf6Yguka+fEcwhYhKtfIFZEQpyX/P776hbbZKdZT1X1OPA8/rluE4ArRSQXV7P6BbhqGqd93Tp6slgJ9HfuFAgDpgHz/BwTACLSWUSia58DlwAbGj/KL+YBNzvPbwbe92MsJ9R+ETu+jZ+undNe/ByQrap/cnvJ79etodgC4dqJSJKIxDrPOwEX4epTWQhc6xTz13WrL7ZNbslfcPUJtPp1U9UHVDVFVdNwfZ99rqrfpSWum7977f39AC7DdRfINuCX/o7HLa4+uO7OWgtsDITYgFdxNUtU4qqV3YqrPfQzYKvzMz5A4poLrAfW4fpi7u6na3YOrir/OmCN87gsQK5bQ7H5/doBw4HVTgwbgF87+/sAK4Ac4E0gPIBi+9y5bhuAl3DumPLXAziPb+6GOu3rZtN9GGOM8aijN0MZY4zxgiULY4wxHlmyMMYY45ElC2OMMR5ZsjDGGOORJQtjmkBEqt1mFV0jLThTsYikuc+ca0wgCfFcxBjj5pi6pnkwpkOxmoUxLUBca4887qxzsEJE+jn7e4vIZ87kcp+JSC9nf1cReddZE2GtiIx3ThUsIv9y1kn41BkhbIzfWbIwpmk61WmGut7ttRJVHQv8Hdd8PDjPX1TV4cDLwF+d/X8FvlDVEbjW4tjo7O8PzFLVocAh4Boffx5jvGIjuI1pAhEpU9WoevbnAheo6nZncr59qpogIvtxTZdR6ezPV9VEESkCUtQ16VztOdJwTXfd39n+BRCqqo/6/pMZ0zirWRjTcrSB5w2Vqc9xt+fVWL+iCRCWLIxpOde7/VzmPF+Ka/ZPgO8CS5znnwF3womFdGJaK0hjmsP+ajGmaTo5K6TV+kRVa2+fDReRr3D9ETbd2fdjYLaI3A8UAd939v8EeEZEbsVVg7gT18y5xgQk67MwpgU4fRYZqrrf37EY4wvWDGWMMcYjq1kYY4zxyGoWxhhjPLJkYYwxxiNLFsYYYzyyZGGMMcYjSxbGGGM8+v9s1N1bkcvRjQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "# from keras import regularizers kernel_regularizer=regularizers.l2(0.01), \n",
    "from keras.optimizers import Adam\n",
    "\n",
    "network = models.Sequential()\n",
    "\n",
    "network.add(layers.Dense(16, input_shape=(8,)))\n",
    "network.add(layers.Dense(32, activation=\"relu\"))\n",
    "network.add(layers.Dense(64, activation=\"relu\"))\n",
    "network.add(layers.Dense(32, activation=\"relu\"))\n",
    "network.add(layers.Dense(32, activation=\"relu\"))\n",
    "network.add(layers.Dense(16, activation=\"sigmoid\"))\n",
    "network.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Adam = Adam(lr=0.05)\n",
    "network.compile(optimizer=Adam(lr=0.0004),\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['acc'])\n",
    "\n",
    "network.summary()\n",
    "\n",
    "history = network.fit(x_train, y_train,\n",
    "                      epochs=40, verbose=1, batch_size=3)\n",
    "\n",
    "loss_and_metrics = network.evaluate(x_test, y_test)\n",
    "print('loss and metrics', loss_and_metrics)\n",
    "\n",
    "# print('prediction: ', network.predict(test_data))\n",
    "\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "all_labels = dataDF.action.values\n",
    "\n",
    "encoder = LabelBinarizer()\n",
    "all_labels = encoder.fit_transform(all_labels)\n",
    "    \n",
    "# create an array of shape 30706, 9 = number of records by the features\n",
    "all_data = np.array([[0 for x in range(8)] for y in range(len(dataDF))])\n",
    "for i in range(len(dataDF)):\n",
    "    all_data[i] = [dataDF.delta.values[i],\n",
    "                       dataDF.theta.values[i],\n",
    "                       dataDF.alphaLow.values[i],\n",
    "                       dataDF.alphaHigh.values[i],\n",
    "                       dataDF.betaLow.values[i],\n",
    "                       dataDF.betaHigh.values[i],\n",
    "                       dataDF.gammaLow.values[i],\n",
    "                       dataDF.gammaMid.values[i]]\n",
    "    \n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "scaler = MinMaxScaler()\n",
    "stan_scaler = StandardScaler()\n",
    "\n",
    "all_data = scaler.fit_transform(all_data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold 1/10.............................................\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_67 (Dense)             (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 5,425\n",
      "Trainable params: 5,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1094 samples, validate on 274 samples\n",
      "Epoch 1/40\n",
      "1094/1094 [==============================] - 2s 2ms/step - loss: 0.7247 - acc: 0.5192 - val_loss: 0.6009 - val_acc: 0.9124\n",
      "Epoch 2/40\n",
      "1094/1094 [==============================] - 1s 600us/step - loss: 0.6820 - acc: 0.5622 - val_loss: 0.5876 - val_acc: 0.9416\n",
      "Epoch 3/40\n",
      "1094/1094 [==============================] - 1s 634us/step - loss: 0.6732 - acc: 0.5750 - val_loss: 0.6295 - val_acc: 0.8759\n",
      "Epoch 4/40\n",
      "1094/1094 [==============================] - 1s 608us/step - loss: 0.6673 - acc: 0.5740 - val_loss: 0.6052 - val_acc: 0.8832\n",
      "Epoch 5/40\n",
      "1094/1094 [==============================] - 1s 721us/step - loss: 0.6638 - acc: 0.5868 - val_loss: 0.5898 - val_acc: 0.8869\n",
      "Epoch 6/40\n",
      "1094/1094 [==============================] - 1s 639us/step - loss: 0.6597 - acc: 0.5804 - val_loss: 0.6607 - val_acc: 0.3066\n",
      "Epoch 7/40\n",
      "1094/1094 [==============================] - 1s 619us/step - loss: 0.6612 - acc: 0.5868 - val_loss: 0.5914 - val_acc: 0.8832\n",
      "Epoch 8/40\n",
      "1094/1094 [==============================] - 1s 600us/step - loss: 0.6588 - acc: 0.6042 - val_loss: 0.6121 - val_acc: 0.8759\n",
      "Epoch 9/40\n",
      "1094/1094 [==============================] - 1s 597us/step - loss: 0.6557 - acc: 0.5914 - val_loss: 0.5679 - val_acc: 0.8832\n",
      "Epoch 10/40\n",
      "1094/1094 [==============================] - 1s 612us/step - loss: 0.6541 - acc: 0.6152 - val_loss: 0.5971 - val_acc: 0.8686\n",
      "Epoch 11/40\n",
      "1094/1094 [==============================] - 1s 679us/step - loss: 0.6516 - acc: 0.6060 - val_loss: 0.6635 - val_acc: 0.7774\n",
      "Epoch 12/40\n",
      "1094/1094 [==============================] - 1s 606us/step - loss: 0.6512 - acc: 0.6106 - val_loss: 0.5901 - val_acc: 0.8650\n",
      "Epoch 13/40\n",
      "1094/1094 [==============================] - 1s 600us/step - loss: 0.6500 - acc: 0.6152 - val_loss: 0.5378 - val_acc: 0.8796\n",
      "Epoch 14/40\n",
      "1094/1094 [==============================] - 1s 601us/step - loss: 0.6463 - acc: 0.6289 - val_loss: 0.5212 - val_acc: 0.8796\n",
      "Epoch 15/40\n",
      "1094/1094 [==============================] - 1s 591us/step - loss: 0.6436 - acc: 0.6307 - val_loss: 0.5167 - val_acc: 0.8686\n",
      "Epoch 16/40\n",
      "1094/1094 [==============================] - 1s 664us/step - loss: 0.6391 - acc: 0.6344 - val_loss: 0.5646 - val_acc: 0.8504\n",
      "Epoch 17/40\n",
      "1094/1094 [==============================] - 1s 651us/step - loss: 0.6358 - acc: 0.6435 - val_loss: 0.5195 - val_acc: 0.8613\n",
      "Epoch 18/40\n",
      "1094/1094 [==============================] - 1s 705us/step - loss: 0.6304 - acc: 0.6435 - val_loss: 0.5097 - val_acc: 0.8540\n",
      "Epoch 19/40\n",
      "1094/1094 [==============================] - 1s 666us/step - loss: 0.6301 - acc: 0.6536 - val_loss: 0.4955 - val_acc: 0.8613\n",
      "Epoch 20/40\n",
      "1094/1094 [==============================] - 1s 649us/step - loss: 0.6254 - acc: 0.6572 - val_loss: 0.5321 - val_acc: 0.8504\n",
      "Epoch 21/40\n",
      "1094/1094 [==============================] - 1s 624us/step - loss: 0.6246 - acc: 0.6517 - val_loss: 0.4913 - val_acc: 0.8431\n",
      "Epoch 22/40\n",
      "1094/1094 [==============================] - 1s 638us/step - loss: 0.6203 - acc: 0.6627 - val_loss: 0.4524 - val_acc: 0.8686\n",
      "Epoch 23/40\n",
      "1094/1094 [==============================] - 1s 612us/step - loss: 0.6171 - acc: 0.6590 - val_loss: 0.4953 - val_acc: 0.8431\n",
      "Epoch 24/40\n",
      "1094/1094 [==============================] - 1s 649us/step - loss: 0.6148 - acc: 0.6600 - val_loss: 0.5855 - val_acc: 0.7664\n",
      "Epoch 25/40\n",
      "1094/1094 [==============================] - 1s 661us/step - loss: 0.6174 - acc: 0.6618 - val_loss: 0.4402 - val_acc: 0.8978\n",
      "Epoch 26/40\n",
      "1094/1094 [==============================] - 1s 657us/step - loss: 0.6117 - acc: 0.6536 - val_loss: 0.4421 - val_acc: 0.8978\n",
      "Epoch 27/40\n",
      "1094/1094 [==============================] - 1s 659us/step - loss: 0.6095 - acc: 0.6600 - val_loss: 0.5015 - val_acc: 0.8613\n",
      "Epoch 28/40\n",
      "1094/1094 [==============================] - 1s 768us/step - loss: 0.6081 - acc: 0.6682 - val_loss: 0.4815 - val_acc: 0.8431\n",
      "Epoch 29/40\n",
      "1094/1094 [==============================] - 1s 671us/step - loss: 0.6031 - acc: 0.6801 - val_loss: 0.5909 - val_acc: 0.7847\n",
      "Epoch 30/40\n",
      "1094/1094 [==============================] - 1s 602us/step - loss: 0.6072 - acc: 0.6618 - val_loss: 0.4351 - val_acc: 0.8796\n",
      "Epoch 31/40\n",
      "1094/1094 [==============================] - 1s 627us/step - loss: 0.6070 - acc: 0.6609 - val_loss: 0.4394 - val_acc: 0.8613\n",
      "Epoch 32/40\n",
      "1094/1094 [==============================] - 1s 628us/step - loss: 0.6044 - acc: 0.6746 - val_loss: 0.4448 - val_acc: 0.8869\n",
      "Epoch 33/40\n",
      "1094/1094 [==============================] - 1s 598us/step - loss: 0.6032 - acc: 0.6746 - val_loss: 0.3821 - val_acc: 0.9124\n",
      "Epoch 34/40\n",
      "1094/1094 [==============================] - 1s 604us/step - loss: 0.6003 - acc: 0.6709 - val_loss: 0.4542 - val_acc: 0.8796\n",
      "Epoch 35/40\n",
      "1094/1094 [==============================] - 1s 628us/step - loss: 0.5990 - acc: 0.6837 - val_loss: 0.4675 - val_acc: 0.8759\n",
      "Epoch 36/40\n",
      "1094/1094 [==============================] - 1s 618us/step - loss: 0.5976 - acc: 0.6828 - val_loss: 0.4605 - val_acc: 0.8759\n",
      "Epoch 37/40\n",
      "1094/1094 [==============================] - 1s 598us/step - loss: 0.5963 - acc: 0.6801 - val_loss: 0.4492 - val_acc: 0.8796\n",
      "Epoch 38/40\n",
      "1094/1094 [==============================] - 1s 623us/step - loss: 0.5983 - acc: 0.6764 - val_loss: 0.3584 - val_acc: 0.9124\n",
      "Epoch 39/40\n",
      "1094/1094 [==============================] - 1s 587us/step - loss: 0.5973 - acc: 0.6929 - val_loss: 0.4836 - val_acc: 0.8285\n",
      "Epoch 40/40\n",
      "1094/1094 [==============================] - 1s 613us/step - loss: 0.5969 - acc: 0.6819 - val_loss: 0.3949 - val_acc: 0.8942\n",
      "153/153 [==============================] - 0s 26us/step\n",
      "Average accuracy of model on the dev set =  0.37254901980262956\n",
      "Training on fold 2/10.............................................\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_73 (Dense)             (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 5,425\n",
      "Trainable params: 5,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1094 samples, validate on 274 samples\n",
      "Epoch 1/40\n",
      "1094/1094 [==============================] - 2s 2ms/step - loss: 0.6892 - acc: 0.5430 - val_loss: 0.6758 - val_acc: 0.7555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/40\n",
      "1094/1094 [==============================] - 1s 589us/step - loss: 0.6787 - acc: 0.5484 - val_loss: 0.6496 - val_acc: 0.7628\n",
      "Epoch 3/40\n",
      "1094/1094 [==============================] - 1s 598us/step - loss: 0.6703 - acc: 0.5667 - val_loss: 0.6095 - val_acc: 0.8869\n",
      "Epoch 4/40\n",
      "1094/1094 [==============================] - 1s 600us/step - loss: 0.6671 - acc: 0.5667 - val_loss: 0.6332 - val_acc: 0.7920\n",
      "Epoch 5/40\n",
      "1094/1094 [==============================] - 1s 596us/step - loss: 0.6648 - acc: 0.5804 - val_loss: 0.6081 - val_acc: 0.8832\n",
      "Epoch 6/40\n",
      "1094/1094 [==============================] - 1s 592us/step - loss: 0.6620 - acc: 0.5777 - val_loss: 0.5958 - val_acc: 0.8796\n",
      "Epoch 7/40\n",
      "1094/1094 [==============================] - 1s 603us/step - loss: 0.6593 - acc: 0.5850 - val_loss: 0.6172 - val_acc: 0.8650\n",
      "Epoch 8/40\n",
      "1094/1094 [==============================] - 1s 615us/step - loss: 0.6599 - acc: 0.5887 - val_loss: 0.5801 - val_acc: 0.9088\n",
      "Epoch 9/40\n",
      "1094/1094 [==============================] - 1s 628us/step - loss: 0.6563 - acc: 0.5941 - val_loss: 0.6291 - val_acc: 0.7518\n",
      "Epoch 10/40\n",
      "1094/1094 [==============================] - 1s 646us/step - loss: 0.6523 - acc: 0.6179 - val_loss: 0.5587 - val_acc: 0.8577\n",
      "Epoch 11/40\n",
      "1094/1094 [==============================] - 1s 633us/step - loss: 0.6497 - acc: 0.6271 - val_loss: 0.5917 - val_acc: 0.7993\n",
      "Epoch 12/40\n",
      "1094/1094 [==============================] - 1s 648us/step - loss: 0.6448 - acc: 0.6298 - val_loss: 0.5960 - val_acc: 0.7774\n",
      "Epoch 13/40\n",
      "1094/1094 [==============================] - 1s 646us/step - loss: 0.6420 - acc: 0.6325 - val_loss: 0.5350 - val_acc: 0.8358\n",
      "Epoch 14/40\n",
      "1094/1094 [==============================] - 1s 646us/step - loss: 0.6378 - acc: 0.6389 - val_loss: 0.5098 - val_acc: 0.8759\n",
      "Epoch 15/40\n",
      "1094/1094 [==============================] - 1s 663us/step - loss: 0.6333 - acc: 0.6371 - val_loss: 0.4622 - val_acc: 0.8869\n",
      "Epoch 16/40\n",
      "1094/1094 [==============================] - 1s 633us/step - loss: 0.6302 - acc: 0.6517 - val_loss: 0.6245 - val_acc: 0.7007\n",
      "Epoch 17/40\n",
      "1094/1094 [==============================] - 1s 615us/step - loss: 0.6292 - acc: 0.6490 - val_loss: 0.4876 - val_acc: 0.8212\n",
      "Epoch 18/40\n",
      "1094/1094 [==============================] - 1s 660us/step - loss: 0.6236 - acc: 0.6636 - val_loss: 0.5384 - val_acc: 0.8102\n",
      "Epoch 19/40\n",
      "1094/1094 [==============================] - 1s 618us/step - loss: 0.6208 - acc: 0.6600 - val_loss: 0.5137 - val_acc: 0.8467\n",
      "Epoch 20/40\n",
      "1094/1094 [==============================] - 1s 602us/step - loss: 0.6177 - acc: 0.6618 - val_loss: 0.4643 - val_acc: 0.8613\n",
      "Epoch 21/40\n",
      "1094/1094 [==============================] - 1s 672us/step - loss: 0.6166 - acc: 0.6554 - val_loss: 0.4910 - val_acc: 0.8102\n",
      "Epoch 22/40\n",
      "1094/1094 [==============================] - 1s 737us/step - loss: 0.6107 - acc: 0.6782 - val_loss: 0.3947 - val_acc: 0.8905\n",
      "Epoch 23/40\n",
      "1094/1094 [==============================] - 1s 666us/step - loss: 0.6113 - acc: 0.6645 - val_loss: 0.4012 - val_acc: 0.8832\n",
      "Epoch 24/40\n",
      "1094/1094 [==============================] - 1s 773us/step - loss: 0.6096 - acc: 0.6682 - val_loss: 0.3893 - val_acc: 0.8796\n",
      "Epoch 25/40\n",
      "1094/1094 [==============================] - 1s 591us/step - loss: 0.6084 - acc: 0.6810 - val_loss: 0.4405 - val_acc: 0.8540\n",
      "Epoch 26/40\n",
      "1094/1094 [==============================] - 1s 732us/step - loss: 0.6054 - acc: 0.6737 - val_loss: 0.4141 - val_acc: 0.8650\n",
      "Epoch 27/40\n",
      "1094/1094 [==============================] - 1s 612us/step - loss: 0.6024 - acc: 0.6718 - val_loss: 0.4847 - val_acc: 0.7883\n",
      "Epoch 28/40\n",
      "1094/1094 [==============================] - 1s 666us/step - loss: 0.6022 - acc: 0.6837 - val_loss: 0.3350 - val_acc: 0.9124\n",
      "Epoch 29/40\n",
      "1094/1094 [==============================] - 1s 590us/step - loss: 0.5998 - acc: 0.6691 - val_loss: 0.4588 - val_acc: 0.8175\n",
      "Epoch 30/40\n",
      "1094/1094 [==============================] - 1s 610us/step - loss: 0.5972 - acc: 0.6846 - val_loss: 0.4572 - val_acc: 0.7920\n",
      "Epoch 31/40\n",
      "1094/1094 [==============================] - 1s 777us/step - loss: 0.5964 - acc: 0.6737 - val_loss: 0.4163 - val_acc: 0.8431\n",
      "Epoch 32/40\n",
      "1094/1094 [==============================] - 1s 756us/step - loss: 0.5969 - acc: 0.6792 - val_loss: 0.3531 - val_acc: 0.8869\n",
      "Epoch 33/40\n",
      "1094/1094 [==============================] - 1s 670us/step - loss: 0.5970 - acc: 0.6782 - val_loss: 0.5240 - val_acc: 0.7591\n",
      "Epoch 34/40\n",
      "1094/1094 [==============================] - 1s 693us/step - loss: 0.5948 - acc: 0.6755 - val_loss: 0.4035 - val_acc: 0.8577\n",
      "Epoch 35/40\n",
      "1094/1094 [==============================] - 1s 705us/step - loss: 0.5963 - acc: 0.6782 - val_loss: 0.3616 - val_acc: 0.8796\n",
      "Epoch 36/40\n",
      "1094/1094 [==============================] - 1s 732us/step - loss: 0.5915 - acc: 0.6773 - val_loss: 0.5204 - val_acc: 0.7518\n",
      "Epoch 37/40\n",
      "1094/1094 [==============================] - 1s 711us/step - loss: 0.5904 - acc: 0.6810 - val_loss: 0.2908 - val_acc: 0.9307\n",
      "Epoch 38/40\n",
      "1094/1094 [==============================] - 1s 682us/step - loss: 0.5899 - acc: 0.6856 - val_loss: 0.5015 - val_acc: 0.7701\n",
      "Epoch 39/40\n",
      "1094/1094 [==============================] - 1s 690us/step - loss: 0.5913 - acc: 0.6865 - val_loss: 0.3451 - val_acc: 0.8650\n",
      "Epoch 40/40\n",
      "1094/1094 [==============================] - 1s 628us/step - loss: 0.5881 - acc: 0.6892 - val_loss: 0.3802 - val_acc: 0.8540\n",
      "153/153 [==============================] - 0s 30us/step\n",
      "Average accuracy of model on the dev set =  0.4183006531078052\n",
      "Training on fold 3/10.............................................\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_79 (Dense)             (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 5,425\n",
      "Trainable params: 5,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1094 samples, validate on 274 samples\n",
      "Epoch 1/40\n",
      "1094/1094 [==============================] - 2s 2ms/step - loss: 0.6928 - acc: 0.5110 - val_loss: 0.6438 - val_acc: 0.8832\n",
      "Epoch 2/40\n",
      "1094/1094 [==============================] - 1s 753us/step - loss: 0.6759 - acc: 0.5649 - val_loss: 0.6399 - val_acc: 0.7482\n",
      "Epoch 3/40\n",
      "1094/1094 [==============================] - 1s 736us/step - loss: 0.6674 - acc: 0.5667 - val_loss: 0.6238 - val_acc: 0.8723\n",
      "Epoch 4/40\n",
      "1094/1094 [==============================] - 1s 762us/step - loss: 0.6636 - acc: 0.5795 - val_loss: 0.5822 - val_acc: 0.8796\n",
      "Epoch 5/40\n",
      "1094/1094 [==============================] - 1s 741us/step - loss: 0.6628 - acc: 0.5804 - val_loss: 0.5885 - val_acc: 0.8723\n",
      "Epoch 6/40\n",
      "1094/1094 [==============================] - 1s 700us/step - loss: 0.6594 - acc: 0.5887 - val_loss: 0.5837 - val_acc: 0.8796\n",
      "Epoch 7/40\n",
      "1094/1094 [==============================] - 1s 752us/step - loss: 0.6579 - acc: 0.5978 - val_loss: 0.5470 - val_acc: 0.8869\n",
      "Epoch 8/40\n",
      "1094/1094 [==============================] - 1s 747us/step - loss: 0.6559 - acc: 0.6005 - val_loss: 0.5988 - val_acc: 0.8613\n",
      "Epoch 9/40\n",
      "1094/1094 [==============================] - 1s 695us/step - loss: 0.6525 - acc: 0.6106 - val_loss: 0.6331 - val_acc: 0.8175\n",
      "Epoch 10/40\n",
      "1094/1094 [==============================] - 1s 661us/step - loss: 0.6486 - acc: 0.6207 - val_loss: 0.5345 - val_acc: 0.8832\n",
      "Epoch 11/40\n",
      "1094/1094 [==============================] - 1s 666us/step - loss: 0.6459 - acc: 0.6197 - val_loss: 0.5456 - val_acc: 0.8686\n",
      "Epoch 12/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1094/1094 [==============================] - 1s 630us/step - loss: 0.6410 - acc: 0.6280 - val_loss: 0.5200 - val_acc: 0.8650\n",
      "Epoch 13/40\n",
      "1094/1094 [==============================] - 1s 623us/step - loss: 0.6348 - acc: 0.6417 - val_loss: 0.6876 - val_acc: 0.6606\n",
      "Epoch 14/40\n",
      "1094/1094 [==============================] - 1s 630us/step - loss: 0.6311 - acc: 0.6508 - val_loss: 0.5084 - val_acc: 0.7737\n",
      "Epoch 15/40\n",
      "1094/1094 [==============================] - 1s 624us/step - loss: 0.6297 - acc: 0.6499 - val_loss: 0.6249 - val_acc: 0.7044\n",
      "Epoch 16/40\n",
      "1094/1094 [==============================] - 1s 686us/step - loss: 0.6221 - acc: 0.6517 - val_loss: 0.5408 - val_acc: 0.7737\n",
      "Epoch 17/40\n",
      "1094/1094 [==============================] - 1s 857us/step - loss: 0.6206 - acc: 0.6654 - val_loss: 0.5202 - val_acc: 0.8431\n",
      "Epoch 18/40\n",
      "1094/1094 [==============================] - 1s 582us/step - loss: 0.6196 - acc: 0.6517 - val_loss: 0.5345 - val_acc: 0.8139\n",
      "Epoch 19/40\n",
      "1094/1094 [==============================] - 1s 804us/step - loss: 0.6157 - acc: 0.6728 - val_loss: 0.4729 - val_acc: 0.8394\n",
      "Epoch 20/40\n",
      "1094/1094 [==============================] - 1s 837us/step - loss: 0.6132 - acc: 0.6572 - val_loss: 0.3690 - val_acc: 0.8978\n",
      "Epoch 21/40\n",
      "1094/1094 [==============================] - 1s 560us/step - loss: 0.6147 - acc: 0.6490 - val_loss: 0.4157 - val_acc: 0.8723\n",
      "Epoch 22/40\n",
      "1094/1094 [==============================] - 1s 559us/step - loss: 0.6093 - acc: 0.6645 - val_loss: 0.3852 - val_acc: 0.9161\n",
      "Epoch 23/40\n",
      "1094/1094 [==============================] - 1s 662us/step - loss: 0.6111 - acc: 0.6609 - val_loss: 0.5277 - val_acc: 0.8029\n",
      "Epoch 24/40\n",
      "1094/1094 [==============================] - 1s 803us/step - loss: 0.6074 - acc: 0.6755 - val_loss: 0.3933 - val_acc: 0.9051\n",
      "Epoch 25/40\n",
      "1094/1094 [==============================] - 1s 647us/step - loss: 0.6070 - acc: 0.6682 - val_loss: 0.4186 - val_acc: 0.9051\n",
      "Epoch 26/40\n",
      "1094/1094 [==============================] - 1s 636us/step - loss: 0.6072 - acc: 0.6609 - val_loss: 0.4221 - val_acc: 0.8431\n",
      "Epoch 27/40\n",
      "1094/1094 [==============================] - 1s 723us/step - loss: 0.6030 - acc: 0.6691 - val_loss: 0.3661 - val_acc: 0.9015\n",
      "Epoch 28/40\n",
      "1094/1094 [==============================] - 1s 659us/step - loss: 0.6064 - acc: 0.6691 - val_loss: 0.3817 - val_acc: 0.8540\n",
      "Epoch 29/40\n",
      "1094/1094 [==============================] - 1s 661us/step - loss: 0.6031 - acc: 0.6709 - val_loss: 0.4567 - val_acc: 0.8431\n",
      "Epoch 30/40\n",
      "1094/1094 [==============================] - 1s 630us/step - loss: 0.6040 - acc: 0.6764 - val_loss: 0.4364 - val_acc: 0.8650\n",
      "Epoch 31/40\n",
      "1094/1094 [==============================] - 1s 657us/step - loss: 0.6022 - acc: 0.6700 - val_loss: 0.4148 - val_acc: 0.8759\n",
      "Epoch 32/40\n",
      "1094/1094 [==============================] - 1s 637us/step - loss: 0.5994 - acc: 0.6728 - val_loss: 0.4315 - val_acc: 0.8759\n",
      "Epoch 33/40\n",
      "1094/1094 [==============================] - 1s 845us/step - loss: 0.6001 - acc: 0.6810 - val_loss: 0.4599 - val_acc: 0.8321\n",
      "Epoch 34/40\n",
      "1094/1094 [==============================] - 1s 914us/step - loss: 0.5987 - acc: 0.6764 - val_loss: 0.5201 - val_acc: 0.7774\n",
      "Epoch 35/40\n",
      "1094/1094 [==============================] - 1s 936us/step - loss: 0.5991 - acc: 0.6746 - val_loss: 0.4217 - val_acc: 0.8650\n",
      "Epoch 36/40\n",
      "1094/1094 [==============================] - 1s 840us/step - loss: 0.5930 - acc: 0.6773 - val_loss: 0.3065 - val_acc: 0.9234\n",
      "Epoch 37/40\n",
      "1094/1094 [==============================] - 1s 679us/step - loss: 0.6003 - acc: 0.6718 - val_loss: 0.4140 - val_acc: 0.8540\n",
      "Epoch 38/40\n",
      "1094/1094 [==============================] - 1s 737us/step - loss: 0.5967 - acc: 0.6846 - val_loss: 0.4409 - val_acc: 0.8358\n",
      "Epoch 39/40\n",
      "1094/1094 [==============================] - 1s 634us/step - loss: 0.5988 - acc: 0.6792 - val_loss: 0.4401 - val_acc: 0.8358\n",
      "Epoch 40/40\n",
      "1094/1094 [==============================] - 1s 640us/step - loss: 0.5946 - acc: 0.6910 - val_loss: 0.2896 - val_acc: 0.9197\n",
      "153/153 [==============================] - 0s 31us/step\n",
      "Average accuracy of model on the dev set =  0.4444444439899428\n",
      "Training on fold 4/10.............................................\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_85 (Dense)             (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 5,425\n",
      "Trainable params: 5,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1095 samples, validate on 274 samples\n",
      "Epoch 1/40\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 0.6942 - acc: 0.5105 - val_loss: 0.6910 - val_acc: 0.2482\n",
      "Epoch 2/40\n",
      "1095/1095 [==============================] - 1s 677us/step - loss: 0.6839 - acc: 0.5434 - val_loss: 0.6581 - val_acc: 0.7263\n",
      "Epoch 3/40\n",
      "1095/1095 [==============================] - 1s 646us/step - loss: 0.6781 - acc: 0.5598 - val_loss: 0.6674 - val_acc: 0.6387\n",
      "Epoch 4/40\n",
      "1095/1095 [==============================] - 1s 732us/step - loss: 0.6757 - acc: 0.5434 - val_loss: 0.6317 - val_acc: 0.7409\n",
      "Epoch 5/40\n",
      "1095/1095 [==============================] - 1s 662us/step - loss: 0.6728 - acc: 0.5607 - val_loss: 0.6901 - val_acc: 0.1752\n",
      "Epoch 6/40\n",
      "1095/1095 [==============================] - 1s 644us/step - loss: 0.6736 - acc: 0.5470 - val_loss: 0.6338 - val_acc: 0.7555\n",
      "Epoch 7/40\n",
      "1095/1095 [==============================] - 1s 668us/step - loss: 0.6716 - acc: 0.5543 - val_loss: 0.6278 - val_acc: 0.6679\n",
      "Epoch 8/40\n",
      "1095/1095 [==============================] - 1s 646us/step - loss: 0.6704 - acc: 0.5571 - val_loss: 0.6589 - val_acc: 0.6387\n",
      "Epoch 9/40\n",
      "1095/1095 [==============================] - 1s 654us/step - loss: 0.6684 - acc: 0.5616 - val_loss: 0.6059 - val_acc: 0.8723\n",
      "Epoch 10/40\n",
      "1095/1095 [==============================] - 1s 654us/step - loss: 0.6664 - acc: 0.5644 - val_loss: 0.6518 - val_acc: 0.6825\n",
      "Epoch 11/40\n",
      "1095/1095 [==============================] - 1s 696us/step - loss: 0.6662 - acc: 0.5763 - val_loss: 0.6169 - val_acc: 0.8066\n",
      "Epoch 12/40\n",
      "1095/1095 [==============================] - 1s 677us/step - loss: 0.6639 - acc: 0.5616 - val_loss: 0.5929 - val_acc: 0.7920\n",
      "Epoch 13/40\n",
      "1095/1095 [==============================] - 1s 737us/step - loss: 0.6626 - acc: 0.5689 - val_loss: 0.6604 - val_acc: 0.5620\n",
      "Epoch 14/40\n",
      "1095/1095 [==============================] - 1s 683us/step - loss: 0.6604 - acc: 0.6046 - val_loss: 0.5782 - val_acc: 0.8832\n",
      "Epoch 15/40\n",
      "1095/1095 [==============================] - 1s 648us/step - loss: 0.6553 - acc: 0.5817 - val_loss: 0.7116 - val_acc: 0.1752\n",
      "Epoch 16/40\n",
      "1095/1095 [==============================] - 1s 672us/step - loss: 0.6577 - acc: 0.5808 - val_loss: 0.5907 - val_acc: 0.8613\n",
      "Epoch 17/40\n",
      "1095/1095 [==============================] - 1s 640us/step - loss: 0.6531 - acc: 0.6091 - val_loss: 0.5420 - val_acc: 0.9197\n",
      "Epoch 18/40\n",
      "1095/1095 [==============================] - 1s 647us/step - loss: 0.6517 - acc: 0.5954 - val_loss: 0.5551 - val_acc: 0.7737\n",
      "Epoch 19/40\n",
      "1095/1095 [==============================] - 1s 648us/step - loss: 0.6492 - acc: 0.6091 - val_loss: 0.5287 - val_acc: 0.9088\n",
      "Epoch 20/40\n",
      "1095/1095 [==============================] - 1s 652us/step - loss: 0.6466 - acc: 0.5973 - val_loss: 0.5628 - val_acc: 0.7628\n",
      "Epoch 21/40\n",
      "1095/1095 [==============================] - 1s 694us/step - loss: 0.6427 - acc: 0.6155 - val_loss: 0.5919 - val_acc: 0.7299\n",
      "Epoch 22/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1095/1095 [==============================] - 1s 696us/step - loss: 0.6415 - acc: 0.6174 - val_loss: 0.5681 - val_acc: 0.8394\n",
      "Epoch 23/40\n",
      "1095/1095 [==============================] - 1s 671us/step - loss: 0.6398 - acc: 0.6219 - val_loss: 0.6241 - val_acc: 0.6861\n",
      "Epoch 24/40\n",
      "1095/1095 [==============================] - 1s 650us/step - loss: 0.6397 - acc: 0.6247 - val_loss: 0.5374 - val_acc: 0.8285\n",
      "Epoch 25/40\n",
      "1095/1095 [==============================] - 1s 662us/step - loss: 0.6367 - acc: 0.6265 - val_loss: 0.5440 - val_acc: 0.7993\n",
      "Epoch 26/40\n",
      "1095/1095 [==============================] - 1s 713us/step - loss: 0.6365 - acc: 0.6228 - val_loss: 0.5543 - val_acc: 0.7409\n",
      "Epoch 27/40\n",
      "1095/1095 [==============================] - 1s 801us/step - loss: 0.6352 - acc: 0.6329 - val_loss: 0.4935 - val_acc: 0.8796\n",
      "Epoch 28/40\n",
      "1095/1095 [==============================] - 1s 771us/step - loss: 0.6316 - acc: 0.6338 - val_loss: 0.3702 - val_acc: 0.9234\n",
      "Epoch 29/40\n",
      "1095/1095 [==============================] - 1s 754us/step - loss: 0.6364 - acc: 0.6228 - val_loss: 0.4857 - val_acc: 0.8394\n",
      "Epoch 30/40\n",
      "1095/1095 [==============================] - 1s 732us/step - loss: 0.6303 - acc: 0.6438 - val_loss: 0.5242 - val_acc: 0.8540\n",
      "Epoch 31/40\n",
      "1095/1095 [==============================] - 1s 685us/step - loss: 0.6290 - acc: 0.6502 - val_loss: 0.5375 - val_acc: 0.8139\n",
      "Epoch 32/40\n",
      "1095/1095 [==============================] - 1s 686us/step - loss: 0.6289 - acc: 0.6393 - val_loss: 0.4593 - val_acc: 0.8175\n",
      "Epoch 33/40\n",
      "1095/1095 [==============================] - 1s 684us/step - loss: 0.6266 - acc: 0.6356 - val_loss: 0.4916 - val_acc: 0.8029\n",
      "Epoch 34/40\n",
      "1095/1095 [==============================] - 1s 682us/step - loss: 0.6264 - acc: 0.6384 - val_loss: 0.4544 - val_acc: 0.8832\n",
      "Epoch 35/40\n",
      "1095/1095 [==============================] - 1s 669us/step - loss: 0.6224 - acc: 0.6356 - val_loss: 0.4551 - val_acc: 0.8066\n",
      "Epoch 36/40\n",
      "1095/1095 [==============================] - 1s 685us/step - loss: 0.6229 - acc: 0.6466 - val_loss: 0.4206 - val_acc: 0.9015\n",
      "Epoch 37/40\n",
      "1095/1095 [==============================] - 1s 680us/step - loss: 0.6198 - acc: 0.6511 - val_loss: 0.4632 - val_acc: 0.7956\n",
      "Epoch 38/40\n",
      "1095/1095 [==============================] - 1s 703us/step - loss: 0.6203 - acc: 0.6502 - val_loss: 0.4652 - val_acc: 0.8577\n",
      "Epoch 39/40\n",
      "1095/1095 [==============================] - 1s 690us/step - loss: 0.6187 - acc: 0.6475 - val_loss: 0.4307 - val_acc: 0.8723\n",
      "Epoch 40/40\n",
      "1095/1095 [==============================] - 1s 685us/step - loss: 0.6182 - acc: 0.6621 - val_loss: 0.4838 - val_acc: 0.8431\n",
      "152/152 [==============================] - 0s 35us/step\n",
      "Average accuracy of model on the dev set =  0.4813596495662024\n",
      "Training on fold 5/10.............................................\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_91 (Dense)             (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 5,425\n",
      "Trainable params: 5,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1095 samples, validate on 274 samples\n",
      "Epoch 1/40\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 0.6952 - acc: 0.5005 - val_loss: 0.6790 - val_acc: 0.9927\n",
      "Epoch 2/40\n",
      "1095/1095 [==============================] - 1s 695us/step - loss: 0.6927 - acc: 0.4986 - val_loss: 0.6795 - val_acc: 0.8723\n",
      "Epoch 3/40\n",
      "1095/1095 [==============================] - 1s 696us/step - loss: 0.6891 - acc: 0.5516 - val_loss: 0.6515 - val_acc: 0.8832\n",
      "Epoch 4/40\n",
      "1095/1095 [==============================] - 1s 717us/step - loss: 0.6836 - acc: 0.5644 - val_loss: 0.6096 - val_acc: 0.9343\n",
      "Epoch 5/40\n",
      "1095/1095 [==============================] - 1s 747us/step - loss: 0.6808 - acc: 0.5626 - val_loss: 0.5953 - val_acc: 0.9307\n",
      "Epoch 6/40\n",
      "1095/1095 [==============================] - 1s 752us/step - loss: 0.6788 - acc: 0.5671 - val_loss: 0.5738 - val_acc: 0.9307\n",
      "Epoch 7/40\n",
      "1095/1095 [==============================] - 1s 722us/step - loss: 0.6782 - acc: 0.5607 - val_loss: 0.5975 - val_acc: 0.7883\n",
      "Epoch 8/40\n",
      "1095/1095 [==============================] - 1s 739us/step - loss: 0.6773 - acc: 0.5562 - val_loss: 0.6079 - val_acc: 0.7883\n",
      "Epoch 9/40\n",
      "1095/1095 [==============================] - 1s 714us/step - loss: 0.6762 - acc: 0.5689 - val_loss: 0.5862 - val_acc: 0.8686\n",
      "Epoch 10/40\n",
      "1095/1095 [==============================] - 1s 748us/step - loss: 0.6754 - acc: 0.5662 - val_loss: 0.5797 - val_acc: 0.7920\n",
      "Epoch 11/40\n",
      "1095/1095 [==============================] - 1s 823us/step - loss: 0.6739 - acc: 0.5726 - val_loss: 0.5655 - val_acc: 0.9270\n",
      "Epoch 12/40\n",
      "1095/1095 [==============================] - 1s 809us/step - loss: 0.6733 - acc: 0.5680 - val_loss: 0.5473 - val_acc: 0.9270\n",
      "Epoch 13/40\n",
      "1095/1095 [==============================] - 1s 744us/step - loss: 0.6732 - acc: 0.5662 - val_loss: 0.5660 - val_acc: 0.8723\n",
      "Epoch 14/40\n",
      "1095/1095 [==============================] - 1s 724us/step - loss: 0.6703 - acc: 0.5708 - val_loss: 0.6704 - val_acc: 0.6387\n",
      "Epoch 15/40\n",
      "1095/1095 [==============================] - 1s 737us/step - loss: 0.6719 - acc: 0.5790 - val_loss: 0.6232 - val_acc: 0.7737\n",
      "Epoch 16/40\n",
      "1095/1095 [==============================] - 1s 735us/step - loss: 0.6703 - acc: 0.5790 - val_loss: 0.6168 - val_acc: 0.7628\n",
      "Epoch 17/40\n",
      "1095/1095 [==============================] - 1s 752us/step - loss: 0.6687 - acc: 0.5817 - val_loss: 0.5738 - val_acc: 0.8321\n",
      "Epoch 18/40\n",
      "1095/1095 [==============================] - 1s 758us/step - loss: 0.6677 - acc: 0.5909 - val_loss: 0.5407 - val_acc: 0.9051\n",
      "Epoch 19/40\n",
      "1095/1095 [==============================] - 1s 754us/step - loss: 0.6668 - acc: 0.5963 - val_loss: 0.5127 - val_acc: 0.9234\n",
      "Epoch 20/40\n",
      "1095/1095 [==============================] - 1s 744us/step - loss: 0.6652 - acc: 0.5936 - val_loss: 0.6261 - val_acc: 0.7518\n",
      "Epoch 21/40\n",
      "1095/1095 [==============================] - 1s 830us/step - loss: 0.6660 - acc: 0.5927 - val_loss: 0.5637 - val_acc: 0.8650\n",
      "Epoch 22/40\n",
      "1095/1095 [==============================] - 1s 825us/step - loss: 0.6627 - acc: 0.5863 - val_loss: 0.4935 - val_acc: 0.9161\n",
      "Epoch 23/40\n",
      "1095/1095 [==============================] - 1s 868us/step - loss: 0.6637 - acc: 0.5854 - val_loss: 0.4813 - val_acc: 0.9197\n",
      "Epoch 24/40\n",
      "1095/1095 [==============================] - 1s 825us/step - loss: 0.6614 - acc: 0.5890 - val_loss: 0.4944 - val_acc: 0.9124\n",
      "Epoch 25/40\n",
      "1095/1095 [==============================] - 1s 842us/step - loss: 0.6584 - acc: 0.6000 - val_loss: 0.5772 - val_acc: 0.8029\n",
      "Epoch 26/40\n",
      "1095/1095 [==============================] - 1s 808us/step - loss: 0.6588 - acc: 0.5963 - val_loss: 0.4678 - val_acc: 0.9197\n",
      "Epoch 27/40\n",
      "1095/1095 [==============================] - 1s 1ms/step - loss: 0.6575 - acc: 0.5945 - val_loss: 0.5438 - val_acc: 0.8066\n",
      "Epoch 28/40\n",
      "1095/1095 [==============================] - 1s 835us/step - loss: 0.6556 - acc: 0.6009 - val_loss: 0.4823 - val_acc: 0.8686\n",
      "Epoch 29/40\n",
      "1095/1095 [==============================] - 1s 813us/step - loss: 0.6549 - acc: 0.6146 - val_loss: 0.5173 - val_acc: 0.7956\n",
      "Epoch 30/40\n",
      "1095/1095 [==============================] - 1s 751us/step - loss: 0.6528 - acc: 0.6137 - val_loss: 0.6192 - val_acc: 0.7445\n",
      "Epoch 31/40\n",
      "1095/1095 [==============================] - 1s 736us/step - loss: 0.6549 - acc: 0.6091 - val_loss: 0.5327 - val_acc: 0.8248\n",
      "Epoch 32/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1095/1095 [==============================] - 1s 703us/step - loss: 0.6538 - acc: 0.6174 - val_loss: 0.4702 - val_acc: 0.8869\n",
      "Epoch 33/40\n",
      "1095/1095 [==============================] - 1s 711us/step - loss: 0.6505 - acc: 0.6137 - val_loss: 0.4657 - val_acc: 0.8832\n",
      "Epoch 34/40\n",
      "1095/1095 [==============================] - 1s 720us/step - loss: 0.6518 - acc: 0.6219 - val_loss: 0.4344 - val_acc: 0.8978\n",
      "Epoch 35/40\n",
      "1095/1095 [==============================] - 1s 729us/step - loss: 0.6500 - acc: 0.6219 - val_loss: 0.5003 - val_acc: 0.8139\n",
      "Epoch 36/40\n",
      "1095/1095 [==============================] - 1s 715us/step - loss: 0.6507 - acc: 0.6119 - val_loss: 0.4239 - val_acc: 0.9051\n",
      "Epoch 37/40\n",
      "1095/1095 [==============================] - 1s 735us/step - loss: 0.6472 - acc: 0.6237 - val_loss: 0.5363 - val_acc: 0.8358\n",
      "Epoch 38/40\n",
      "1095/1095 [==============================] - 1s 711us/step - loss: 0.6479 - acc: 0.6210 - val_loss: 0.4474 - val_acc: 0.8869\n",
      "Epoch 39/40\n",
      "1095/1095 [==============================] - 1s 716us/step - loss: 0.6421 - acc: 0.6247 - val_loss: 0.5293 - val_acc: 0.8248\n",
      "Epoch 40/40\n",
      "1095/1095 [==============================] - 1s 733us/step - loss: 0.6466 - acc: 0.6128 - val_loss: 0.4744 - val_acc: 0.8759\n",
      "152/152 [==============================] - 0s 32us/step\n",
      "Average accuracy of model on the dev set =  0.5442982459687513\n",
      "Training on fold 6/10.............................................\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_97 (Dense)             (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 5,425\n",
      "Trainable params: 5,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1095 samples, validate on 274 samples\n",
      "Epoch 1/40\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 0.6925 - acc: 0.4950 - val_loss: 0.7160 - val_acc: 0.1387\n",
      "Epoch 2/40\n",
      "1095/1095 [==============================] - 1s 715us/step - loss: 0.6869 - acc: 0.5361 - val_loss: 0.6181 - val_acc: 0.9453\n",
      "Epoch 3/40\n",
      "1095/1095 [==============================] - 1s 752us/step - loss: 0.6796 - acc: 0.5425 - val_loss: 0.6251 - val_acc: 0.4635\n",
      "Epoch 4/40\n",
      "1095/1095 [==============================] - 1s 725us/step - loss: 0.6738 - acc: 0.5534 - val_loss: 0.6144 - val_acc: 0.8796\n",
      "Epoch 5/40\n",
      "1095/1095 [==============================] - 1s 738us/step - loss: 0.6694 - acc: 0.5671 - val_loss: 0.6048 - val_acc: 0.8796\n",
      "Epoch 6/40\n",
      "1095/1095 [==============================] - 1s 734us/step - loss: 0.6669 - acc: 0.5808 - val_loss: 0.6961 - val_acc: 0.3066\n",
      "Epoch 7/40\n",
      "1095/1095 [==============================] - 1s 733us/step - loss: 0.6672 - acc: 0.5635 - val_loss: 0.6125 - val_acc: 0.8723\n",
      "Epoch 8/40\n",
      "1095/1095 [==============================] - 1s 738us/step - loss: 0.6640 - acc: 0.5772 - val_loss: 0.6193 - val_acc: 0.8650\n",
      "Epoch 9/40\n",
      "1095/1095 [==============================] - 1s 701us/step - loss: 0.6623 - acc: 0.5954 - val_loss: 0.5990 - val_acc: 0.8723\n",
      "Epoch 10/40\n",
      "1095/1095 [==============================] - 1s 723us/step - loss: 0.6616 - acc: 0.5890 - val_loss: 0.6016 - val_acc: 0.8613\n",
      "Epoch 11/40\n",
      "1095/1095 [==============================] - 1s 729us/step - loss: 0.6585 - acc: 0.6100 - val_loss: 0.6011 - val_acc: 0.8832\n",
      "Epoch 12/40\n",
      "1095/1095 [==============================] - 1s 723us/step - loss: 0.6582 - acc: 0.6009 - val_loss: 0.6042 - val_acc: 0.8650\n",
      "Epoch 13/40\n",
      "1095/1095 [==============================] - 1s 762us/step - loss: 0.6561 - acc: 0.5945 - val_loss: 0.6287 - val_acc: 0.7628\n",
      "Epoch 14/40\n",
      "1095/1095 [==============================] - 1s 739us/step - loss: 0.6570 - acc: 0.5973 - val_loss: 0.5669 - val_acc: 0.8723\n",
      "Epoch 15/40\n",
      "1095/1095 [==============================] - 1s 748us/step - loss: 0.6553 - acc: 0.6064 - val_loss: 0.5952 - val_acc: 0.8540\n",
      "Epoch 16/40\n",
      "1095/1095 [==============================] - 1s 790us/step - loss: 0.6516 - acc: 0.6037 - val_loss: 0.4922 - val_acc: 0.8978\n",
      "Epoch 17/40\n",
      "1095/1095 [==============================] - 1s 753us/step - loss: 0.6524 - acc: 0.6091 - val_loss: 0.5453 - val_acc: 0.8796\n",
      "Epoch 18/40\n",
      "1095/1095 [==============================] - 1s 771us/step - loss: 0.6520 - acc: 0.6064 - val_loss: 0.5401 - val_acc: 0.8759\n",
      "Epoch 19/40\n",
      "1095/1095 [==============================] - 1s 761us/step - loss: 0.6501 - acc: 0.6091 - val_loss: 0.5716 - val_acc: 0.8175\n",
      "Epoch 20/40\n",
      "1095/1095 [==============================] - 1s 737us/step - loss: 0.6509 - acc: 0.6018 - val_loss: 0.5546 - val_acc: 0.8723\n",
      "Epoch 21/40\n",
      "1095/1095 [==============================] - 1s 724us/step - loss: 0.6484 - acc: 0.6000 - val_loss: 0.5077 - val_acc: 0.8796\n",
      "Epoch 22/40\n",
      "1095/1095 [==============================] - 1s 769us/step - loss: 0.6469 - acc: 0.6073 - val_loss: 0.5276 - val_acc: 0.8102\n",
      "Epoch 23/40\n",
      "1095/1095 [==============================] - 1s 743us/step - loss: 0.6448 - acc: 0.6201 - val_loss: 0.5977 - val_acc: 0.8139\n",
      "Epoch 24/40\n",
      "1095/1095 [==============================] - 1s 733us/step - loss: 0.6437 - acc: 0.6128 - val_loss: 0.5168 - val_acc: 0.8467\n",
      "Epoch 25/40\n",
      "1095/1095 [==============================] - 1s 786us/step - loss: 0.6444 - acc: 0.6137 - val_loss: 0.4763 - val_acc: 0.8759\n",
      "Epoch 26/40\n",
      "1095/1095 [==============================] - 1s 745us/step - loss: 0.6429 - acc: 0.6283 - val_loss: 0.4776 - val_acc: 0.8759\n",
      "Epoch 27/40\n",
      "1095/1095 [==============================] - 1s 811us/step - loss: 0.6426 - acc: 0.6082 - val_loss: 0.4674 - val_acc: 0.9088\n",
      "Epoch 28/40\n",
      "1095/1095 [==============================] - 1s 703us/step - loss: 0.6423 - acc: 0.6201 - val_loss: 0.4924 - val_acc: 0.8723\n",
      "Epoch 29/40\n",
      "1095/1095 [==============================] - 1s 742us/step - loss: 0.6393 - acc: 0.6192 - val_loss: 0.5346 - val_acc: 0.8431\n",
      "Epoch 30/40\n",
      "1095/1095 [==============================] - 1s 767us/step - loss: 0.6383 - acc: 0.6183 - val_loss: 0.4451 - val_acc: 0.9307\n",
      "Epoch 31/40\n",
      "1095/1095 [==============================] - 1s 743us/step - loss: 0.6391 - acc: 0.6256 - val_loss: 0.5466 - val_acc: 0.8431\n",
      "Epoch 32/40\n",
      "1095/1095 [==============================] - 1s 738us/step - loss: 0.6357 - acc: 0.6311 - val_loss: 0.5014 - val_acc: 0.8139\n",
      "Epoch 33/40\n",
      "1095/1095 [==============================] - 1s 741us/step - loss: 0.6378 - acc: 0.6037 - val_loss: 0.4929 - val_acc: 0.8686\n",
      "Epoch 34/40\n",
      "1095/1095 [==============================] - 1s 734us/step - loss: 0.6362 - acc: 0.6192 - val_loss: 0.4266 - val_acc: 0.9197\n",
      "Epoch 35/40\n",
      "1095/1095 [==============================] - 1s 706us/step - loss: 0.6333 - acc: 0.6274 - val_loss: 0.5527 - val_acc: 0.8248\n",
      "Epoch 36/40\n",
      "1095/1095 [==============================] - 1s 754us/step - loss: 0.6356 - acc: 0.6210 - val_loss: 0.6082 - val_acc: 0.7263\n",
      "Epoch 37/40\n",
      "1095/1095 [==============================] - 1s 734us/step - loss: 0.6355 - acc: 0.6274 - val_loss: 0.5277 - val_acc: 0.8029\n",
      "Epoch 38/40\n",
      "1095/1095 [==============================] - 1s 740us/step - loss: 0.6366 - acc: 0.6237 - val_loss: 0.4382 - val_acc: 0.9015\n",
      "Epoch 39/40\n",
      "1095/1095 [==============================] - 1s 977us/step - loss: 0.6364 - acc: 0.6247 - val_loss: 0.4327 - val_acc: 0.9197\n",
      "Epoch 40/40\n",
      "1095/1095 [==============================] - 1s 983us/step - loss: 0.6364 - acc: 0.6265 - val_loss: 0.5312 - val_acc: 0.8540\n",
      "152/152 [==============================] - 0s 33us/step\n",
      "Average accuracy of model on the dev set =  0.5774853798897083\n",
      "Training on fold 7/10.............................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_103 (Dense)            (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 5,425\n",
      "Trainable params: 5,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1095 samples, validate on 274 samples\n",
      "Epoch 1/40\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 0.7069 - acc: 0.4968 - val_loss: 0.7235 - val_acc: 0.1642\n",
      "Epoch 2/40\n",
      "1095/1095 [==============================] - 1s 773us/step - loss: 0.6902 - acc: 0.5288 - val_loss: 0.7226 - val_acc: 0.1350\n",
      "Epoch 3/40\n",
      "1095/1095 [==============================] - 1s 837us/step - loss: 0.6847 - acc: 0.5333 - val_loss: 0.6234 - val_acc: 0.8321\n",
      "Epoch 4/40\n",
      "1095/1095 [==============================] - 1s 811us/step - loss: 0.6804 - acc: 0.5543 - val_loss: 0.6726 - val_acc: 0.4051\n",
      "Epoch 5/40\n",
      "1095/1095 [==============================] - 1s 729us/step - loss: 0.6770 - acc: 0.5598 - val_loss: 0.6210 - val_acc: 0.7847\n",
      "Epoch 6/40\n",
      "1095/1095 [==============================] - 1s 851us/step - loss: 0.6749 - acc: 0.5607 - val_loss: 0.6332 - val_acc: 0.7847\n",
      "Epoch 7/40\n",
      "1095/1095 [==============================] - 1s 751us/step - loss: 0.6724 - acc: 0.5297 - val_loss: 0.5793 - val_acc: 0.8759\n",
      "Epoch 8/40\n",
      "1095/1095 [==============================] - 1s 725us/step - loss: 0.6710 - acc: 0.5598 - val_loss: 0.5888 - val_acc: 0.8358\n",
      "Epoch 9/40\n",
      "1095/1095 [==============================] - 1s 713us/step - loss: 0.6720 - acc: 0.5498 - val_loss: 0.6477 - val_acc: 0.7810\n",
      "Epoch 10/40\n",
      "1095/1095 [==============================] - 1s 747us/step - loss: 0.6676 - acc: 0.5744 - val_loss: 0.5574 - val_acc: 0.9380\n",
      "Epoch 11/40\n",
      "1095/1095 [==============================] - 1s 937us/step - loss: 0.6675 - acc: 0.5826 - val_loss: 0.6491 - val_acc: 0.7810\n",
      "Epoch 12/40\n",
      "1095/1095 [==============================] - 1s 841us/step - loss: 0.6659 - acc: 0.5671 - val_loss: 0.6532 - val_acc: 0.7810\n",
      "Epoch 13/40\n",
      "1095/1095 [==============================] - 1s 777us/step - loss: 0.6655 - acc: 0.5772 - val_loss: 0.5895 - val_acc: 0.8942\n",
      "Epoch 14/40\n",
      "1095/1095 [==============================] - 1s 731us/step - loss: 0.6640 - acc: 0.5826 - val_loss: 0.5512 - val_acc: 0.9343\n",
      "Epoch 15/40\n",
      "1095/1095 [==============================] - 1s 768us/step - loss: 0.6640 - acc: 0.5744 - val_loss: 0.6057 - val_acc: 0.8212\n",
      "Epoch 16/40\n",
      "1095/1095 [==============================] - 1s 731us/step - loss: 0.6616 - acc: 0.5799 - val_loss: 0.5755 - val_acc: 0.8796\n",
      "Epoch 17/40\n",
      "1095/1095 [==============================] - 1s 751us/step - loss: 0.6602 - acc: 0.5936 - val_loss: 0.6646 - val_acc: 0.7117\n",
      "Epoch 18/40\n",
      "1095/1095 [==============================] - 1s 747us/step - loss: 0.6602 - acc: 0.5927 - val_loss: 0.6412 - val_acc: 0.7737\n",
      "Epoch 19/40\n",
      "1095/1095 [==============================] - 1s 705us/step - loss: 0.6592 - acc: 0.5826 - val_loss: 0.6054 - val_acc: 0.8467\n",
      "Epoch 20/40\n",
      "1095/1095 [==============================] - 1s 748us/step - loss: 0.6576 - acc: 0.5991 - val_loss: 0.6026 - val_acc: 0.8686\n",
      "Epoch 21/40\n",
      "1095/1095 [==============================] - 1s 800us/step - loss: 0.6565 - acc: 0.6018 - val_loss: 0.5855 - val_acc: 0.7847\n",
      "Epoch 22/40\n",
      "1095/1095 [==============================] - 1s 807us/step - loss: 0.6562 - acc: 0.5900 - val_loss: 0.6206 - val_acc: 0.7591\n",
      "Epoch 23/40\n",
      "1095/1095 [==============================] - 1s 736us/step - loss: 0.6530 - acc: 0.6174 - val_loss: 0.5516 - val_acc: 0.8686\n",
      "Epoch 24/40\n",
      "1095/1095 [==============================] - 1s 827us/step - loss: 0.6512 - acc: 0.6183 - val_loss: 0.7507 - val_acc: 0.2956\n",
      "Epoch 25/40\n",
      "1095/1095 [==============================] - 1s 850us/step - loss: 0.6538 - acc: 0.5973 - val_loss: 0.5249 - val_acc: 0.8796\n",
      "Epoch 26/40\n",
      "1095/1095 [==============================] - 1s 876us/step - loss: 0.6499 - acc: 0.6037 - val_loss: 0.5594 - val_acc: 0.8321\n",
      "Epoch 27/40\n",
      "1095/1095 [==============================] - 1s 885us/step - loss: 0.6502 - acc: 0.6237 - val_loss: 0.6125 - val_acc: 0.7117\n",
      "Epoch 28/40\n",
      "1095/1095 [==============================] - 1s 840us/step - loss: 0.6470 - acc: 0.6137 - val_loss: 0.5925 - val_acc: 0.8248\n",
      "Epoch 29/40\n",
      "1095/1095 [==============================] - 1s 841us/step - loss: 0.6442 - acc: 0.6155 - val_loss: 0.5060 - val_acc: 0.8577\n",
      "Epoch 30/40\n",
      "1095/1095 [==============================] - 1s 728us/step - loss: 0.6442 - acc: 0.6183 - val_loss: 0.5001 - val_acc: 0.8650\n",
      "Epoch 31/40\n",
      "1095/1095 [==============================] - 1s 720us/step - loss: 0.6440 - acc: 0.6201 - val_loss: 0.5426 - val_acc: 0.8613\n",
      "Epoch 32/40\n",
      "1095/1095 [==============================] - 1s 748us/step - loss: 0.6413 - acc: 0.6228 - val_loss: 0.5618 - val_acc: 0.8212\n",
      "Epoch 33/40\n",
      "1095/1095 [==============================] - 1s 737us/step - loss: 0.6413 - acc: 0.6164 - val_loss: 0.5462 - val_acc: 0.8613\n",
      "Epoch 34/40\n",
      "1095/1095 [==============================] - 1s 892us/step - loss: 0.6393 - acc: 0.6237 - val_loss: 0.5216 - val_acc: 0.8759\n",
      "Epoch 35/40\n",
      "1095/1095 [==============================] - 1s 823us/step - loss: 0.6392 - acc: 0.6265 - val_loss: 0.4674 - val_acc: 0.8577\n",
      "Epoch 36/40\n",
      "1095/1095 [==============================] - 1s 862us/step - loss: 0.6377 - acc: 0.6329 - val_loss: 0.4980 - val_acc: 0.8321\n",
      "Epoch 37/40\n",
      "1095/1095 [==============================] - 1s 790us/step - loss: 0.6364 - acc: 0.6365 - val_loss: 0.4874 - val_acc: 0.8942\n",
      "Epoch 38/40\n",
      "1095/1095 [==============================] - 1s 782us/step - loss: 0.6354 - acc: 0.6283 - val_loss: 0.5755 - val_acc: 0.7299\n",
      "Epoch 39/40\n",
      "1095/1095 [==============================] - 1s 832us/step - loss: 0.6363 - acc: 0.6283 - val_loss: 0.5109 - val_acc: 0.8358\n",
      "Epoch 40/40\n",
      "1095/1095 [==============================] - 1s 859us/step - loss: 0.6379 - acc: 0.6210 - val_loss: 0.5029 - val_acc: 0.8613\n",
      "152/152 [==============================] - 0s 47us/step\n",
      "Average accuracy of model on the dev set =  0.5955513782513288\n",
      "Training on fold 8/10.............................................\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_109 (Dense)            (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 5,425\n",
      "Trainable params: 5,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1095 samples, validate on 274 samples\n",
      "Epoch 1/40\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 0.6981 - acc: 0.4968 - val_loss: 0.6255 - val_acc: 0.9416\n",
      "Epoch 2/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1095/1095 [==============================] - 1s 877us/step - loss: 0.6871 - acc: 0.5534 - val_loss: 0.6343 - val_acc: 0.8650\n",
      "Epoch 3/40\n",
      "1095/1095 [==============================] - 1s 842us/step - loss: 0.6837 - acc: 0.5553 - val_loss: 0.6172 - val_acc: 0.8686\n",
      "Epoch 4/40\n",
      "1095/1095 [==============================] - 1s 871us/step - loss: 0.6809 - acc: 0.5662 - val_loss: 0.6189 - val_acc: 0.8686\n",
      "Epoch 5/40\n",
      "1095/1095 [==============================] - 1s 935us/step - loss: 0.6781 - acc: 0.5653 - val_loss: 0.6026 - val_acc: 0.8686\n",
      "Epoch 6/40\n",
      "1095/1095 [==============================] - 1s 869us/step - loss: 0.6759 - acc: 0.5653 - val_loss: 0.6070 - val_acc: 0.8431\n",
      "Epoch 7/40\n",
      "1095/1095 [==============================] - 1s 862us/step - loss: 0.6749 - acc: 0.5662 - val_loss: 0.6395 - val_acc: 0.8431\n",
      "Epoch 8/40\n",
      "1095/1095 [==============================] - 1s 842us/step - loss: 0.6728 - acc: 0.5717 - val_loss: 0.5714 - val_acc: 0.8504\n",
      "Epoch 9/40\n",
      "1095/1095 [==============================] - 1s 931us/step - loss: 0.6725 - acc: 0.5717 - val_loss: 0.6097 - val_acc: 0.8467\n",
      "Epoch 10/40\n",
      "1095/1095 [==============================] - 1s 896us/step - loss: 0.6709 - acc: 0.5799 - val_loss: 0.6128 - val_acc: 0.8431\n",
      "Epoch 11/40\n",
      "1095/1095 [==============================] - 1s 949us/step - loss: 0.6700 - acc: 0.5781 - val_loss: 0.5657 - val_acc: 0.8504\n",
      "Epoch 12/40\n",
      "1095/1095 [==============================] - 1s 865us/step - loss: 0.6692 - acc: 0.5836 - val_loss: 0.5682 - val_acc: 0.8504\n",
      "Epoch 13/40\n",
      "1095/1095 [==============================] - 1s 931us/step - loss: 0.6675 - acc: 0.5973 - val_loss: 0.6363 - val_acc: 0.7080\n",
      "Epoch 14/40\n",
      "1095/1095 [==============================] - 1s 784us/step - loss: 0.6681 - acc: 0.5890 - val_loss: 0.5931 - val_acc: 0.8321\n",
      "Epoch 15/40\n",
      "1095/1095 [==============================] - 1s 784us/step - loss: 0.6664 - acc: 0.5909 - val_loss: 0.5736 - val_acc: 0.8540\n",
      "Epoch 16/40\n",
      "1095/1095 [==============================] - 1s 804us/step - loss: 0.6634 - acc: 0.5909 - val_loss: 0.5995 - val_acc: 0.8212\n",
      "Epoch 17/40\n",
      "1095/1095 [==============================] - 1s 799us/step - loss: 0.6630 - acc: 0.5963 - val_loss: 0.6028 - val_acc: 0.7226\n",
      "Epoch 18/40\n",
      "1095/1095 [==============================] - 1s 803us/step - loss: 0.6615 - acc: 0.5900 - val_loss: 0.6061 - val_acc: 0.7117\n",
      "Epoch 19/40\n",
      "1095/1095 [==============================] - 1s 787us/step - loss: 0.6605 - acc: 0.5963 - val_loss: 0.5832 - val_acc: 0.8102\n",
      "Epoch 20/40\n",
      "1095/1095 [==============================] - 1s 797us/step - loss: 0.6579 - acc: 0.6009 - val_loss: 0.6580 - val_acc: 0.6679\n",
      "Epoch 21/40\n",
      "1095/1095 [==============================] - 1s 752us/step - loss: 0.6595 - acc: 0.6000 - val_loss: 0.5493 - val_acc: 0.8248\n",
      "Epoch 22/40\n",
      "1095/1095 [==============================] - 1s 790us/step - loss: 0.6543 - acc: 0.6137 - val_loss: 0.5970 - val_acc: 0.7701\n",
      "Epoch 23/40\n",
      "1095/1095 [==============================] - 1s 821us/step - loss: 0.6537 - acc: 0.6228 - val_loss: 0.6123 - val_acc: 0.7518\n",
      "Epoch 24/40\n",
      "1095/1095 [==============================] - 1s 806us/step - loss: 0.6519 - acc: 0.6201 - val_loss: 0.5261 - val_acc: 0.8029\n",
      "Epoch 25/40\n",
      "1095/1095 [==============================] - 1s 778us/step - loss: 0.6486 - acc: 0.6247 - val_loss: 0.5726 - val_acc: 0.7591\n",
      "Epoch 26/40\n",
      "1095/1095 [==============================] - 1s 733us/step - loss: 0.6497 - acc: 0.6119 - val_loss: 0.5816 - val_acc: 0.7737\n",
      "Epoch 27/40\n",
      "1095/1095 [==============================] - 1s 778us/step - loss: 0.6476 - acc: 0.6219 - val_loss: 0.5019 - val_acc: 0.7956\n",
      "Epoch 28/40\n",
      "1095/1095 [==============================] - 1s 765us/step - loss: 0.6466 - acc: 0.6228 - val_loss: 0.5607 - val_acc: 0.7591\n",
      "Epoch 29/40\n",
      "1095/1095 [==============================] - 1s 767us/step - loss: 0.6429 - acc: 0.6265 - val_loss: 0.5232 - val_acc: 0.8029\n",
      "Epoch 30/40\n",
      "1095/1095 [==============================] - 1s 834us/step - loss: 0.6422 - acc: 0.6256 - val_loss: 0.5081 - val_acc: 0.8139\n",
      "Epoch 31/40\n",
      "1095/1095 [==============================] - 1s 782us/step - loss: 0.6430 - acc: 0.6237 - val_loss: 0.5325 - val_acc: 0.7664\n",
      "Epoch 32/40\n",
      "1095/1095 [==============================] - 1s 775us/step - loss: 0.6399 - acc: 0.6274 - val_loss: 0.5878 - val_acc: 0.7628\n",
      "Epoch 33/40\n",
      "1095/1095 [==============================] - 1s 894us/step - loss: 0.6371 - acc: 0.6256 - val_loss: 0.4799 - val_acc: 0.8175\n",
      "Epoch 34/40\n",
      "1095/1095 [==============================] - 1s 787us/step - loss: 0.6388 - acc: 0.6155 - val_loss: 0.5378 - val_acc: 0.7701\n",
      "Epoch 35/40\n",
      "1095/1095 [==============================] - 1s 883us/step - loss: 0.6371 - acc: 0.6365 - val_loss: 0.5851 - val_acc: 0.7409\n",
      "Epoch 36/40\n",
      "1095/1095 [==============================] - 1s 759us/step - loss: 0.6397 - acc: 0.6247 - val_loss: 0.5169 - val_acc: 0.7883\n",
      "Epoch 37/40\n",
      "1095/1095 [==============================] - 1s 832us/step - loss: 0.6344 - acc: 0.6292 - val_loss: 0.4756 - val_acc: 0.8139\n",
      "Epoch 38/40\n",
      "1095/1095 [==============================] - 1s 820us/step - loss: 0.6352 - acc: 0.6347 - val_loss: 0.5601 - val_acc: 0.7555\n",
      "Epoch 39/40\n",
      "1095/1095 [==============================] - 1s 783us/step - loss: 0.6346 - acc: 0.6311 - val_loss: 0.5005 - val_acc: 0.7774\n",
      "Epoch 40/40\n",
      "1095/1095 [==============================] - 1s 802us/step - loss: 0.6327 - acc: 0.6338 - val_loss: 0.4796 - val_acc: 0.8029\n",
      "152/152 [==============================] - 0s 51us/step\n",
      "Average accuracy of model on the dev set =  0.6222587713672506\n",
      "Training on fold 9/10.............................................\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_115 (Dense)            (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_118 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_119 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 5,425\n",
      "Trainable params: 5,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1096 samples, validate on 274 samples\n",
      "Epoch 1/40\n",
      "1096/1096 [==============================] - 2s 2ms/step - loss: 0.6953 - acc: 0.4927 - val_loss: 0.7425 - val_acc: 0.0000e+00\n",
      "Epoch 2/40\n",
      "1096/1096 [==============================] - 1s 788us/step - loss: 0.6898 - acc: 0.5356 - val_loss: 0.6682 - val_acc: 0.7445\n",
      "Epoch 3/40\n",
      "1096/1096 [==============================] - 1s 787us/step - loss: 0.6821 - acc: 0.5429 - val_loss: 0.6091 - val_acc: 0.8942\n",
      "Epoch 4/40\n",
      "1096/1096 [==============================] - 1s 828us/step - loss: 0.6763 - acc: 0.5575 - val_loss: 0.5916 - val_acc: 0.8978\n",
      "Epoch 5/40\n",
      "1096/1096 [==============================] - 1s 822us/step - loss: 0.6724 - acc: 0.5721 - val_loss: 0.6158 - val_acc: 0.7409\n",
      "Epoch 6/40\n",
      "1096/1096 [==============================] - 1s 887us/step - loss: 0.6700 - acc: 0.5648 - val_loss: 0.6448 - val_acc: 0.6277\n",
      "Epoch 7/40\n",
      "1096/1096 [==============================] - 1s 926us/step - loss: 0.6680 - acc: 0.5776 - val_loss: 0.5439 - val_acc: 0.8686\n",
      "Epoch 8/40\n",
      "1096/1096 [==============================] - 1s 836us/step - loss: 0.6679 - acc: 0.5757 - val_loss: 0.5712 - val_acc: 0.8358\n",
      "Epoch 9/40\n",
      "1096/1096 [==============================] - 1s 851us/step - loss: 0.6646 - acc: 0.5958 - val_loss: 0.5572 - val_acc: 0.8686\n",
      "Epoch 10/40\n",
      "1096/1096 [==============================] - 1s 851us/step - loss: 0.6645 - acc: 0.5830 - val_loss: 0.6020 - val_acc: 0.7372\n",
      "Epoch 11/40\n",
      "1096/1096 [==============================] - 1s 902us/step - loss: 0.6596 - acc: 0.5976 - val_loss: 0.5464 - val_acc: 0.8650\n",
      "Epoch 12/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1096/1096 [==============================] - 1s 849us/step - loss: 0.6609 - acc: 0.6031 - val_loss: 0.5663 - val_acc: 0.8431\n",
      "Epoch 13/40\n",
      "1096/1096 [==============================] - 1s 912us/step - loss: 0.6576 - acc: 0.5995 - val_loss: 0.5965 - val_acc: 0.7007\n",
      "Epoch 14/40\n",
      "1096/1096 [==============================] - 1s 877us/step - loss: 0.6547 - acc: 0.6214 - val_loss: 0.4694 - val_acc: 0.9051\n",
      "Epoch 15/40\n",
      "1096/1096 [==============================] - 1s 931us/step - loss: 0.6549 - acc: 0.5903 - val_loss: 0.5090 - val_acc: 0.8869\n",
      "Epoch 16/40\n",
      "1096/1096 [==============================] - 1s 936us/step - loss: 0.6524 - acc: 0.5995 - val_loss: 0.5211 - val_acc: 0.8431\n",
      "Epoch 17/40\n",
      "1096/1096 [==============================] - 1s 840us/step - loss: 0.6506 - acc: 0.6141 - val_loss: 0.5283 - val_acc: 0.7883\n",
      "Epoch 18/40\n",
      "1096/1096 [==============================] - 1s 748us/step - loss: 0.6459 - acc: 0.6177 - val_loss: 0.4530 - val_acc: 0.8504\n",
      "Epoch 19/40\n",
      "1096/1096 [==============================] - 1s 867us/step - loss: 0.6455 - acc: 0.6159 - val_loss: 0.5193 - val_acc: 0.8504\n",
      "Epoch 20/40\n",
      "1096/1096 [==============================] - 1s 825us/step - loss: 0.6420 - acc: 0.6305 - val_loss: 0.6046 - val_acc: 0.7299\n",
      "Epoch 21/40\n",
      "1096/1096 [==============================] - 1s 746us/step - loss: 0.6419 - acc: 0.6241 - val_loss: 0.5637 - val_acc: 0.7774\n",
      "Epoch 22/40\n",
      "1096/1096 [==============================] - 1s 744us/step - loss: 0.6440 - acc: 0.6186 - val_loss: 0.4921 - val_acc: 0.7993\n",
      "Epoch 23/40\n",
      "1096/1096 [==============================] - 1s 963us/step - loss: 0.6384 - acc: 0.6296 - val_loss: 0.4271 - val_acc: 0.8832\n",
      "Epoch 24/40\n",
      "1096/1096 [==============================] - 1s 795us/step - loss: 0.6361 - acc: 0.6250 - val_loss: 0.5448 - val_acc: 0.7810\n",
      "Epoch 25/40\n",
      "1096/1096 [==============================] - 1s 783us/step - loss: 0.6401 - acc: 0.6223 - val_loss: 0.5281 - val_acc: 0.7737\n",
      "Epoch 26/40\n",
      "1096/1096 [==============================] - 1s 871us/step - loss: 0.6353 - acc: 0.6277 - val_loss: 0.4435 - val_acc: 0.8869\n",
      "Epoch 27/40\n",
      "1096/1096 [==============================] - 1s 1ms/step - loss: 0.6342 - acc: 0.6323 - val_loss: 0.5873 - val_acc: 0.7044\n",
      "Epoch 28/40\n",
      "1096/1096 [==============================] - 1s 814us/step - loss: 0.6340 - acc: 0.6268 - val_loss: 0.4346 - val_acc: 0.8577\n",
      "Epoch 29/40\n",
      "1096/1096 [==============================] - 1s 1ms/step - loss: 0.6328 - acc: 0.6369 - val_loss: 0.5379 - val_acc: 0.7628\n",
      "Epoch 30/40\n",
      "1096/1096 [==============================] - 2s 1ms/step - loss: 0.6350 - acc: 0.6277 - val_loss: 0.5505 - val_acc: 0.7847\n",
      "Epoch 31/40\n",
      "1096/1096 [==============================] - 1s 886us/step - loss: 0.6300 - acc: 0.6250 - val_loss: 0.5623 - val_acc: 0.7482\n",
      "Epoch 32/40\n",
      "1096/1096 [==============================] - 1s 948us/step - loss: 0.6300 - acc: 0.6414 - val_loss: 0.4791 - val_acc: 0.8394\n",
      "Epoch 33/40\n",
      "1096/1096 [==============================] - 1s 948us/step - loss: 0.6289 - acc: 0.6277 - val_loss: 0.4553 - val_acc: 0.7956\n",
      "Epoch 34/40\n",
      "1096/1096 [==============================] - 1s 921us/step - loss: 0.6280 - acc: 0.6332 - val_loss: 0.5461 - val_acc: 0.7117\n",
      "Epoch 35/40\n",
      "1096/1096 [==============================] - 1s 957us/step - loss: 0.6282 - acc: 0.6223 - val_loss: 0.5085 - val_acc: 0.7920\n",
      "Epoch 36/40\n",
      "1096/1096 [==============================] - 1s 915us/step - loss: 0.6266 - acc: 0.6241 - val_loss: 0.4740 - val_acc: 0.8139\n",
      "Epoch 37/40\n",
      "1096/1096 [==============================] - 1s 797us/step - loss: 0.6250 - acc: 0.6286 - val_loss: 0.4087 - val_acc: 0.8942\n",
      "Epoch 38/40\n",
      "1096/1096 [==============================] - 1s 855us/step - loss: 0.6290 - acc: 0.6323 - val_loss: 0.5199 - val_acc: 0.7883\n",
      "Epoch 39/40\n",
      "1096/1096 [==============================] - 1s 867us/step - loss: 0.6267 - acc: 0.6332 - val_loss: 0.5187 - val_acc: 0.7701\n",
      "Epoch 40/40\n",
      "1096/1096 [==============================] - 1s 750us/step - loss: 0.6263 - acc: 0.6369 - val_loss: 0.4369 - val_acc: 0.8431\n",
      "151/151 [==============================] - 0s 37us/step\n",
      "Average accuracy of model on the dev set =  0.6406832935034904\n",
      "Training on fold 10/10.............................................\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_121 (Dense)            (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_123 (Dense)            (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_124 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_125 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_126 (Dense)            (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 5,425\n",
      "Trainable params: 5,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1096 samples, validate on 274 samples\n",
      "Epoch 1/40\n",
      "1096/1096 [==============================] - 2s 2ms/step - loss: 0.6939 - acc: 0.5036 - val_loss: 0.6754 - val_acc: 0.8175\n",
      "Epoch 2/40\n",
      "1096/1096 [==============================] - 1s 758us/step - loss: 0.6889 - acc: 0.5319 - val_loss: 0.6670 - val_acc: 0.7737\n",
      "Epoch 3/40\n",
      "1096/1096 [==============================] - 1s 649us/step - loss: 0.6830 - acc: 0.5420 - val_loss: 0.6425 - val_acc: 0.8650\n",
      "Epoch 4/40\n",
      "1096/1096 [==============================] - 1s 841us/step - loss: 0.6793 - acc: 0.5420 - val_loss: 0.6154 - val_acc: 0.8650\n",
      "Epoch 5/40\n",
      "1096/1096 [==============================] - 1s 749us/step - loss: 0.6768 - acc: 0.5347 - val_loss: 0.5791 - val_acc: 0.9197\n",
      "Epoch 6/40\n",
      "1096/1096 [==============================] - 1s 754us/step - loss: 0.6761 - acc: 0.5474 - val_loss: 0.5836 - val_acc: 0.8869\n",
      "Epoch 7/40\n",
      "1096/1096 [==============================] - 1s 777us/step - loss: 0.6760 - acc: 0.5675 - val_loss: 0.6233 - val_acc: 0.7628\n",
      "Epoch 8/40\n",
      "1096/1096 [==============================] - 1s 792us/step - loss: 0.6728 - acc: 0.5675 - val_loss: 0.6537 - val_acc: 0.2956\n",
      "Epoch 9/40\n",
      "1096/1096 [==============================] - 1s 787us/step - loss: 0.6726 - acc: 0.5620 - val_loss: 0.6413 - val_acc: 0.7263\n",
      "Epoch 10/40\n",
      "1096/1096 [==============================] - 1s 806us/step - loss: 0.6713 - acc: 0.5785 - val_loss: 0.5933 - val_acc: 0.8686\n",
      "Epoch 11/40\n",
      "1096/1096 [==============================] - 1s 790us/step - loss: 0.6701 - acc: 0.5830 - val_loss: 0.5797 - val_acc: 0.8759\n",
      "Epoch 12/40\n",
      "1096/1096 [==============================] - 1s 824us/step - loss: 0.6692 - acc: 0.5821 - val_loss: 0.5932 - val_acc: 0.8686\n",
      "Epoch 13/40\n",
      "1096/1096 [==============================] - 1s 797us/step - loss: 0.6683 - acc: 0.5757 - val_loss: 0.6204 - val_acc: 0.7445\n",
      "Epoch 14/40\n",
      "1096/1096 [==============================] - 1s 806us/step - loss: 0.6676 - acc: 0.5812 - val_loss: 0.5992 - val_acc: 0.8504\n",
      "Epoch 15/40\n",
      "1096/1096 [==============================] - 1s 799us/step - loss: 0.6658 - acc: 0.5903 - val_loss: 0.5692 - val_acc: 0.8686\n",
      "Epoch 16/40\n",
      "1096/1096 [==============================] - 1s 914us/step - loss: 0.6656 - acc: 0.5876 - val_loss: 0.5840 - val_acc: 0.8577\n",
      "Epoch 17/40\n",
      "1096/1096 [==============================] - 1s 760us/step - loss: 0.6634 - acc: 0.5903 - val_loss: 0.6361 - val_acc: 0.6971\n",
      "Epoch 18/40\n",
      "1096/1096 [==============================] - 1s 777us/step - loss: 0.6629 - acc: 0.5976 - val_loss: 0.5762 - val_acc: 0.8577\n",
      "Epoch 19/40\n",
      "1096/1096 [==============================] - 1s 754us/step - loss: 0.6616 - acc: 0.6031 - val_loss: 0.5985 - val_acc: 0.8394\n",
      "Epoch 20/40\n",
      "1096/1096 [==============================] - 1s 788us/step - loss: 0.6607 - acc: 0.6040 - val_loss: 0.5479 - val_acc: 0.8686\n",
      "Epoch 21/40\n",
      "1096/1096 [==============================] - 1s 905us/step - loss: 0.6597 - acc: 0.5976 - val_loss: 0.5695 - val_acc: 0.8540\n",
      "Epoch 22/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1096/1096 [==============================] - 1s 874us/step - loss: 0.6583 - acc: 0.6022 - val_loss: 0.6090 - val_acc: 0.7847\n",
      "Epoch 23/40\n",
      "1096/1096 [==============================] - 1s 853us/step - loss: 0.6545 - acc: 0.6068 - val_loss: 0.6220 - val_acc: 0.7226\n",
      "Epoch 24/40\n",
      "1096/1096 [==============================] - 1s 841us/step - loss: 0.6543 - acc: 0.6049 - val_loss: 0.5673 - val_acc: 0.8358\n",
      "Epoch 25/40\n",
      "1096/1096 [==============================] - 1s 654us/step - loss: 0.6552 - acc: 0.6223 - val_loss: 0.6105 - val_acc: 0.7920\n",
      "Epoch 26/40\n",
      "1096/1096 [==============================] - 1s 739us/step - loss: 0.6500 - acc: 0.6141 - val_loss: 0.6264 - val_acc: 0.6277\n",
      "Epoch 27/40\n",
      "1096/1096 [==============================] - 1s 778us/step - loss: 0.6515 - acc: 0.6131 - val_loss: 0.5378 - val_acc: 0.8394\n",
      "Epoch 28/40\n",
      "1096/1096 [==============================] - 1s 674us/step - loss: 0.6485 - acc: 0.6268 - val_loss: 0.5550 - val_acc: 0.7591\n",
      "Epoch 29/40\n",
      "1096/1096 [==============================] - 1s 753us/step - loss: 0.6489 - acc: 0.6159 - val_loss: 0.5776 - val_acc: 0.8139\n",
      "Epoch 30/40\n",
      "1096/1096 [==============================] - 1s 741us/step - loss: 0.6477 - acc: 0.6077 - val_loss: 0.5030 - val_acc: 0.8431\n",
      "Epoch 31/40\n",
      "1096/1096 [==============================] - 1s 707us/step - loss: 0.6462 - acc: 0.6177 - val_loss: 0.5543 - val_acc: 0.8285\n",
      "Epoch 32/40\n",
      "1096/1096 [==============================] - 1s 689us/step - loss: 0.6479 - acc: 0.6086 - val_loss: 0.5559 - val_acc: 0.8029\n",
      "Epoch 33/40\n",
      "1096/1096 [==============================] - 1s 689us/step - loss: 0.6408 - acc: 0.6286 - val_loss: 0.4753 - val_acc: 0.8796\n",
      "Epoch 34/40\n",
      "1096/1096 [==============================] - 1s 718us/step - loss: 0.6423 - acc: 0.6250 - val_loss: 0.5018 - val_acc: 0.8321\n",
      "Epoch 35/40\n",
      "1096/1096 [==============================] - 1s 685us/step - loss: 0.6389 - acc: 0.6268 - val_loss: 0.4990 - val_acc: 0.8248\n",
      "Epoch 36/40\n",
      "1096/1096 [==============================] - 1s 681us/step - loss: 0.6398 - acc: 0.6323 - val_loss: 0.5866 - val_acc: 0.7847\n",
      "Epoch 37/40\n",
      "1096/1096 [==============================] - 1s 682us/step - loss: 0.6368 - acc: 0.6277 - val_loss: 0.5133 - val_acc: 0.8139\n",
      "Epoch 38/40\n",
      "1096/1096 [==============================] - 1s 658us/step - loss: 0.6389 - acc: 0.6159 - val_loss: 0.5399 - val_acc: 0.7956\n",
      "Epoch 39/40\n",
      "1096/1096 [==============================] - 1s 687us/step - loss: 0.6361 - acc: 0.6268 - val_loss: 0.5041 - val_acc: 0.8102\n",
      "Epoch 40/40\n",
      "1096/1096 [==============================] - 1s 732us/step - loss: 0.6336 - acc: 0.6442 - val_loss: 0.4245 - val_acc: 0.9051\n",
      "151/151 [==============================] - 0s 36us/step\n",
      "Average accuracy of model on the dev set =  0.650124898243762\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, random_state=12)\n",
    "avg_loss = []\n",
    "avg_acc = []\n",
    "# Loop through the indices the split() method returns\n",
    "for index, (train_index, test_index) in enumerate(skf.split(all_data, labels)):\n",
    "    print(\"Training on fold \" + str(index + 1) + \"/10.............................................\")\n",
    "    # Generate batches from indices\n",
    "    x_train, x_test = all_data[train_index], all_data[test_index]\n",
    "    # use one-hot vectors as labels\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "\n",
    "    network = models.Sequential()\n",
    "    \n",
    "\n",
    "    network.add(layers.Dense(16, input_shape=(8,)))\n",
    "    network.add(layers.Dense(32, activation=\"relu\"))\n",
    "    network.add(layers.Dense(64, activation=\"relu\"))\n",
    "    network.add(layers.Dense(32, activation=\"relu\"))\n",
    "    network.add(layers.Dense(16, activation=\"sigmoid\"))\n",
    "    network.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Adam = Adam(lr=0.05)\n",
    "    network.compile(optimizer=Adam(lr=0.00038),\n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=['acc'])\n",
    "\n",
    "    network.summary()\n",
    "\n",
    "    history = network.fit(x_train, y_train, validation_split=0.2,\n",
    "                          epochs=40, verbose=1, batch_size=3)\n",
    "\n",
    "    loss, accuracy = network.evaluate(x_test, y_test)\n",
    "\n",
    "    # evaluate and store the accuracy\n",
    "#     loss, accuracy = model.evaluate(xtest_imagelist, ytest, verbose=1)\n",
    "    avg_loss.append(loss)\n",
    "    avg_acc.append(accuracy)\n",
    "\n",
    "    # cross validation score\n",
    "    print(\"Average accuracy of model on the dev set = \", np.mean(avg_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
