{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn import preprocessing\n",
    "# new data\n",
    "\n",
    "flying_forward_stationary1 = pd.read_csv(\"../data_files/serial_connection_on_mac_recordings/move_drone_forward_1.csv\")\n",
    "flying_forward_stationary2 = pd.read_csv(\"../data_files/serial_connection_on_mac_recordings/move_drone_forward_2.csv\")\n",
    "flying_forward_stationary3 = pd.read_csv(\"../data_files/serial_connection_on_mac_recordings/move_drone_forward_3_90secs.csv\")\n",
    "flying_forward_stationary4 = pd.read_csv(\"../data_files/serial_connection_on_mac_recordings/move_drone_forward_4.csv\")\n",
    "flying_forward_stationary5 = pd.read_csv(\"../data_files/serial_connection_on_mac_recordings/move_drone_forward_5.csv\")\n",
    "flying_forward_stationary6 = pd.read_csv(\"../data_files/serial_connection_on_mac_recordings/move_drone_forward_6.csv\")\n",
    "flying_forward_stationary7 = pd.read_csv(\"../data_files/serial_connection_on_mac_recordings/move_drone_forward_7.csv\")\n",
    "flying_forward_stationary8 = pd.read_csv(\"../data_files/serial_connection_on_mac_recordings/move_drone_forward_8.csv\")\n",
    "flying_forward_stationary9 = pd.read_csv(\"../data_files/serial_connection_on_mac_recordings/move_drone_forward_9.csv\")\n",
    "flying_forward_stationary10 = pd.read_csv(\"../data_files/serial_connection_on_mac_recordings/move_drone_forward_10_5mins.csv\")\n",
    "\n",
    "new_rest1 = pd.read_csv(\"../data_files/serial_connection_on_mac_recordings/rest.csv\")\n",
    "new_rest2 = pd.read_csv(\"../data_files/serial_connection_on_mac_recordings/rest2.csv\")\n",
    "new_rest3 = pd.read_csv(\"../data_files/serial_connection_on_mac_recordings/rest3.csv\")\n",
    "new_rest4 = pd.read_csv(\"../data_files/serial_connection_on_mac_recordings/rest_17ishmins.csv\")\n",
    "\n",
    "fly_forward = pd.concat([\n",
    "    flying_forward_stationary1, \n",
    "    flying_forward_stationary2,\n",
    "    flying_forward_stationary3,\n",
    "    flying_forward_stationary4, \n",
    "    flying_forward_stationary5,\n",
    "    flying_forward_stationary6, \n",
    "    flying_forward_stationary7,\n",
    "    flying_forward_stationary8, \n",
    "    flying_forward_stationary9,\n",
    "    flying_forward_stationary10\n",
    "])\n",
    "new_rest = pd.concat([new_rest1, new_rest2, new_rest3, new_rest4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "s = [new_rest.delta.mean(), new_rest.theta.mean(), new_rest.alphaLow.mean(), \n",
    "     new_rest.alphaHigh.mean(), new_rest.betaLow.mean(), new_rest.betaHigh.mean(), \n",
    "     new_rest.gammaLow.mean(), new_rest.gammaMid.mean()]\n",
    "\n",
    "index = ['delta', 'theta', 'alphaLow','alphaHigh', 'betaLow', 'betaHigh', 'gammaLow', 'gammaMid']\n",
    "\n",
    "df = pd.DataFrame({'resting': s}, index=index)\n",
    "ax = df.plot.bar(rot=0, figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ff = [fly_forward.delta.mean(), fly_forward.theta.mean(), fly_forward.alphaLow.mean(), \n",
    "     fly_forward.alphaHigh.mean(), fly_forward.betaLow.mean(), fly_forward.betaHigh.mean(), \n",
    "     fly_forward.gammaLow.mean(), fly_forward.gammaMid.mean()]\n",
    "\n",
    "index = ['delta', 'theta', 'alphaLow','alphaHigh', 'betaLow', 'betaHigh', 'gammaLow', 'gammaMid']\n",
    "\n",
    "df = pd.DataFrame({'fly_forward': ff}, index=index)\n",
    "ax = df.plot.bar(rot=0, figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ff = [fly_forward.delta.mean(), fly_forward.theta.mean(), fly_forward.alphaLow.mean(), \n",
    "     fly_forward.alphaHigh.mean(), fly_forward.betaLow.mean(), fly_forward.betaHigh.mean(), \n",
    "     fly_forward.gammaLow.mean(), fly_forward.gammaMid.mean()]\n",
    "\n",
    "s = [new_rest.delta.mean(), new_rest.theta.mean(), new_rest.alphaLow.mean(), \n",
    "     new_rest.alphaHigh.mean(), new_rest.betaLow.mean(), new_rest.betaHigh.mean(), \n",
    "     new_rest.gammaLow.mean(), new_rest.gammaMid.mean()]\n",
    "\n",
    "index = ['delta', 'theta', 'alphaLow','alphaHigh', 'betaLow', 'betaHigh', 'gammaLow', 'gammaMid']\n",
    "\n",
    "df = pd.DataFrame({'fly_forward': ff, 'resting': s}, index=index)\n",
    "ax = df.plot.bar(rot=0, figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "fly_forward_train = pd.concat([\n",
    "    flying_forward_stationary1, \n",
    "    flying_forward_stationary2,\n",
    "    flying_forward_stationary4,\n",
    "    flying_forward_stationary5, \n",
    "    flying_forward_stationary6,\n",
    "    flying_forward_stationary7,\n",
    "    flying_forward_stationary10\n",
    "])\n",
    "fly_forward_test = pd.concat([\n",
    "    flying_forward_stationary8, \n",
    "    flying_forward_stationary9,\n",
    "    flying_forward_stationary3\n",
    "])\n",
    "\n",
    "new_rest_train = pd.concat([new_rest1, new_rest2, new_rest4])\n",
    "new_rest_test = new_rest3\n",
    "\n",
    "train = pd.concat([fly_forward_train, new_rest_train])\n",
    "test = pd.concat([fly_forward_test, new_rest_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(['delta', 'theta'], axis=1)\n",
    "test = test.drop(['delta', 'theta'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an array of shape 30706, 9 = number of records by the features\n",
    "train_data = np.array([[0 for x in range(9)] for y in range(len(train))])\n",
    "for i in range(len(train)):\n",
    "    train_data[i] = [train.eegRawValue.values[i],\n",
    "                       train.delta.values[i],\n",
    "                       train.theta.values[i],\n",
    "                       train.alphaLow.values[i],\n",
    "                       train.alphaHigh.values[i],\n",
    "                       train.betaLow.values[i],\n",
    "                       train.betaHigh.values[i],\n",
    "                       train.gammaLow.values[i],\n",
    "                       train.gammaMid.values[i]]\n",
    "    \n",
    "# create an array of shape 30706, 9 = number of records by the features\n",
    "test_data = np.array([[0 for x in range(9)] for y in range(len(test))])\n",
    "for i in range(len(test)):\n",
    "    test_data[i] = [test.eegRawValue.values[i],\n",
    "                       test.delta.values[i],\n",
    "                       test.theta.values[i],\n",
    "                       test.alphaLow.values[i],\n",
    "                       test.alphaHigh.values[i],\n",
    "                       test.betaLow.values[i],\n",
    "                       test.betaHigh.values[i],\n",
    "                       test.gammaLow.values[i],\n",
    "                       test.gammaMid.values[i]]\n",
    "    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "encoder = LabelBinarizer()\n",
    "train_labels = encoder.fit_transform(train.action.values)\n",
    "test_labels = encoder.fit_transform(test.action.values)\n",
    "\n",
    "# creating training and test sets\n",
    "X_std = (train_data - train_data.min(axis=0)) / (train_data.max(axis=0) - train_data.min(axis=0))\n",
    "X_scaled = X_std * (np.max(train_data) - np.min(train_data)) + np.min(train_data)\n",
    "train_data = train_data.astype('float32') / X_scaled\n",
    "\n",
    "X_std_test = (test_data - test_data.min(axis=0)) / (test_data.max(axis=0) - test_data.min(axis=0))\n",
    "X_scaled_test = X_std_test * (np.max(test_data) - np.min(test_data)) + np.min(test_data)\n",
    "test_data = test_data.astype('float32') / X_scaled_test\n",
    "\n",
    "\n",
    "# # # standardisation works best for Random Forest\n",
    "# x_train = x_train.astype('float32')\n",
    "# x_test = x_test.astype('float32')\n",
    "# mean = x_train.mean(axis=0)\n",
    "# x_train -= mean\n",
    "# std = x_train.std(axis=0)\n",
    "# x_train /= std\n",
    "# x_test -= mean\n",
    "# x_test /= std\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "scaler = MinMaxScaler()\n",
    "stan_scaler = StandardScaler()\n",
    "\n",
    "# train_data = scaler.fit_transform(train_data)\n",
    "# test_data = scaler.fit_transform(test_data)\n",
    "# val_data = scaler.fit_transform(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_69 (Dense)             (None, 32)                320       \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 353\n",
      "Trainable params: 353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "17658/17658 [==============================] - 6s 319us/step - loss: 0.5109 - acc: 0.7972\n",
      "Epoch 2/10\n",
      "17658/17658 [==============================] - 8s 438us/step - loss: 0.5069 - acc: 0.8013\n",
      "Epoch 3/10\n",
      " 3860/17658 [=====>........................] - ETA: 7s - loss: 0.5159 - acc: 0.7927"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-123-40848802718a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m history = network.fit(train_data, train_labels,\n\u001b[0;32m---> 20\u001b[0;31m                       epochs=10, verbose=1, batch_size=5)\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mloss_and_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcallback_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0mdelta_t_median\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         if (self._delta_t_batch > 0. and\n\u001b[1;32m    119\u001b[0m            (delta_t_median > 0.95 * self._delta_t_batch and delta_t_median > 0.1)):\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mmedian\u001b[0;34m(a, axis, out, overwrite_input, keepdims)\u001b[0m\n\u001b[1;32m   3334\u001b[0m     \"\"\"\n\u001b[1;32m   3335\u001b[0m     r, k = _ureduce(a, func=_median, axis=axis, out=out,\n\u001b[0;32m-> 3336\u001b[0;31m                     overwrite_input=overwrite_input)\n\u001b[0m\u001b[1;32m   3337\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3338\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_ureduce\u001b[0;34m(a, func, **kwargs)\u001b[0m\n\u001b[1;32m   3248\u001b[0m         \u001b[0mkeepdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3250\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3251\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_median\u001b[0;34m(a, axis, out, overwrite_input)\u001b[0m\n\u001b[1;32m   3377\u001b[0m     \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3378\u001b[0m     \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3379\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3380\u001b[0m         \u001b[0;31m# index with slice to allow mean (below) to work\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3381\u001b[0m         \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "network = models.Sequential()\n",
    "\n",
    "network.add(layers.Dense(32, input_shape=(9,)))\n",
    "network.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Adam = Adam(lr=0.05)\n",
    "network.compile(optimizer='Adam',\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['acc'])\n",
    "\n",
    "network.summary()\n",
    "\n",
    "history = network.fit(train_data, train_labels,\n",
    "                      epochs=10, verbose=1, batch_size=5)\n",
    "\n",
    "loss_and_metrics = network.evaluate(test_data, test_labels)\n",
    "print('loss and metrics', loss_and_metrics)\n",
    "\n",
    "# print('prediction: ', network.predict(test_data))\n",
    "\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an array of shape 30706, 9 = number of records by the features\n",
    "train_data = np.array([[0 for x in range(7)] for y in range(len(train))])\n",
    "for i in range(len(train)):\n",
    "    train_data[i] = [train.eegRawValue.values[i],\n",
    "                       train.alphaLow.values[i],\n",
    "                       train.alphaHigh.values[i],\n",
    "                       train.betaLow.values[i],\n",
    "                       train.betaHigh.values[i],\n",
    "                       train.gammaLow.values[i],\n",
    "                       train.gammaMid.values[i]]\n",
    "    \n",
    "# create an array of shape 30706, 9 = number of records by the features\n",
    "test_data = np.array([[0 for x in range(7)] for y in range(len(test))])\n",
    "for i in range(len(test)):\n",
    "    test_data[i] = [test.eegRawValue.values[i],\n",
    "                       test.alphaLow.values[i],\n",
    "                       test.alphaHigh.values[i],\n",
    "                       test.betaLow.values[i],\n",
    "                       test.betaHigh.values[i],\n",
    "                       test.gammaLow.values[i],\n",
    "                       test.gammaMid.values[i]]\n",
    "    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "encoder = LabelBinarizer()\n",
    "train_labels = encoder.fit_transform(train.action.values)\n",
    "test_labels = encoder.fit_transform(test.action.values)\n",
    "\n",
    "# creating training and test sets\n",
    "X_std = (train_data - train_data.min(axis=0)) / (train_data.max(axis=0) - train_data.min(axis=0))\n",
    "X_scaled = X_std * (np.max(train_data) - np.min(train_data)) + np.min(train_data)\n",
    "train_data = train_data.astype('float32') / X_scaled\n",
    "\n",
    "X_std_test = (test_data - test_data.min(axis=0)) / (test_data.max(axis=0) - test_data.min(axis=0))\n",
    "X_scaled_test = X_std_test * (np.max(test_data) - np.min(test_data)) + np.min(test_data)\n",
    "test_data = test_data.astype('float32') / X_scaled_test\n",
    "\n",
    "\n",
    "# # # standardisation works best for Random Forest\n",
    "# x_train = x_train.astype('float32')\n",
    "# x_test = x_test.astype('float32')\n",
    "# mean = x_train.mean(axis=0)\n",
    "# x_train -= mean\n",
    "# std = x_train.std(axis=0)\n",
    "# x_train /= std\n",
    "# x_test -= mean\n",
    "# x_test /= std\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "scaler = MinMaxScaler()\n",
    "stan_scaler = StandardScaler()\n",
    "\n",
    "# train_data = scaler.fit_transform(train_data)\n",
    "# test_data = scaler.fit_transform(test_data)\n",
    "# val_data = scaler.fit_transform(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 32)                256       \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,401\n",
      "Trainable params: 2,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_20_input to have shape (7,) but got array with shape (9,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-ee9ae0a4e2b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m history = network.fit(train_data, train_labels, validation_split=0.1,\n\u001b[0;32m---> 22\u001b[0;31m                       epochs=10, verbose=1, batch_size=5)\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mloss_and_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    136\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected dense_20_input to have shape (7,) but got array with shape (9,)"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "network = models.Sequential()\n",
    "\n",
    "network.add(layers.Dense(32, input_shape=(7,)))\n",
    "network.add(layers.Dense(32, activation=\"relu\"))\n",
    "network.add(layers.Dense(32, activation=\"relu\"))\n",
    "network.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Adam = Adam(lr=0.05)\n",
    "network.compile(optimizer=\"Adam\",\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['acc'])\n",
    "\n",
    "network.summary()\n",
    "\n",
    "history = network.fit(train_data, train_labels, validation_split=0.1,\n",
    "                      epochs=10, verbose=1, batch_size=5)\n",
    "\n",
    "loss_and_metrics = network.evaluate(test_data, test_labels)\n",
    "print('loss and metrics', loss_and_metrics)\n",
    "\n",
    "# print('prediction: ', network.predict(test_data))\n",
    "\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an array of shape 30706, 9 = number of records by the features\n",
    "train_data = np.array([[0 for x in range(9)] for y in range(len(train))])\n",
    "for i in range(len(train)):\n",
    "    train_data[i] = [train.eegRawValue.values[i],\n",
    "                       train.delta.values[i],\n",
    "                       train.theta.values[i],\n",
    "                       train.alphaLow.values[i],\n",
    "                       train.alphaHigh.values[i],\n",
    "                       train.betaLow.values[i],\n",
    "                       train.betaHigh.values[i],\n",
    "                       train.gammaLow.values[i],\n",
    "                       train.gammaMid.values[i]]\n",
    "    \n",
    "# create an array of shape 30706, 9 = number of records by the features\n",
    "test_data = np.array([[0 for x in range(9)] for y in range(len(test))])\n",
    "for i in range(len(test)):\n",
    "    test_data[i] = [test.eegRawValue.values[i],\n",
    "                       test.delta.values[i],\n",
    "                       test.theta.values[i],\n",
    "                       test.alphaLow.values[i],\n",
    "                       test.alphaHigh.values[i],\n",
    "                       test.betaLow.values[i],\n",
    "                       test.betaHigh.values[i],\n",
    "                       test.gammaLow.values[i],\n",
    "                       test.gammaMid.values[i]]\n",
    "    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "encoder = LabelBinarizer()\n",
    "rfc_train_labels = encoder.fit_transform(train.action.values)\n",
    "rfc_test_labels = encoder.fit_transform(test.action.values)\n",
    "\n",
    "# standardisation works best for Random Forest\n",
    "train_data = train_data.astype('float32')\n",
    "test_data = test_data.astype('float32')\n",
    "mean = train_data.mean(axis=0)\n",
    "train_data -= mean\n",
    "std = train_data.std(axis=0)\n",
    "train_data /= std\n",
    "test_data -= mean\n",
    "test_data /= std\n",
    "\n",
    "# rfc_train_data = stan_scaler.fit_transform(rfc_train_data)\n",
    "# rfc_test_data = stan_scaler.fit_transform(rfc_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an array of shape 30706, 9 = number of records by the features\n",
    "train_data = np.array([[0 for x in range(7)] for y in range(len(train))])\n",
    "for i in range(len(train)):\n",
    "    train_data[i] = [train.eegRawValue.values[i],\n",
    "                       train.alphaLow.values[i],\n",
    "                       train.alphaHigh.values[i],\n",
    "                       train.betaLow.values[i],\n",
    "                       train.betaHigh.values[i],\n",
    "                       train.gammaLow.values[i],\n",
    "                       train.gammaMid.values[i]]\n",
    "    \n",
    "# create an array of shape 30706, 9 = number of records by the features\n",
    "test_data = np.array([[0 for x in range(7)] for y in range(len(test))])\n",
    "for i in range(len(test)):\n",
    "    test_data[i] = [test.eegRawValue.values[i],\n",
    "                       test.alphaLow.values[i],\n",
    "                       test.alphaHigh.values[i],\n",
    "                       test.betaLow.values[i],\n",
    "                       test.betaHigh.values[i],\n",
    "                       test.gammaLow.values[i],\n",
    "                       test.gammaMid.values[i]]\n",
    "    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "encoder = LabelBinarizer()\n",
    "rfc_train_labels = encoder.fit_transform(train.action.values)\n",
    "rfc_test_labels = encoder.fit_transform(test.action.values)\n",
    "\n",
    "# standardisation works best for Random Forest\n",
    "train_data = train_data.astype('float32')\n",
    "test_data = test_data.astype('float32')\n",
    "mean = train_data.mean(axis=0)\n",
    "train_data -= mean\n",
    "std = train_data.std(axis=0)\n",
    "train_data /= std\n",
    "test_data -= mean\n",
    "test_data /= std\n",
    "\n",
    "# rfc_train_data = stan_scaler.fit_transform(rfc_train_data)\n",
    "# rfc_test_data = stan_scaler.fit_transform(rfc_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01140843 0.20435106 0.11842848 0.09790519 0.12226094 0.23855323\n",
      " 0.20709267]\n",
      "The score for Random Forest  0.6475535168195719\n",
      "17658\n",
      "Accuracy for x_test: 0.6475535168195719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Random Forrest\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(train_data, train_labels)\n",
    "\n",
    "print(rfc.feature_importances_)\n",
    "\n",
    "# print(rfc.predict(test_data))\n",
    "\n",
    "print(\"The score for Random Forest \", rfc.score(test_data, test_labels))\n",
    "y_pred = rfc.predict(test_data)\n",
    "# print(\"The prediction for the test set is \", y_pred)\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(len(rfc_train_labels))\n",
    "print(\"Accuracy for x_test:\", metrics.accuracy_score(test_labels, y_pred))\n",
    "# scores = cross_val_score(rfc, rfc_data_all, rfc_all_labels, cv=5)\n",
    "# print(\"Cross Validation Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "The score for XGBoost  0.6303516819571865\n",
      "Accuracy for x_test: 0.6303516819571865\n",
      "Accuracy: 63.04%\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(train_data, train_labels)\n",
    "print(xgb)\n",
    "print(\"The score for XGBoost \", xgb.score(test_data, test_labels))\n",
    "y_pred = xgb.predict(test_data)\n",
    "# print(\"The prediction for the test set is \", y_pred)\n",
    "\n",
    "print(\"Accuracy for x_test:\", metrics.accuracy_score(test_labels, y_pred))\n",
    "\n",
    "\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = metrics.accuracy_score(test_labels, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
