{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "rest_android = pd.read_csv(\"../../data_files/data_from_android_api/rest/rest_25_mins.csv\")\n",
    "\n",
    "forward_android4 = pd.read_csv(\"../../data_files/data_from_android_api/forward/forward_5mins_4.csv\")\n",
    "forward_android5 = pd.read_csv(\"../../data_files/data_from_android_api/forward/forward_5mins_5.csv\")\n",
    "\n",
    "back1 = pd.read_csv('../../data_files/data_from_android_api/back/back_5mins_1.csv')\n",
    "back2 = pd.read_csv('../../data_files/data_from_android_api/back/back_5mins_2.csv')\n",
    "\n",
    "\n",
    "forward = pd.concat([forward_android5, forward_android4])\n",
    "back = pd.concat([back1, back2])\n",
    "\n",
    "dataDF = pd.concat([forward, back])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "u = [back.delta.mean(), back.theta.mean(), back.alphaLow.mean(), \n",
    "     back.betaHigh.mean(), back.betaLow.mean(), back.alphaHigh.mean(), \n",
    "     back.gammaLow.mean(), back.gammaMid.mean()]\n",
    "\n",
    "d = [forward.delta.mean(), forward.theta.mean(), forward.alphaLow.mean(), \n",
    "     forward.betaHigh.mean(), forward.betaLow.mean(), forward.alphaHigh.mean(), \n",
    "     forward.gammaLow.mean(), forward.gammaMid.mean()]\n",
    "\n",
    "\n",
    "index = ['delta', 'theta', 'alphaLow','alphaHigh', 'betaLow', 'betaHigh', 'gammaLow', 'gammaMid']\n",
    "\n",
    "df = pd.DataFrame({'back': u, 'forward': d}, index=index)\n",
    "ax = df.plot.bar(rot=0, figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# create an array of shape 30706, 9 = number of records by the features\n",
    "data = np.array([[0 for x in range(8)] for y in range(len(dataDF))])\n",
    "for i in range(len(dataDF)):\n",
    "    data[i] = [dataDF.delta.values[i],\n",
    "                       dataDF.theta.values[i],\n",
    "                       dataDF.alphaLow.values[i],\n",
    "                       dataDF.alphaHigh.values[i],\n",
    "                       dataDF.betaLow.values[i],\n",
    "                       dataDF.betaHigh.values[i],\n",
    "                       dataDF.gammaLow.values[i],\n",
    "                       dataDF.gammaMid.values[i]]\n",
    "    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "encoder = LabelBinarizer()\n",
    "labels = encoder.fit_transform(dataDF.action.values)\n",
    "\n",
    "# creating training and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, labels)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "scaler = MinMaxScaler()\n",
    "stan_scaler = StandardScaler()\n",
    "\n",
    "x_train = stan_scaler.fit_transform(x_train)\n",
    "x_test = stan_scaler.transform(x_test)\n",
    "\n",
    "all_data = dataDF.drop(['action'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.19387911 0.13444212 0.10819613 0.09117022 0.10716855 0.10922581\n",
      " 0.11133712 0.14458094]\n",
      "The score for Random Forest  0.5606557377049181\n",
      "913\n",
      "Accuracy for x_test: 0.5606557377049181\n",
      "Cross Validation Accuracy: 0.58 (+/- 0.21)\n",
      "[0.45901639 0.50819672 0.42622951 0.48360656 0.52459016 0.59836066\n",
      " 0.66393443 0.71311475 0.71900826 0.67768595]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Random Forrest\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(x_train, y_train)\n",
    "\n",
    "print(rfc.feature_importances_)\n",
    "\n",
    "print(\"The score for Random Forest \", rfc.score(x_test, y_test))\n",
    "y_pred = rfc.predict(x_test)\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(len(y_train))\n",
    "print(\"Accuracy for x_test:\", metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "scores = cross_val_score(rfc, all_data, labels, cv=10, scoring='accuracy')\n",
    "print(\"Cross Validation Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "The score for XGBoost  0.6360655737704918\n",
      "Accuracy for x_test: 0.6360655737704918\n",
      "Accuracy: 63.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracy: 0.64 (+/- 0.29)\n",
      "[0.43442623 0.51639344 0.5        0.58196721 0.55737705 0.55737705\n",
      " 0.79508197 0.85245902 0.82644628 0.75206612]\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(x_train, y_train)\n",
    "\n",
    "# plot feature importance\n",
    "plot_importance(xgb)\n",
    "pyplot.show()\n",
    "print(xgb)\n",
    "print(\"The score for XGBoost \", xgb.score(x_test, y_test))\n",
    "y_pred = xgb.predict(x_test)\n",
    "\n",
    "print(\"Accuracy for x_test:\", metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = metrics.accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "\n",
    "scores = cross_val_score(xgb, all_data, labels, cv=10, scoring='accuracy')\n",
    "print(\"Cross Validation Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_set = [(x_train, y_train), (x_test, y_test)]\n",
    "eval_metric = [\"auc\",\"error\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Tuning and feature importance XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score for XGBoost  0.6426229508196721\n",
      "Accuracy for x_test: 0.6426229508196721\n",
      "Accuracy: 64.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracy: 0.64 (+/- 0.30)\n",
      "[0.42622951 0.54098361 0.51639344 0.53278689 0.57377049 0.57377049\n",
      " 0.80327869 0.8442623  0.85123967 0.76033058]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresh=0.041, n=8, Accuracy: 64.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresh=0.043, n=7, Accuracy: 63.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresh=0.051, n=6, Accuracy: 63.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresh=0.063, n=5, Accuracy: 63.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresh=0.097, n=4, Accuracy: 62.95%\n",
      "Thresh=0.148, n=3, Accuracy: 64.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresh=0.150, n=2, Accuracy: 64.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresh=0.406, n=1, Accuracy: 64.26%\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "from numpy import sort\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "xgb = XGBClassifier(silent=True, \n",
    "                      scale_pos_weight=1,\n",
    "                      learning_rate=0.01,  \n",
    "                      colsample_bytree = 0.4,\n",
    "                      subsample = 0.8,\n",
    "                      objective='binary:logistic', \n",
    "                      n_estimators=1000, \n",
    "                      reg_alpha = 0.3,\n",
    "                      max_depth=4, \n",
    "                      gamma=10)\n",
    "xgb.fit(x_train, y_train)\n",
    "# plot feature importance\n",
    "plot_importance(xgb)\n",
    "pyplot.show()\n",
    "# print(xgb)\n",
    "print(\"The score for XGBoost \", xgb.score(x_test, y_test))\n",
    "y_pred = xgb.predict(x_test)\n",
    "\n",
    "print(\"Accuracy for x_test:\", metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = metrics.accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "\n",
    "scores = cross_val_score(xgb, all_data, labels, cv=10, scoring='accuracy')\n",
    "print(\"Cross Validation Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "print(scores)\n",
    "\n",
    "# Fit model using each importance as a threshold\n",
    "thresholds = sort(xgb.feature_importances_)\n",
    "for thresh in thresholds:\n",
    "\t# select features using threshold\n",
    "\tselection = SelectFromModel(xgb, threshold=thresh, prefit=True)\n",
    "\tselect_X_train = selection.transform(x_train)\n",
    "\t# train model\n",
    "\tselection_model = XGBClassifier(silent=True, \n",
    "                      scale_pos_weight=1,\n",
    "                      learning_rate=0.01,  \n",
    "                      colsample_bytree = 0.4,\n",
    "                      subsample = 0.8,\n",
    "                      objective='binary:logistic', \n",
    "                      n_estimators=1000, \n",
    "                      reg_alpha = 0.3,\n",
    "                      max_depth=4, \n",
    "                      gamma=10)\n",
    "\tselection_model.fit(select_X_train, y_train)\n",
    "\t# eval model\n",
    "\tselect_X_test = selection.transform(x_test)\n",
    "\ty_pred = selection_model.predict(select_X_test)\n",
    "\tpredictions = [round(value) for value in y_pred]\n",
    "\taccuracy = accuracy_score(y_test, predictions)\n",
    "\tprint(\"Thresh=%.3f, n=%d, Accuracy: %.2f%%\" % (thresh, select_X_train.shape[1], accuracy*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 5,425\n",
      "Trainable params: 5,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.6847 - acc: 0.5159\n",
      "Epoch 2/40\n",
      "913/913 [==============================] - 0s 453us/step - loss: 0.6700 - acc: 0.5586\n",
      "Epoch 3/40\n",
      "913/913 [==============================] - 0s 438us/step - loss: 0.6687 - acc: 0.5674\n",
      "Epoch 4/40\n",
      "913/913 [==============================] - 0s 426us/step - loss: 0.6680 - acc: 0.5882\n",
      "Epoch 5/40\n",
      "913/913 [==============================] - 0s 479us/step - loss: 0.6635 - acc: 0.5794\n",
      "Epoch 6/40\n",
      "913/913 [==============================] - 0s 489us/step - loss: 0.6611 - acc: 0.5882\n",
      "Epoch 7/40\n",
      "913/913 [==============================] - 0s 422us/step - loss: 0.6590 - acc: 0.5728\n",
      "Epoch 8/40\n",
      "913/913 [==============================] - 0s 442us/step - loss: 0.6564 - acc: 0.5893\n",
      "Epoch 9/40\n",
      "913/913 [==============================] - 0s 474us/step - loss: 0.6535 - acc: 0.5871\n",
      "Epoch 10/40\n",
      "913/913 [==============================] - 0s 470us/step - loss: 0.6464 - acc: 0.6166\n",
      "Epoch 11/40\n",
      "913/913 [==============================] - 0s 460us/step - loss: 0.6424 - acc: 0.6221\n",
      "Epoch 12/40\n",
      "913/913 [==============================] - 0s 536us/step - loss: 0.6356 - acc: 0.6287\n",
      "Epoch 13/40\n",
      "913/913 [==============================] - 0s 483us/step - loss: 0.6349 - acc: 0.6276\n",
      "Epoch 14/40\n",
      "913/913 [==============================] - 0s 493us/step - loss: 0.6302 - acc: 0.6287\n",
      "Epoch 15/40\n",
      "913/913 [==============================] - 0s 473us/step - loss: 0.6251 - acc: 0.6407 0s - loss: 0.6223 - acc: 0.642\n",
      "Epoch 16/40\n",
      "913/913 [==============================] - 0s 423us/step - loss: 0.6242 - acc: 0.6342\n",
      "Epoch 17/40\n",
      "913/913 [==============================] - 1s 555us/step - loss: 0.6221 - acc: 0.6429\n",
      "Epoch 18/40\n",
      "913/913 [==============================] - 0s 497us/step - loss: 0.6138 - acc: 0.6429 0s - loss: 0.6099 - acc: 0.6\n",
      "Epoch 19/40\n",
      "913/913 [==============================] - 0s 515us/step - loss: 0.6161 - acc: 0.6418 0s - loss: 0.6093 - acc:\n",
      "Epoch 20/40\n",
      "913/913 [==============================] - 0s 526us/step - loss: 0.6150 - acc: 0.6440\n",
      "Epoch 21/40\n",
      "913/913 [==============================] - 0s 483us/step - loss: 0.6108 - acc: 0.6473\n",
      "Epoch 22/40\n",
      "913/913 [==============================] - 0s 490us/step - loss: 0.6163 - acc: 0.6495\n",
      "Epoch 23/40\n",
      "913/913 [==============================] - 0s 521us/step - loss: 0.6111 - acc: 0.6528\n",
      "Epoch 24/40\n",
      "913/913 [==============================] - 0s 498us/step - loss: 0.6111 - acc: 0.6462\n",
      "Epoch 25/40\n",
      "913/913 [==============================] - 1s 597us/step - loss: 0.6069 - acc: 0.6550\n",
      "Epoch 26/40\n",
      "913/913 [==============================] - 1s 572us/step - loss: 0.6080 - acc: 0.6462\n",
      "Epoch 27/40\n",
      "913/913 [==============================] - 0s 518us/step - loss: 0.6041 - acc: 0.6473\n",
      "Epoch 28/40\n",
      "913/913 [==============================] - 0s 507us/step - loss: 0.6042 - acc: 0.6561\n",
      "Epoch 29/40\n",
      "913/913 [==============================] - 0s 536us/step - loss: 0.6025 - acc: 0.6550\n",
      "Epoch 30/40\n",
      "913/913 [==============================] - 0s 499us/step - loss: 0.5996 - acc: 0.6462\n",
      "Epoch 31/40\n",
      "913/913 [==============================] - 1s 551us/step - loss: 0.6013 - acc: 0.6407\n",
      "Epoch 32/40\n",
      "913/913 [==============================] - 0s 524us/step - loss: 0.5996 - acc: 0.6528\n",
      "Epoch 33/40\n",
      "913/913 [==============================] - 1s 603us/step - loss: 0.5985 - acc: 0.6506\n",
      "Epoch 34/40\n",
      "913/913 [==============================] - 0s 533us/step - loss: 0.5992 - acc: 0.6550 0s - loss: 0.6060 - acc: 0.6\n",
      "Epoch 35/40\n",
      "913/913 [==============================] - 0s 522us/step - loss: 0.6061 - acc: 0.6605\n",
      "Epoch 36/40\n",
      "913/913 [==============================] - 1s 572us/step - loss: 0.5980 - acc: 0.6550\n",
      "Epoch 37/40\n",
      "913/913 [==============================] - 0s 514us/step - loss: 0.5931 - acc: 0.6670\n",
      "Epoch 38/40\n",
      "913/913 [==============================] - 0s 527us/step - loss: 0.5913 - acc: 0.6659\n",
      "Epoch 39/40\n",
      "913/913 [==============================] - 1s 628us/step - loss: 0.5933 - acc: 0.6627\n",
      "Epoch 40/40\n",
      "913/913 [==============================] - 1s 553us/step - loss: 0.5902 - acc: 0.6648\n",
      "305/305 [==============================] - 0s 214us/step\n",
      "loss and metrics [0.7163659564784316, 0.6327868862230269]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "# from keras import regularizers kernel_regularizer=regularizers.l2(0.01), \n",
    "from keras.optimizers import Adam\n",
    "\n",
    "network = models.Sequential()\n",
    "\n",
    "network.add(layers.Dense(16, input_shape=(8,)))\n",
    "network.add(layers.Dense(32, activation=\"relu\"))\n",
    "network.add(layers.Dense(64, activation=\"relu\"))\n",
    "network.add(layers.Dense(32, activation=\"relu\"))\n",
    "network.add(layers.Dense(16, activation=\"sigmoid\"))\n",
    "network.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Adam = Adam(lr=0.05)\n",
    "network.compile(optimizer='Adam',\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['acc'])\n",
    "\n",
    "network.summary()\n",
    "\n",
    "history = network.fit(x_train, y_train,\n",
    "                      epochs=40, verbose=1, batch_size=3)\n",
    "\n",
    "loss_and_metrics = network.evaluate(x_test, y_test)\n",
    "print('loss and metrics', loss_and_metrics)\n",
    "\n",
    "# print('prediction: ', network.predict(test_data))\n",
    "\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "all_labels = dataDF.action.values\n",
    "\n",
    "encoder = LabelBinarizer()\n",
    "all_labels = encoder.fit_transform(all_labels)\n",
    "    \n",
    "# create an array of shape 30706, 9 = number of records by the features\n",
    "all_data = np.array([[0 for x in range(8)] for y in range(len(dataDF))])\n",
    "for i in range(len(dataDF)):\n",
    "    all_data[i] = [dataDF.delta.values[i],\n",
    "                       dataDF.theta.values[i],\n",
    "                       dataDF.alphaLow.values[i],\n",
    "                       dataDF.alphaHigh.values[i],\n",
    "                       dataDF.betaLow.values[i],\n",
    "                       dataDF.betaHigh.values[i],\n",
    "                       dataDF.gammaLow.values[i],\n",
    "                       dataDF.gammaMid.values[i]]\n",
    "    \n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "scaler = MinMaxScaler()\n",
    "stan_scaler = StandardScaler()\n",
    "\n",
    "all_data = scaler.fit_transform(all_data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold 1/10.............................................\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 32)                288       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,721\n",
      "Trainable params: 2,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 876 samples, validate on 220 samples\n",
      "Epoch 1/40\n",
      "876/876 [==============================] - 2s 2ms/step - loss: 0.6867 - acc: 0.6244 - val_loss: 1.0269 - val_acc: 0.0000e+00\n",
      "Epoch 2/40\n",
      "876/876 [==============================] - 1s 619us/step - loss: 0.6619 - acc: 0.6244 - val_loss: 0.9810 - val_acc: 0.0000e+00\n",
      "Epoch 3/40\n",
      "876/876 [==============================] - 1s 793us/step - loss: 0.6601 - acc: 0.6244 - val_loss: 0.9375 - val_acc: 0.0000e+00\n",
      "Epoch 4/40\n",
      "876/876 [==============================] - 1s 730us/step - loss: 0.6588 - acc: 0.6244 - val_loss: 0.9598 - val_acc: 0.0000e+00\n",
      "Epoch 5/40\n",
      "876/876 [==============================] - 1s 690us/step - loss: 0.6582 - acc: 0.6244 - val_loss: 0.9582 - val_acc: 0.0000e+00\n",
      "Epoch 6/40\n",
      "876/876 [==============================] - 1s 735us/step - loss: 0.6559 - acc: 0.6256 - val_loss: 0.8571 - val_acc: 0.0591\n",
      "Epoch 7/40\n",
      "876/876 [==============================] - 1s 698us/step - loss: 0.6553 - acc: 0.6256 - val_loss: 0.9522 - val_acc: 0.0000e+00\n",
      "Epoch 8/40\n",
      "876/876 [==============================] - 1s 754us/step - loss: 0.6553 - acc: 0.6244 - val_loss: 0.9555 - val_acc: 0.0000e+00\n",
      "Epoch 9/40\n",
      "876/876 [==============================] - 1s 763us/step - loss: 0.6527 - acc: 0.6256 - val_loss: 0.8825 - val_acc: 0.0591\n",
      "Epoch 10/40\n",
      "876/876 [==============================] - 1s 701us/step - loss: 0.6526 - acc: 0.6279 - val_loss: 0.9178 - val_acc: 0.0000e+00\n",
      "Epoch 11/40\n",
      "876/876 [==============================] - 1s 758us/step - loss: 0.6509 - acc: 0.6290 - val_loss: 0.8815 - val_acc: 0.0273\n",
      "Epoch 12/40\n",
      "876/876 [==============================] - 1s 719us/step - loss: 0.6512 - acc: 0.6324 - val_loss: 0.9068 - val_acc: 0.0273\n",
      "Epoch 13/40\n",
      "876/876 [==============================] - 1s 643us/step - loss: 0.6492 - acc: 0.6279 - val_loss: 0.8733 - val_acc: 0.0273\n",
      "Epoch 14/40\n",
      "876/876 [==============================] - 1s 690us/step - loss: 0.6492 - acc: 0.6336 - val_loss: 0.9473 - val_acc: 0.0045\n",
      "Epoch 15/40\n",
      "876/876 [==============================] - 1s 671us/step - loss: 0.6488 - acc: 0.6279 - val_loss: 0.9366 - val_acc: 0.0273\n",
      "Epoch 16/40\n",
      "876/876 [==============================] - 1s 696us/step - loss: 0.6466 - acc: 0.6336 - val_loss: 0.9080 - val_acc: 0.0273\n",
      "Epoch 17/40\n",
      "876/876 [==============================] - 1s 683us/step - loss: 0.6470 - acc: 0.6324 - val_loss: 0.9037 - val_acc: 0.0273\n",
      "Epoch 18/40\n",
      "876/876 [==============================] - 1s 663us/step - loss: 0.6448 - acc: 0.6324 - val_loss: 0.8890 - val_acc: 0.0273\n",
      "Epoch 19/40\n",
      "876/876 [==============================] - 1s 761us/step - loss: 0.6440 - acc: 0.6313 - val_loss: 0.8944 - val_acc: 0.0409\n",
      "Epoch 20/40\n",
      "876/876 [==============================] - 1s 649us/step - loss: 0.6443 - acc: 0.6347 - val_loss: 0.9067 - val_acc: 0.0273\n",
      "Epoch 21/40\n",
      "876/876 [==============================] - 1s 686us/step - loss: 0.6421 - acc: 0.6336 - val_loss: 0.8810 - val_acc: 0.0955\n",
      "Epoch 22/40\n",
      "876/876 [==============================] - 1s 667us/step - loss: 0.6411 - acc: 0.6358 - val_loss: 0.8972 - val_acc: 0.0636\n",
      "Epoch 23/40\n",
      "876/876 [==============================] - 1s 677us/step - loss: 0.6415 - acc: 0.6358 - val_loss: 0.8938 - val_acc: 0.0409\n",
      "Epoch 24/40\n",
      "876/876 [==============================] - 1s 655us/step - loss: 0.6403 - acc: 0.6381 - val_loss: 0.8869 - val_acc: 0.0636\n",
      "Epoch 25/40\n",
      "876/876 [==============================] - 1s 655us/step - loss: 0.6390 - acc: 0.6381 - val_loss: 0.8745 - val_acc: 0.0636\n",
      "Epoch 26/40\n",
      "876/876 [==============================] - 1s 700us/step - loss: 0.6388 - acc: 0.6370 - val_loss: 0.8929 - val_acc: 0.0409\n",
      "Epoch 27/40\n",
      "876/876 [==============================] - 1s 655us/step - loss: 0.6381 - acc: 0.6381 - val_loss: 0.8670 - val_acc: 0.1182\n",
      "Epoch 28/40\n",
      "876/876 [==============================] - 1s 651us/step - loss: 0.6380 - acc: 0.6347 - val_loss: 0.9401 - val_acc: 0.0409\n",
      "Epoch 29/40\n",
      "876/876 [==============================] - 1s 648us/step - loss: 0.6381 - acc: 0.6404 - val_loss: 0.8910 - val_acc: 0.0636\n",
      "Epoch 30/40\n",
      "876/876 [==============================] - 1s 642us/step - loss: 0.6357 - acc: 0.6450 - val_loss: 0.9177 - val_acc: 0.0409\n",
      "Epoch 31/40\n",
      "876/876 [==============================] - 1s 654us/step - loss: 0.6351 - acc: 0.6438 - val_loss: 0.9485 - val_acc: 0.0273\n",
      "Epoch 32/40\n",
      "876/876 [==============================] - 1s 694us/step - loss: 0.6345 - acc: 0.6427 - val_loss: 0.9152 - val_acc: 0.0409\n",
      "Epoch 33/40\n",
      "876/876 [==============================] - 1s 651us/step - loss: 0.6344 - acc: 0.6404 - val_loss: 0.9189 - val_acc: 0.0409\n",
      "Epoch 34/40\n",
      "876/876 [==============================] - 1s 644us/step - loss: 0.6335 - acc: 0.6473 - val_loss: 0.8837 - val_acc: 0.1182\n",
      "Epoch 35/40\n",
      "876/876 [==============================] - 0s 546us/step - loss: 0.6338 - acc: 0.6438 - val_loss: 0.8846 - val_acc: 0.0773\n",
      "Epoch 36/40\n",
      "876/876 [==============================] - 0s 518us/step - loss: 0.6321 - acc: 0.6473 - val_loss: 0.9547 - val_acc: 0.0409\n",
      "Epoch 37/40\n",
      "876/876 [==============================] - 0s 546us/step - loss: 0.6318 - acc: 0.6473 - val_loss: 0.9013 - val_acc: 0.0636\n",
      "Epoch 38/40\n",
      "876/876 [==============================] - 0s 424us/step - loss: 0.6314 - acc: 0.6461 - val_loss: 0.8798 - val_acc: 0.0636\n",
      "Epoch 39/40\n",
      "876/876 [==============================] - 0s 475us/step - loss: 0.6312 - acc: 0.6484 - val_loss: 0.9192 - val_acc: 0.0591\n",
      "Epoch 40/40\n",
      "876/876 [==============================] - 0s 509us/step - loss: 0.6307 - acc: 0.6427 - val_loss: 0.9331 - val_acc: 0.0409\n",
      "122/122 [==============================] - 0s 42us/step\n",
      "Average accuracy of model on the dev set =  0.5491803284795558\n",
      "Training on fold 2/10.............................................\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 32)                288       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,721\n",
      "Trainable params: 2,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 876 samples, validate on 220 samples\n",
      "Epoch 1/40\n",
      "876/876 [==============================] - 1s 2ms/step - loss: 0.6787 - acc: 0.5776 - val_loss: 0.9497 - val_acc: 0.0000e+00\n",
      "Epoch 2/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "876/876 [==============================] - 1s 781us/step - loss: 0.6619 - acc: 0.6244 - val_loss: 0.9756 - val_acc: 0.0000e+00\n",
      "Epoch 3/40\n",
      "876/876 [==============================] - 1s 707us/step - loss: 0.6613 - acc: 0.6244 - val_loss: 0.9792 - val_acc: 0.0000e+00\n",
      "Epoch 4/40\n",
      "876/876 [==============================] - 1s 602us/step - loss: 0.6601 - acc: 0.6244 - val_loss: 0.9495 - val_acc: 0.0000e+00\n",
      "Epoch 5/40\n",
      "876/876 [==============================] - 1s 589us/step - loss: 0.6597 - acc: 0.6244 - val_loss: 0.9473 - val_acc: 0.0000e+00\n",
      "Epoch 6/40\n",
      "876/876 [==============================] - 1s 577us/step - loss: 0.6584 - acc: 0.6244 - val_loss: 0.9477 - val_acc: 0.0000e+00\n",
      "Epoch 7/40\n",
      "876/876 [==============================] - 1s 573us/step - loss: 0.6576 - acc: 0.6244 - val_loss: 0.9623 - val_acc: 0.0000e+00\n",
      "Epoch 8/40\n",
      "876/876 [==============================] - 1s 572us/step - loss: 0.6572 - acc: 0.6244 - val_loss: 0.8942 - val_acc: 0.0000e+00\n",
      "Epoch 9/40\n",
      "876/876 [==============================] - 1s 616us/step - loss: 0.6562 - acc: 0.6244 - val_loss: 0.9313 - val_acc: 0.0000e+00\n",
      "Epoch 10/40\n",
      "876/876 [==============================] - 1s 614us/step - loss: 0.6551 - acc: 0.6244 - val_loss: 0.9274 - val_acc: 0.0000e+00\n",
      "Epoch 11/40\n",
      "876/876 [==============================] - 1s 642us/step - loss: 0.6533 - acc: 0.6244 - val_loss: 0.9287 - val_acc: 0.0000e+00\n",
      "Epoch 12/40\n",
      "876/876 [==============================] - 1s 596us/step - loss: 0.6520 - acc: 0.6244 - val_loss: 0.8805 - val_acc: 0.0364\n",
      "Epoch 13/40\n",
      "876/876 [==============================] - 1s 629us/step - loss: 0.6509 - acc: 0.6244 - val_loss: 0.9375 - val_acc: 0.0000e+00\n",
      "Epoch 14/40\n",
      "876/876 [==============================] - 1s 636us/step - loss: 0.6500 - acc: 0.6290 - val_loss: 0.9228 - val_acc: 0.0000e+00\n",
      "Epoch 15/40\n",
      "876/876 [==============================] - 1s 608us/step - loss: 0.6488 - acc: 0.6358 - val_loss: 0.9466 - val_acc: 0.0000e+00\n",
      "Epoch 16/40\n",
      "876/876 [==============================] - 1s 615us/step - loss: 0.6468 - acc: 0.6256 - val_loss: 0.9595 - val_acc: 0.0364\n",
      "Epoch 17/40\n",
      "876/876 [==============================] - 1s 632us/step - loss: 0.6462 - acc: 0.6244 - val_loss: 0.9623 - val_acc: 0.0591\n",
      "Epoch 18/40\n",
      "876/876 [==============================] - 1s 604us/step - loss: 0.6432 - acc: 0.6381 - val_loss: 0.8437 - val_acc: 0.2364\n",
      "Epoch 19/40\n",
      "876/876 [==============================] - 1s 625us/step - loss: 0.6441 - acc: 0.6381 - val_loss: 0.9413 - val_acc: 0.0591\n",
      "Epoch 20/40\n",
      "876/876 [==============================] - 1s 702us/step - loss: 0.6418 - acc: 0.6416 - val_loss: 0.8396 - val_acc: 0.2455\n",
      "Epoch 21/40\n",
      "876/876 [==============================] - 1s 682us/step - loss: 0.6412 - acc: 0.6416 - val_loss: 0.8102 - val_acc: 0.2727\n",
      "Epoch 22/40\n",
      "876/876 [==============================] - 1s 607us/step - loss: 0.6432 - acc: 0.6438 - val_loss: 0.8825 - val_acc: 0.0591\n",
      "Epoch 23/40\n",
      "876/876 [==============================] - 1s 653us/step - loss: 0.6409 - acc: 0.6427 - val_loss: 0.9205 - val_acc: 0.0591\n",
      "Epoch 24/40\n",
      "876/876 [==============================] - 1s 632us/step - loss: 0.6388 - acc: 0.6461 - val_loss: 0.9462 - val_acc: 0.0591\n",
      "Epoch 25/40\n",
      "876/876 [==============================] - 1s 623us/step - loss: 0.6388 - acc: 0.6507 - val_loss: 0.8990 - val_acc: 0.0591\n",
      "Epoch 26/40\n",
      "876/876 [==============================] - 1s 658us/step - loss: 0.6376 - acc: 0.6416 - val_loss: 0.9444 - val_acc: 0.0591\n",
      "Epoch 27/40\n",
      "876/876 [==============================] - 1s 614us/step - loss: 0.6371 - acc: 0.6461 - val_loss: 0.9241 - val_acc: 0.0591\n",
      "Epoch 28/40\n",
      "876/876 [==============================] - 1s 609us/step - loss: 0.6357 - acc: 0.6427 - val_loss: 0.8653 - val_acc: 0.1909\n",
      "Epoch 29/40\n",
      "876/876 [==============================] - 1s 652us/step - loss: 0.6351 - acc: 0.6461 - val_loss: 0.8672 - val_acc: 0.0682\n",
      "Epoch 30/40\n",
      "876/876 [==============================] - 1s 601us/step - loss: 0.6347 - acc: 0.6484 - val_loss: 0.9470 - val_acc: 0.0591\n",
      "Epoch 31/40\n",
      "876/876 [==============================] - 1s 641us/step - loss: 0.6351 - acc: 0.6495 - val_loss: 0.8787 - val_acc: 0.1864\n",
      "Epoch 32/40\n",
      "876/876 [==============================] - 1s 629us/step - loss: 0.6323 - acc: 0.6495 - val_loss: 0.8998 - val_acc: 0.0636\n",
      "Epoch 33/40\n",
      "876/876 [==============================] - 1s 622us/step - loss: 0.6340 - acc: 0.6553 - val_loss: 0.8918 - val_acc: 0.0636\n",
      "Epoch 34/40\n",
      "876/876 [==============================] - 1s 705us/step - loss: 0.6322 - acc: 0.6507 - val_loss: 0.8766 - val_acc: 0.1864\n",
      "Epoch 35/40\n",
      "876/876 [==============================] - 1s 605us/step - loss: 0.6312 - acc: 0.6564 - val_loss: 0.9183 - val_acc: 0.0773\n",
      "Epoch 36/40\n",
      "876/876 [==============================] - 1s 653us/step - loss: 0.6297 - acc: 0.6495 - val_loss: 0.9751 - val_acc: 0.0591\n",
      "Epoch 37/40\n",
      "876/876 [==============================] - 1s 626us/step - loss: 0.6311 - acc: 0.6541 - val_loss: 0.9049 - val_acc: 0.0591\n",
      "Epoch 38/40\n",
      "876/876 [==============================] - 1s 612us/step - loss: 0.6306 - acc: 0.6541 - val_loss: 0.9322 - val_acc: 0.0591\n",
      "Epoch 39/40\n",
      "876/876 [==============================] - 1s 615us/step - loss: 0.6293 - acc: 0.6553 - val_loss: 0.8885 - val_acc: 0.0773\n",
      "Epoch 40/40\n",
      "876/876 [==============================] - 1s 619us/step - loss: 0.6290 - acc: 0.6495 - val_loss: 0.9031 - val_acc: 0.0682\n",
      "122/122 [==============================] - 0s 54us/step\n",
      "Average accuracy of model on the dev set =  0.5204918038893919\n",
      "Training on fold 3/10.............................................\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 32)                288       \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,721\n",
      "Trainable params: 2,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 876 samples, validate on 220 samples\n",
      "Epoch 1/40\n",
      "876/876 [==============================] - 1s 1ms/step - loss: 0.6625 - acc: 0.6244 - val_loss: 0.9940 - val_acc: 0.0000e+00\n",
      "Epoch 2/40\n",
      "876/876 [==============================] - 1s 626us/step - loss: 0.6609 - acc: 0.6244 - val_loss: 0.9733 - val_acc: 0.0000e+00\n",
      "Epoch 3/40\n",
      "876/876 [==============================] - 1s 667us/step - loss: 0.6597 - acc: 0.6244 - val_loss: 0.9485 - val_acc: 0.0000e+00\n",
      "Epoch 4/40\n",
      "876/876 [==============================] - 1s 642us/step - loss: 0.6580 - acc: 0.6244 - val_loss: 0.9262 - val_acc: 0.0000e+00\n",
      "Epoch 5/40\n",
      "876/876 [==============================] - 1s 716us/step - loss: 0.6567 - acc: 0.6244 - val_loss: 0.9601 - val_acc: 0.0000e+00\n",
      "Epoch 6/40\n",
      "876/876 [==============================] - 1s 687us/step - loss: 0.6544 - acc: 0.6244 - val_loss: 1.0015 - val_acc: 0.0000e+00\n",
      "Epoch 7/40\n",
      "876/876 [==============================] - 1s 665us/step - loss: 0.6543 - acc: 0.6244 - val_loss: 0.9554 - val_acc: 0.0000e+00\n",
      "Epoch 8/40\n",
      "876/876 [==============================] - 1s 675us/step - loss: 0.6527 - acc: 0.6244 - val_loss: 0.9038 - val_acc: 0.0000e+00\n",
      "Epoch 9/40\n",
      "876/876 [==============================] - 1s 675us/step - loss: 0.6518 - acc: 0.6244 - val_loss: 0.9327 - val_acc: 0.0000e+00\n",
      "Epoch 10/40\n",
      "876/876 [==============================] - 1s 699us/step - loss: 0.6503 - acc: 0.6244 - val_loss: 0.8935 - val_acc: 0.0182\n",
      "Epoch 11/40\n",
      "876/876 [==============================] - 1s 651us/step - loss: 0.6496 - acc: 0.6279 - val_loss: 0.9245 - val_acc: 0.0227\n",
      "Epoch 12/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "876/876 [==============================] - 1s 649us/step - loss: 0.6486 - acc: 0.6279 - val_loss: 0.8871 - val_acc: 0.0227\n",
      "Epoch 13/40\n",
      "876/876 [==============================] - 1s 615us/step - loss: 0.6474 - acc: 0.6336 - val_loss: 0.9418 - val_acc: 0.0227\n",
      "Epoch 14/40\n",
      "876/876 [==============================] - 1s 638us/step - loss: 0.6466 - acc: 0.6336 - val_loss: 0.8885 - val_acc: 0.0227\n",
      "Epoch 15/40\n",
      "876/876 [==============================] - 1s 596us/step - loss: 0.6462 - acc: 0.6370 - val_loss: 0.9332 - val_acc: 0.0227\n",
      "Epoch 16/40\n",
      "876/876 [==============================] - 1s 588us/step - loss: 0.6455 - acc: 0.6381 - val_loss: 0.9228 - val_acc: 0.0227\n",
      "Epoch 17/40\n",
      "876/876 [==============================] - 1s 677us/step - loss: 0.6449 - acc: 0.6370 - val_loss: 0.8795 - val_acc: 0.0227\n",
      "Epoch 18/40\n",
      "876/876 [==============================] - 1s 646us/step - loss: 0.6433 - acc: 0.6381 - val_loss: 0.9527 - val_acc: 0.0227\n",
      "Epoch 19/40\n",
      "876/876 [==============================] - 1s 717us/step - loss: 0.6433 - acc: 0.6381 - val_loss: 0.9350 - val_acc: 0.0227\n",
      "Epoch 20/40\n",
      "876/876 [==============================] - 1s 707us/step - loss: 0.6429 - acc: 0.6313 - val_loss: 0.8936 - val_acc: 0.0409\n",
      "Epoch 21/40\n",
      "876/876 [==============================] - 1s 769us/step - loss: 0.6413 - acc: 0.6336 - val_loss: 0.8604 - val_acc: 0.0455\n",
      "Epoch 22/40\n",
      "876/876 [==============================] - 1s 658us/step - loss: 0.6416 - acc: 0.6416 - val_loss: 0.8846 - val_acc: 0.0409\n",
      "Epoch 23/40\n",
      "876/876 [==============================] - 1s 655us/step - loss: 0.6421 - acc: 0.6416 - val_loss: 0.8751 - val_acc: 0.0636\n",
      "Epoch 24/40\n",
      "876/876 [==============================] - 1s 609us/step - loss: 0.6410 - acc: 0.6427 - val_loss: 0.8958 - val_acc: 0.0455\n",
      "Epoch 25/40\n",
      "876/876 [==============================] - 1s 615us/step - loss: 0.6389 - acc: 0.6450 - val_loss: 0.9159 - val_acc: 0.0636\n",
      "Epoch 26/40\n",
      "876/876 [==============================] - 1s 612us/step - loss: 0.6389 - acc: 0.6358 - val_loss: 0.8815 - val_acc: 0.0636\n",
      "Epoch 27/40\n",
      "876/876 [==============================] - 1s 636us/step - loss: 0.6359 - acc: 0.6450 - val_loss: 0.9780 - val_acc: 0.0591\n",
      "Epoch 28/40\n",
      "876/876 [==============================] - 1s 711us/step - loss: 0.6394 - acc: 0.6416 - val_loss: 0.9243 - val_acc: 0.0591\n",
      "Epoch 29/40\n",
      "876/876 [==============================] - 1s 641us/step - loss: 0.6374 - acc: 0.6427 - val_loss: 0.8460 - val_acc: 0.0682\n",
      "Epoch 30/40\n",
      "876/876 [==============================] - 1s 684us/step - loss: 0.6398 - acc: 0.6370 - val_loss: 0.8933 - val_acc: 0.0636\n",
      "Epoch 31/40\n",
      "876/876 [==============================] - 1s 675us/step - loss: 0.6381 - acc: 0.6404 - val_loss: 0.8744 - val_acc: 0.0682\n",
      "Epoch 32/40\n",
      "876/876 [==============================] - 1s 676us/step - loss: 0.6355 - acc: 0.6404 - val_loss: 0.9086 - val_acc: 0.0636\n",
      "Epoch 33/40\n",
      "876/876 [==============================] - 1s 710us/step - loss: 0.6353 - acc: 0.6438 - val_loss: 0.8941 - val_acc: 0.0636\n",
      "Epoch 34/40\n",
      "876/876 [==============================] - 1s 734us/step - loss: 0.6346 - acc: 0.6393 - val_loss: 0.8878 - val_acc: 0.0636\n",
      "Epoch 35/40\n",
      "876/876 [==============================] - 1s 667us/step - loss: 0.6343 - acc: 0.6495 - val_loss: 0.8891 - val_acc: 0.0682\n",
      "Epoch 36/40\n",
      "876/876 [==============================] - 1s 794us/step - loss: 0.6325 - acc: 0.6450 - val_loss: 0.8776 - val_acc: 0.0682\n",
      "Epoch 37/40\n",
      "876/876 [==============================] - 1s 849us/step - loss: 0.6326 - acc: 0.6404 - val_loss: 0.8254 - val_acc: 0.1909\n",
      "Epoch 38/40\n",
      "876/876 [==============================] - 1s 657us/step - loss: 0.6325 - acc: 0.6484 - val_loss: 0.8402 - val_acc: 0.1909\n",
      "Epoch 39/40\n",
      "876/876 [==============================] - 1s 824us/step - loss: 0.6338 - acc: 0.6370 - val_loss: 0.9399 - val_acc: 0.0591\n",
      "Epoch 40/40\n",
      "876/876 [==============================] - 1s 795us/step - loss: 0.6304 - acc: 0.6438 - val_loss: 0.8499 - val_acc: 0.0682\n",
      "122/122 [==============================] - 0s 46us/step\n",
      "Average accuracy of model on the dev set =  0.5081967217593245\n",
      "Training on fold 4/10.............................................\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 32)                288       \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,721\n",
      "Trainable params: 2,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 876 samples, validate on 220 samples\n",
      "Epoch 1/40\n",
      "876/876 [==============================] - 2s 2ms/step - loss: 0.6956 - acc: 0.5400 - val_loss: 0.8917 - val_acc: 0.0000e+00\n",
      "Epoch 2/40\n",
      "876/876 [==============================] - 1s 647us/step - loss: 0.6651 - acc: 0.6244 - val_loss: 0.9157 - val_acc: 0.0000e+00\n",
      "Epoch 3/40\n",
      "876/876 [==============================] - 1s 622us/step - loss: 0.6629 - acc: 0.6244 - val_loss: 1.0133 - val_acc: 0.0000e+00\n",
      "Epoch 4/40\n",
      "876/876 [==============================] - 1s 633us/step - loss: 0.6632 - acc: 0.6244 - val_loss: 0.9418 - val_acc: 0.0000e+00\n",
      "Epoch 5/40\n",
      "876/876 [==============================] - 1s 643us/step - loss: 0.6616 - acc: 0.6244 - val_loss: 0.9760 - val_acc: 0.0000e+00\n",
      "Epoch 6/40\n",
      "876/876 [==============================] - 1s 782us/step - loss: 0.6611 - acc: 0.6244 - val_loss: 0.9153 - val_acc: 0.0000e+00\n",
      "Epoch 7/40\n",
      "876/876 [==============================] - 1s 648us/step - loss: 0.6608 - acc: 0.6244 - val_loss: 0.9415 - val_acc: 0.0000e+00\n",
      "Epoch 8/40\n",
      "876/876 [==============================] - 1s 643us/step - loss: 0.6597 - acc: 0.6244 - val_loss: 0.9362 - val_acc: 0.0000e+00\n",
      "Epoch 9/40\n",
      "876/876 [==============================] - 1s 638us/step - loss: 0.6587 - acc: 0.6244 - val_loss: 0.8915 - val_acc: 0.0000e+00\n",
      "Epoch 10/40\n",
      "876/876 [==============================] - 1s 655us/step - loss: 0.6579 - acc: 0.6244 - val_loss: 0.9462 - val_acc: 0.0000e+00\n",
      "Epoch 11/40\n",
      "876/876 [==============================] - 1s 611us/step - loss: 0.6570 - acc: 0.6244 - val_loss: 0.9314 - val_acc: 0.0000e+00\n",
      "Epoch 12/40\n",
      "876/876 [==============================] - 1s 609us/step - loss: 0.6549 - acc: 0.6244 - val_loss: 0.8677 - val_acc: 0.0000e+00\n",
      "Epoch 13/40\n",
      "876/876 [==============================] - 1s 571us/step - loss: 0.6545 - acc: 0.6244 - val_loss: 0.9100 - val_acc: 0.0000e+00\n",
      "Epoch 14/40\n",
      "876/876 [==============================] - 1s 721us/step - loss: 0.6527 - acc: 0.6244 - val_loss: 0.8552 - val_acc: 0.0136\n",
      "Epoch 15/40\n",
      "876/876 [==============================] - 1s 715us/step - loss: 0.6531 - acc: 0.6256 - val_loss: 0.9093 - val_acc: 0.0000e+00\n",
      "Epoch 16/40\n",
      "876/876 [==============================] - 1s 691us/step - loss: 0.6514 - acc: 0.6221 - val_loss: 0.9343 - val_acc: 0.0000e+00\n",
      "Epoch 17/40\n",
      "876/876 [==============================] - 1s 709us/step - loss: 0.6498 - acc: 0.6244 - val_loss: 0.8925 - val_acc: 0.0182\n",
      "Epoch 18/40\n",
      "876/876 [==============================] - 1s 661us/step - loss: 0.6493 - acc: 0.6256 - val_loss: 0.9278 - val_acc: 0.0136\n",
      "Epoch 19/40\n",
      "876/876 [==============================] - 1s 659us/step - loss: 0.6482 - acc: 0.6336 - val_loss: 0.8895 - val_acc: 0.0182\n",
      "Epoch 20/40\n",
      "876/876 [==============================] - 1s 648us/step - loss: 0.6478 - acc: 0.6313 - val_loss: 0.8778 - val_acc: 0.0455\n",
      "Epoch 21/40\n",
      "876/876 [==============================] - 1s 684us/step - loss: 0.6459 - acc: 0.6370 - val_loss: 0.9306 - val_acc: 0.0182\n",
      "Epoch 22/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "876/876 [==============================] - 1s 637us/step - loss: 0.6467 - acc: 0.6438 - val_loss: 0.9420 - val_acc: 0.0409\n",
      "Epoch 23/40\n",
      "876/876 [==============================] - 1s 638us/step - loss: 0.6451 - acc: 0.6461 - val_loss: 0.9229 - val_acc: 0.0455\n",
      "Epoch 24/40\n",
      "876/876 [==============================] - 1s 706us/step - loss: 0.6450 - acc: 0.6404 - val_loss: 0.8891 - val_acc: 0.0636\n",
      "Epoch 25/40\n",
      "876/876 [==============================] - 1s 671us/step - loss: 0.6438 - acc: 0.6416 - val_loss: 0.8235 - val_acc: 0.2000\n",
      "Epoch 26/40\n",
      "876/876 [==============================] - 1s 621us/step - loss: 0.6425 - acc: 0.6427 - val_loss: 0.9178 - val_acc: 0.0636\n",
      "Epoch 27/40\n",
      "876/876 [==============================] - 1s 729us/step - loss: 0.6438 - acc: 0.6473 - val_loss: 0.8638 - val_acc: 0.0636\n",
      "Epoch 28/40\n",
      "876/876 [==============================] - 1s 692us/step - loss: 0.6432 - acc: 0.6313 - val_loss: 0.8920 - val_acc: 0.0636\n",
      "Epoch 29/40\n",
      "876/876 [==============================] - 1s 673us/step - loss: 0.6420 - acc: 0.6416 - val_loss: 0.9713 - val_acc: 0.0136\n",
      "Epoch 30/40\n",
      "876/876 [==============================] - 1s 668us/step - loss: 0.6424 - acc: 0.6473 - val_loss: 0.8750 - val_acc: 0.0636\n",
      "Epoch 31/40\n",
      "876/876 [==============================] - 1s 667us/step - loss: 0.6414 - acc: 0.6416 - val_loss: 1.0164 - val_acc: 0.0318\n",
      "Epoch 32/40\n",
      "876/876 [==============================] - 1s 665us/step - loss: 0.6418 - acc: 0.6416 - val_loss: 0.8599 - val_acc: 0.0636\n",
      "Epoch 33/40\n",
      "876/876 [==============================] - 1s 583us/step - loss: 0.6403 - acc: 0.6461 - val_loss: 0.9266 - val_acc: 0.0591\n",
      "Epoch 34/40\n",
      "876/876 [==============================] - 0s 564us/step - loss: 0.6403 - acc: 0.6393 - val_loss: 0.8700 - val_acc: 0.1864\n",
      "Epoch 35/40\n",
      "876/876 [==============================] - 0s 557us/step - loss: 0.6383 - acc: 0.6450 - val_loss: 0.8943 - val_acc: 0.0636\n",
      "Epoch 36/40\n",
      "876/876 [==============================] - 0s 478us/step - loss: 0.6396 - acc: 0.6404 - val_loss: 0.8721 - val_acc: 0.1909\n",
      "Epoch 37/40\n",
      "876/876 [==============================] - 1s 726us/step - loss: 0.6390 - acc: 0.6427 - val_loss: 0.8991 - val_acc: 0.0636\n",
      "Epoch 38/40\n",
      "876/876 [==============================] - 1s 641us/step - loss: 0.6381 - acc: 0.6427 - val_loss: 0.9322 - val_acc: 0.0591\n",
      "Epoch 39/40\n",
      "876/876 [==============================] - 1s 786us/step - loss: 0.6377 - acc: 0.6427 - val_loss: 0.8717 - val_acc: 0.0682\n",
      "Epoch 40/40\n",
      "876/876 [==============================] - 1s 715us/step - loss: 0.6351 - acc: 0.6427 - val_loss: 0.9764 - val_acc: 0.0364\n",
      "122/122 [==============================] - 0s 39us/step\n",
      "Average accuracy of model on the dev set =  0.5061475413958313\n",
      "Training on fold 5/10.............................................\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_31 (Dense)             (None, 32)                288       \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,721\n",
      "Trainable params: 2,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 876 samples, validate on 220 samples\n",
      "Epoch 1/40\n",
      "876/876 [==============================] - 2s 2ms/step - loss: 0.6640 - acc: 0.6244 - val_loss: 0.9639 - val_acc: 0.0000e+00\n",
      "Epoch 2/40\n",
      "876/876 [==============================] - 1s 712us/step - loss: 0.6621 - acc: 0.6244 - val_loss: 0.9828 - val_acc: 0.0000e+00\n",
      "Epoch 3/40\n",
      "876/876 [==============================] - 1s 708us/step - loss: 0.6614 - acc: 0.6244 - val_loss: 0.9459 - val_acc: 0.0000e+00\n",
      "Epoch 4/40\n",
      "876/876 [==============================] - 1s 747us/step - loss: 0.6615 - acc: 0.6244 - val_loss: 0.9287 - val_acc: 0.0000e+00\n",
      "Epoch 5/40\n",
      "876/876 [==============================] - 1s 700us/step - loss: 0.6604 - acc: 0.6244 - val_loss: 0.9717 - val_acc: 0.0000e+00\n",
      "Epoch 6/40\n",
      "876/876 [==============================] - 1s 741us/step - loss: 0.6584 - acc: 0.6244 - val_loss: 0.9379 - val_acc: 0.0000e+00\n",
      "Epoch 7/40\n",
      "876/876 [==============================] - 1s 701us/step - loss: 0.6564 - acc: 0.6244 - val_loss: 0.9173 - val_acc: 0.0000e+00\n",
      "Epoch 8/40\n",
      "876/876 [==============================] - 1s 754us/step - loss: 0.6548 - acc: 0.6233 - val_loss: 0.9316 - val_acc: 0.0000e+00\n",
      "Epoch 9/40\n",
      "876/876 [==============================] - 1s 679us/step - loss: 0.6538 - acc: 0.6267 - val_loss: 0.8956 - val_acc: 0.0273\n",
      "Epoch 10/40\n",
      "876/876 [==============================] - 1s 743us/step - loss: 0.6519 - acc: 0.6267 - val_loss: 0.8846 - val_acc: 0.0455\n",
      "Epoch 11/40\n",
      "876/876 [==============================] - 1s 742us/step - loss: 0.6505 - acc: 0.6358 - val_loss: 0.8550 - val_acc: 0.0864\n",
      "Epoch 12/40\n",
      "876/876 [==============================] - 1s 661us/step - loss: 0.6505 - acc: 0.6301 - val_loss: 0.9125 - val_acc: 0.0273\n",
      "Epoch 13/40\n",
      "876/876 [==============================] - 1s 763us/step - loss: 0.6473 - acc: 0.6313 - val_loss: 0.8992 - val_acc: 0.0455\n",
      "Epoch 14/40\n",
      "876/876 [==============================] - 1s 844us/step - loss: 0.6470 - acc: 0.6347 - val_loss: 0.9168 - val_acc: 0.0273\n",
      "Epoch 15/40\n",
      "876/876 [==============================] - 1s 705us/step - loss: 0.6453 - acc: 0.6347 - val_loss: 0.9416 - val_acc: 0.0273\n",
      "Epoch 16/40\n",
      "876/876 [==============================] - 1s 753us/step - loss: 0.6454 - acc: 0.6313 - val_loss: 0.9198 - val_acc: 0.0455\n",
      "Epoch 17/40\n",
      "876/876 [==============================] - 1s 660us/step - loss: 0.6428 - acc: 0.6336 - val_loss: 0.9094 - val_acc: 0.0682\n",
      "Epoch 18/40\n",
      "876/876 [==============================] - 1s 731us/step - loss: 0.6413 - acc: 0.6438 - val_loss: 0.9389 - val_acc: 0.0318\n",
      "Epoch 19/40\n",
      "876/876 [==============================] - 1s 816us/step - loss: 0.6426 - acc: 0.6438 - val_loss: 0.9064 - val_acc: 0.0682\n",
      "Epoch 20/40\n",
      "876/876 [==============================] - 1s 804us/step - loss: 0.6398 - acc: 0.6416 - val_loss: 0.8733 - val_acc: 0.0864\n",
      "Epoch 21/40\n",
      "876/876 [==============================] - 1s 777us/step - loss: 0.6396 - acc: 0.6450 - val_loss: 0.9448 - val_acc: 0.0545\n",
      "Epoch 22/40\n",
      "876/876 [==============================] - 1s 765us/step - loss: 0.6376 - acc: 0.6438 - val_loss: 0.9470 - val_acc: 0.0545\n",
      "Epoch 23/40\n",
      "876/876 [==============================] - 1s 737us/step - loss: 0.6379 - acc: 0.6450 - val_loss: 0.9147 - val_acc: 0.0682\n",
      "Epoch 24/40\n",
      "876/876 [==============================] - 1s 856us/step - loss: 0.6366 - acc: 0.6450 - val_loss: 0.8632 - val_acc: 0.0909\n",
      "Epoch 25/40\n",
      "876/876 [==============================] - 1s 881us/step - loss: 0.6362 - acc: 0.6438 - val_loss: 0.9137 - val_acc: 0.0864\n",
      "Epoch 26/40\n",
      "876/876 [==============================] - 1s 761us/step - loss: 0.6345 - acc: 0.6473 - val_loss: 0.9496 - val_acc: 0.0591\n",
      "Epoch 27/40\n",
      "876/876 [==============================] - 1s 772us/step - loss: 0.6337 - acc: 0.6461 - val_loss: 0.9501 - val_acc: 0.0500\n",
      "Epoch 28/40\n",
      "876/876 [==============================] - 1s 828us/step - loss: 0.6341 - acc: 0.6484 - val_loss: 0.9006 - val_acc: 0.0864\n",
      "Epoch 29/40\n",
      "876/876 [==============================] - 1s 602us/step - loss: 0.6322 - acc: 0.6416 - val_loss: 0.8457 - val_acc: 0.0909\n",
      "Epoch 30/40\n",
      "876/876 [==============================] - 1s 597us/step - loss: 0.6321 - acc: 0.6461 - val_loss: 0.9439 - val_acc: 0.0682\n",
      "Epoch 31/40\n",
      "876/876 [==============================] - 1s 601us/step - loss: 0.6321 - acc: 0.6404 - val_loss: 0.9410 - val_acc: 0.0682\n",
      "Epoch 32/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "876/876 [==============================] - 1s 587us/step - loss: 0.6322 - acc: 0.6473 - val_loss: 0.8901 - val_acc: 0.0864\n",
      "Epoch 33/40\n",
      "876/876 [==============================] - 1s 596us/step - loss: 0.6316 - acc: 0.6484 - val_loss: 0.8916 - val_acc: 0.0864\n",
      "Epoch 34/40\n",
      "876/876 [==============================] - 0s 568us/step - loss: 0.6311 - acc: 0.6427 - val_loss: 0.9159 - val_acc: 0.0864\n",
      "Epoch 35/40\n",
      "876/876 [==============================] - 1s 583us/step - loss: 0.6296 - acc: 0.6484 - val_loss: 0.9177 - val_acc: 0.0818\n",
      "Epoch 36/40\n",
      "876/876 [==============================] - 1s 585us/step - loss: 0.6295 - acc: 0.6461 - val_loss: 0.9116 - val_acc: 0.0864\n",
      "Epoch 37/40\n",
      "876/876 [==============================] - 1s 586us/step - loss: 0.6287 - acc: 0.6507 - val_loss: 0.9119 - val_acc: 0.0864\n",
      "Epoch 38/40\n",
      "876/876 [==============================] - 1s 574us/step - loss: 0.6293 - acc: 0.6473 - val_loss: 0.9138 - val_acc: 0.0864\n",
      "Epoch 39/40\n",
      "876/876 [==============================] - 1s 653us/step - loss: 0.6286 - acc: 0.6484 - val_loss: 0.9252 - val_acc: 0.0864\n",
      "Epoch 40/40\n",
      "876/876 [==============================] - 1s 789us/step - loss: 0.6279 - acc: 0.6484 - val_loss: 0.9208 - val_acc: 0.0864\n",
      "122/122 [==============================] - 0s 41us/step\n",
      "Average accuracy of model on the dev set =  0.5000000003908501\n",
      "Training on fold 6/10.............................................\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_37 (Dense)             (None, 32)                288       \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,721\n",
      "Trainable params: 2,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 876 samples, validate on 220 samples\n",
      "Epoch 1/40\n",
      "876/876 [==============================] - 2s 2ms/step - loss: 0.6709 - acc: 0.6130 - val_loss: 0.9360 - val_acc: 0.0000e+00\n",
      "Epoch 2/40\n",
      "876/876 [==============================] - 1s 693us/step - loss: 0.6625 - acc: 0.6244 - val_loss: 0.9514 - val_acc: 0.0000e+00\n",
      "Epoch 3/40\n",
      "876/876 [==============================] - 1s 684us/step - loss: 0.6618 - acc: 0.6244 - val_loss: 0.9999 - val_acc: 0.0000e+00\n",
      "Epoch 4/40\n",
      "876/876 [==============================] - 1s 695us/step - loss: 0.6610 - acc: 0.6244 - val_loss: 0.9413 - val_acc: 0.0000e+00\n",
      "Epoch 5/40\n",
      "876/876 [==============================] - 1s 649us/step - loss: 0.6604 - acc: 0.6244 - val_loss: 0.9558 - val_acc: 0.0000e+00\n",
      "Epoch 6/40\n",
      "876/876 [==============================] - 1s 662us/step - loss: 0.6593 - acc: 0.6244 - val_loss: 0.9892 - val_acc: 0.0000e+00\n",
      "Epoch 7/40\n",
      "876/876 [==============================] - 1s 680us/step - loss: 0.6581 - acc: 0.6244 - val_loss: 0.9357 - val_acc: 0.0000e+00\n",
      "Epoch 8/40\n",
      "876/876 [==============================] - 1s 668us/step - loss: 0.6570 - acc: 0.6244 - val_loss: 0.9399 - val_acc: 0.0000e+00\n",
      "Epoch 9/40\n",
      "876/876 [==============================] - 1s 782us/step - loss: 0.6559 - acc: 0.6290 - val_loss: 0.9715 - val_acc: 0.0000e+00\n",
      "Epoch 10/40\n",
      "876/876 [==============================] - 1s 648us/step - loss: 0.6547 - acc: 0.6233 - val_loss: 0.9111 - val_acc: 0.0000e+00\n",
      "Epoch 11/40\n",
      "876/876 [==============================] - 1s 789us/step - loss: 0.6528 - acc: 0.6279 - val_loss: 0.9060 - val_acc: 0.0000e+00\n",
      "Epoch 12/40\n",
      "876/876 [==============================] - 1s 764us/step - loss: 0.6524 - acc: 0.6244 - val_loss: 0.9613 - val_acc: 0.0000e+00\n",
      "Epoch 13/40\n",
      "876/876 [==============================] - 1s 804us/step - loss: 0.6512 - acc: 0.6244 - val_loss: 0.9685 - val_acc: 0.0000e+00\n",
      "Epoch 14/40\n",
      "876/876 [==============================] - 1s 956us/step - loss: 0.6499 - acc: 0.6279 - val_loss: 0.8776 - val_acc: 0.0500\n",
      "Epoch 15/40\n",
      "876/876 [==============================] - 1s 799us/step - loss: 0.6493 - acc: 0.6301 - val_loss: 0.8672 - val_acc: 0.0682\n",
      "Epoch 16/40\n",
      "876/876 [==============================] - 1s 788us/step - loss: 0.6481 - acc: 0.6358 - val_loss: 0.9487 - val_acc: 0.0045\n",
      "Epoch 17/40\n",
      "876/876 [==============================] - 1s 942us/step - loss: 0.6484 - acc: 0.6313 - val_loss: 0.9325 - val_acc: 0.0455\n",
      "Epoch 18/40\n",
      "876/876 [==============================] - 1s 841us/step - loss: 0.6467 - acc: 0.6381 - val_loss: 0.9266 - val_acc: 0.0409\n",
      "Epoch 19/40\n",
      "876/876 [==============================] - 1s 806us/step - loss: 0.6460 - acc: 0.6358 - val_loss: 0.9112 - val_acc: 0.0682\n",
      "Epoch 20/40\n",
      "876/876 [==============================] - 1s 830us/step - loss: 0.6442 - acc: 0.6416 - val_loss: 0.9851 - val_acc: 0.0364\n",
      "Epoch 21/40\n",
      "876/876 [==============================] - 1s 762us/step - loss: 0.6451 - acc: 0.6416 - val_loss: 0.9263 - val_acc: 0.0500\n",
      "Epoch 22/40\n",
      "876/876 [==============================] - 1s 687us/step - loss: 0.6445 - acc: 0.6336 - val_loss: 0.8838 - val_acc: 0.0682\n",
      "Epoch 23/40\n",
      "876/876 [==============================] - 1s 703us/step - loss: 0.6430 - acc: 0.6381 - val_loss: 0.8638 - val_acc: 0.2500\n",
      "Epoch 24/40\n",
      "876/876 [==============================] - 1s 604us/step - loss: 0.6421 - acc: 0.6450 - val_loss: 0.8822 - val_acc: 0.2500\n",
      "Epoch 25/40\n",
      "876/876 [==============================] - 0s 562us/step - loss: 0.6416 - acc: 0.6484 - val_loss: 0.8429 - val_acc: 0.2500\n",
      "Epoch 26/40\n",
      "876/876 [==============================] - 1s 771us/step - loss: 0.6423 - acc: 0.6438 - val_loss: 0.9472 - val_acc: 0.0409\n",
      "Epoch 27/40\n",
      "876/876 [==============================] - 1s 804us/step - loss: 0.6421 - acc: 0.6404 - val_loss: 0.9252 - val_acc: 0.0682\n",
      "Epoch 28/40\n",
      "876/876 [==============================] - 1s 804us/step - loss: 0.6400 - acc: 0.6358 - val_loss: 0.9418 - val_acc: 0.0682\n",
      "Epoch 29/40\n",
      "876/876 [==============================] - 1s 783us/step - loss: 0.6409 - acc: 0.6427 - val_loss: 0.8682 - val_acc: 0.1955\n",
      "Epoch 30/40\n",
      "876/876 [==============================] - 1s 676us/step - loss: 0.6399 - acc: 0.6438 - val_loss: 0.9420 - val_acc: 0.0682\n",
      "Epoch 31/40\n",
      "876/876 [==============================] - 1s 667us/step - loss: 0.6403 - acc: 0.6461 - val_loss: 0.9344 - val_acc: 0.0682\n",
      "Epoch 32/40\n",
      "876/876 [==============================] - 1s 639us/step - loss: 0.6386 - acc: 0.6427 - val_loss: 0.8757 - val_acc: 0.0773\n",
      "Epoch 33/40\n",
      "876/876 [==============================] - 1s 653us/step - loss: 0.6391 - acc: 0.6416 - val_loss: 0.9091 - val_acc: 0.0500\n",
      "Epoch 34/40\n",
      "876/876 [==============================] - 1s 680us/step - loss: 0.6390 - acc: 0.6438 - val_loss: 0.9634 - val_acc: 0.0455\n",
      "Epoch 35/40\n",
      "876/876 [==============================] - 1s 642us/step - loss: 0.6389 - acc: 0.6381 - val_loss: 0.9226 - val_acc: 0.0682\n",
      "Epoch 36/40\n",
      "876/876 [==============================] - 1s 601us/step - loss: 0.6378 - acc: 0.6404 - val_loss: 0.9372 - val_acc: 0.0682\n",
      "Epoch 37/40\n",
      "876/876 [==============================] - 1s 704us/step - loss: 0.6385 - acc: 0.6427 - val_loss: 0.9339 - val_acc: 0.0682\n",
      "Epoch 38/40\n",
      "876/876 [==============================] - 1s 660us/step - loss: 0.6369 - acc: 0.6495 - val_loss: 0.9838 - val_acc: 0.0409\n",
      "Epoch 39/40\n",
      "876/876 [==============================] - 1s 729us/step - loss: 0.6372 - acc: 0.6427 - val_loss: 0.9395 - val_acc: 0.0636\n",
      "Epoch 40/40\n",
      "876/876 [==============================] - 1s 674us/step - loss: 0.6362 - acc: 0.6473 - val_loss: 0.9643 - val_acc: 0.0500\n",
      "122/122 [==============================] - 0s 37us/step\n",
      "Average accuracy of model on the dev set =  0.5068306014186046\n",
      "Training on fold 7/10.............................................\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_43 (Dense)             (None, 32)                288       \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,721\n",
      "Trainable params: 2,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 876 samples, validate on 220 samples\n",
      "Epoch 1/40\n",
      "876/876 [==============================] - 2s 2ms/step - loss: 0.6676 - acc: 0.6244 - val_loss: 0.9640 - val_acc: 0.0000e+00\n",
      "Epoch 2/40\n",
      "876/876 [==============================] - 1s 669us/step - loss: 0.6630 - acc: 0.6244 - val_loss: 0.9652 - val_acc: 0.0000e+00\n",
      "Epoch 3/40\n",
      "876/876 [==============================] - 1s 651us/step - loss: 0.6627 - acc: 0.6244 - val_loss: 0.9613 - val_acc: 0.0000e+00\n",
      "Epoch 4/40\n",
      "876/876 [==============================] - 1s 655us/step - loss: 0.6629 - acc: 0.6244 - val_loss: 0.9916 - val_acc: 0.0000e+00\n",
      "Epoch 5/40\n",
      "876/876 [==============================] - 1s 629us/step - loss: 0.6623 - acc: 0.6244 - val_loss: 0.9932 - val_acc: 0.0000e+00\n",
      "Epoch 6/40\n",
      "876/876 [==============================] - 1s 770us/step - loss: 0.6623 - acc: 0.6244 - val_loss: 1.0193 - val_acc: 0.0000e+00\n",
      "Epoch 7/40\n",
      "876/876 [==============================] - 1s 693us/step - loss: 0.6617 - acc: 0.6244 - val_loss: 0.9624 - val_acc: 0.0000e+00\n",
      "Epoch 8/40\n",
      "876/876 [==============================] - 1s 638us/step - loss: 0.6608 - acc: 0.6244 - val_loss: 0.9252 - val_acc: 0.0000e+00\n",
      "Epoch 9/40\n",
      "876/876 [==============================] - 1s 643us/step - loss: 0.6617 - acc: 0.6244 - val_loss: 1.0091 - val_acc: 0.0000e+00\n",
      "Epoch 10/40\n",
      "876/876 [==============================] - 1s 708us/step - loss: 0.6602 - acc: 0.6244 - val_loss: 0.9464 - val_acc: 0.0000e+00\n",
      "Epoch 11/40\n",
      "876/876 [==============================] - 1s 649us/step - loss: 0.6612 - acc: 0.6244 - val_loss: 1.0044 - val_acc: 0.0000e+00\n",
      "Epoch 12/40\n",
      "876/876 [==============================] - 1s 750us/step - loss: 0.6597 - acc: 0.6244 - val_loss: 1.0007 - val_acc: 0.0000e+00\n",
      "Epoch 13/40\n",
      "876/876 [==============================] - 1s 672us/step - loss: 0.6592 - acc: 0.6244 - val_loss: 1.0182 - val_acc: 0.0000e+00\n",
      "Epoch 14/40\n",
      "876/876 [==============================] - 1s 656us/step - loss: 0.6586 - acc: 0.6244 - val_loss: 1.0388 - val_acc: 0.0000e+00\n",
      "Epoch 15/40\n",
      "876/876 [==============================] - 1s 692us/step - loss: 0.6566 - acc: 0.6244 - val_loss: 0.9584 - val_acc: 0.0000e+00\n",
      "Epoch 16/40\n",
      "876/876 [==============================] - 1s 776us/step - loss: 0.6563 - acc: 0.6279 - val_loss: 1.0464 - val_acc: 0.0000e+00\n",
      "Epoch 17/40\n",
      "876/876 [==============================] - 1s 681us/step - loss: 0.6556 - acc: 0.6267 - val_loss: 1.0207 - val_acc: 0.0000e+00\n",
      "Epoch 18/40\n",
      "876/876 [==============================] - 1s 665us/step - loss: 0.6536 - acc: 0.6244 - val_loss: 1.0160 - val_acc: 0.0000e+00\n",
      "Epoch 19/40\n",
      "876/876 [==============================] - 1s 649us/step - loss: 0.6525 - acc: 0.6313 - val_loss: 1.0733 - val_acc: 0.0000e+00\n",
      "Epoch 20/40\n",
      "876/876 [==============================] - 1s 698us/step - loss: 0.6508 - acc: 0.6370 - val_loss: 1.1178 - val_acc: 0.0000e+00\n",
      "Epoch 21/40\n",
      "876/876 [==============================] - 1s 653us/step - loss: 0.6502 - acc: 0.6336 - val_loss: 1.0594 - val_acc: 0.0045\n",
      "Epoch 22/40\n",
      "876/876 [==============================] - 1s 617us/step - loss: 0.6480 - acc: 0.6416 - val_loss: 1.0929 - val_acc: 0.0045\n",
      "Epoch 23/40\n",
      "876/876 [==============================] - 1s 704us/step - loss: 0.6467 - acc: 0.6370 - val_loss: 0.9783 - val_acc: 0.0409\n",
      "Epoch 24/40\n",
      "876/876 [==============================] - 1s 848us/step - loss: 0.6466 - acc: 0.6404 - val_loss: 1.1051 - val_acc: 0.0000e+00 - loss: 0.6524 - acc: 0.\n",
      "Epoch 25/40\n",
      "876/876 [==============================] - 1s 602us/step - loss: 0.6453 - acc: 0.6450 - val_loss: 1.0780 - val_acc: 0.0318\n",
      "Epoch 26/40\n",
      "876/876 [==============================] - 1s 647us/step - loss: 0.6440 - acc: 0.6518 - val_loss: 1.0355 - val_acc: 0.0364\n",
      "Epoch 27/40\n",
      "876/876 [==============================] - 1s 635us/step - loss: 0.6431 - acc: 0.6518 - val_loss: 1.0174 - val_acc: 0.0364\n",
      "Epoch 28/40\n",
      "876/876 [==============================] - 1s 610us/step - loss: 0.6430 - acc: 0.6507 - val_loss: 1.0682 - val_acc: 0.0364\n",
      "Epoch 29/40\n",
      "876/876 [==============================] - 1s 810us/step - loss: 0.6428 - acc: 0.6518 - val_loss: 1.0353 - val_acc: 0.0364\n",
      "Epoch 30/40\n",
      "876/876 [==============================] - 1s 714us/step - loss: 0.6406 - acc: 0.6495 - val_loss: 1.0051 - val_acc: 0.0545\n",
      "Epoch 31/40\n",
      "876/876 [==============================] - 1s 772us/step - loss: 0.6404 - acc: 0.6507 - val_loss: 1.0459 - val_acc: 0.0364\n",
      "Epoch 32/40\n",
      "876/876 [==============================] - 1s 864us/step - loss: 0.6398 - acc: 0.6461 - val_loss: 1.0669 - val_acc: 0.0364\n",
      "Epoch 33/40\n",
      "876/876 [==============================] - 1s 786us/step - loss: 0.6396 - acc: 0.6530 - val_loss: 1.0516 - val_acc: 0.0364\n",
      "Epoch 34/40\n",
      "876/876 [==============================] - 1s 780us/step - loss: 0.6389 - acc: 0.6507 - val_loss: 1.0710 - val_acc: 0.0364\n",
      "Epoch 35/40\n",
      "876/876 [==============================] - 1s 816us/step - loss: 0.6380 - acc: 0.6530 - val_loss: 1.0599 - val_acc: 0.0364\n",
      "Epoch 36/40\n",
      "876/876 [==============================] - 1s 914us/step - loss: 0.6366 - acc: 0.6495 - val_loss: 0.9658 - val_acc: 0.0591\n",
      "Epoch 37/40\n",
      "876/876 [==============================] - 1s 807us/step - loss: 0.6367 - acc: 0.6530 - val_loss: 1.0204 - val_acc: 0.0364\n",
      "Epoch 38/40\n",
      "876/876 [==============================] - 1s 746us/step - loss: 0.6363 - acc: 0.6530 - val_loss: 1.0521 - val_acc: 0.0364\n",
      "Epoch 39/40\n",
      "876/876 [==============================] - 1s 606us/step - loss: 0.6350 - acc: 0.6530 - val_loss: 1.0781 - val_acc: 0.0364\n",
      "Epoch 40/40\n",
      "876/876 [==============================] - 1s 591us/step - loss: 0.6374 - acc: 0.6518 - val_loss: 1.0616 - val_acc: 0.0364\n",
      "122/122 [==============================] - 0s 43us/step\n",
      "Average accuracy of model on the dev set =  0.501170960510154\n",
      "Training on fold 8/10.............................................\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_49 (Dense)             (None, 32)                288       \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,721\n",
      "Trainable params: 2,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 876 samples, validate on 220 samples\n",
      "Epoch 1/40\n",
      "876/876 [==============================] - 2s 2ms/step - loss: 0.6631 - acc: 0.6244 - val_loss: 0.9908 - val_acc: 0.0000e+00\n",
      "Epoch 2/40\n",
      "876/876 [==============================] - 1s 793us/step - loss: 0.6625 - acc: 0.6244 - val_loss: 0.9618 - val_acc: 0.0000e+00\n",
      "Epoch 3/40\n",
      "876/876 [==============================] - 1s 777us/step - loss: 0.6621 - acc: 0.6244 - val_loss: 0.9629 - val_acc: 0.0000e+00 - loss: 0.6502 - acc: \n",
      "Epoch 4/40\n",
      "876/876 [==============================] - 1s 608us/step - loss: 0.6625 - acc: 0.6244 - val_loss: 0.9853 - val_acc: 0.0000e+00\n",
      "Epoch 5/40\n",
      "876/876 [==============================] - 1s 613us/step - loss: 0.6614 - acc: 0.6244 - val_loss: 0.9782 - val_acc: 0.0000e+00\n",
      "Epoch 6/40\n",
      "876/876 [==============================] - 1s 720us/step - loss: 0.6616 - acc: 0.6244 - val_loss: 1.0012 - val_acc: 0.0000e+00\n",
      "Epoch 7/40\n",
      "876/876 [==============================] - 1s 664us/step - loss: 0.6601 - acc: 0.6244 - val_loss: 0.9677 - val_acc: 0.0000e+00\n",
      "Epoch 8/40\n",
      "876/876 [==============================] - 1s 616us/step - loss: 0.6599 - acc: 0.6244 - val_loss: 0.9468 - val_acc: 0.0000e+00\n",
      "Epoch 9/40\n",
      "876/876 [==============================] - 1s 704us/step - loss: 0.6590 - acc: 0.6244 - val_loss: 0.9934 - val_acc: 0.0000e+00\n",
      "Epoch 10/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "876/876 [==============================] - 1s 649us/step - loss: 0.6578 - acc: 0.6244 - val_loss: 1.0130 - val_acc: 0.0000e+00\n",
      "Epoch 11/40\n",
      "876/876 [==============================] - 1s 685us/step - loss: 0.6571 - acc: 0.6244 - val_loss: 0.9812 - val_acc: 0.0000e+00\n",
      "Epoch 12/40\n",
      "876/876 [==============================] - 1s 600us/step - loss: 0.6555 - acc: 0.6244 - val_loss: 0.9321 - val_acc: 0.0000e+00\n",
      "Epoch 13/40\n",
      "876/876 [==============================] - 1s 624us/step - loss: 0.6552 - acc: 0.6279 - val_loss: 1.0161 - val_acc: 0.0000e+00\n",
      "Epoch 14/40\n",
      "876/876 [==============================] - 1s 713us/step - loss: 0.6537 - acc: 0.6267 - val_loss: 0.9985 - val_acc: 0.0000e+00\n",
      "Epoch 15/40\n",
      "876/876 [==============================] - 1s 734us/step - loss: 0.6524 - acc: 0.6256 - val_loss: 0.9773 - val_acc: 0.0000e+00\n",
      "Epoch 16/40\n",
      "876/876 [==============================] - 1s 661us/step - loss: 0.6506 - acc: 0.6290 - val_loss: 0.9763 - val_acc: 0.0000e+00\n",
      "Epoch 17/40\n",
      "876/876 [==============================] - 1s 864us/step - loss: 0.6505 - acc: 0.6370 - val_loss: 1.0228 - val_acc: 0.0000e+00\n",
      "Epoch 18/40\n",
      "876/876 [==============================] - 1s 832us/step - loss: 0.6496 - acc: 0.6347 - val_loss: 1.0463 - val_acc: 0.0000e+00\n",
      "Epoch 19/40\n",
      "876/876 [==============================] - 1s 609us/step - loss: 0.6503 - acc: 0.6347 - val_loss: 1.0491 - val_acc: 0.0000e+00\n",
      "Epoch 20/40\n",
      "876/876 [==============================] - 1s 802us/step - loss: 0.6472 - acc: 0.6347 - val_loss: 0.9790 - val_acc: 0.0000e+00\n",
      "Epoch 21/40\n",
      "876/876 [==============================] - 1s 810us/step - loss: 0.6469 - acc: 0.6427 - val_loss: 1.0442 - val_acc: 0.0000e+00\n",
      "Epoch 22/40\n",
      "876/876 [==============================] - 1s 756us/step - loss: 0.6465 - acc: 0.6358 - val_loss: 1.0293 - val_acc: 0.0000e+00\n",
      "Epoch 23/40\n",
      "876/876 [==============================] - 1s 762us/step - loss: 0.6453 - acc: 0.6393 - val_loss: 1.0418 - val_acc: 0.0000e+00\n",
      "Epoch 24/40\n",
      "876/876 [==============================] - 1s 693us/step - loss: 0.6456 - acc: 0.6370 - val_loss: 1.0475 - val_acc: 0.0000e+00\n",
      "Epoch 25/40\n",
      "876/876 [==============================] - 1s 669us/step - loss: 0.6435 - acc: 0.6416 - val_loss: 0.9812 - val_acc: 0.0045\n",
      "Epoch 26/40\n",
      "876/876 [==============================] - 1s 848us/step - loss: 0.6436 - acc: 0.6416 - val_loss: 1.0484 - val_acc: 0.0000e+00\n",
      "Epoch 27/40\n",
      "876/876 [==============================] - 1s 811us/step - loss: 0.6439 - acc: 0.6393 - val_loss: 0.9741 - val_acc: 0.0045\n",
      "Epoch 28/40\n",
      "876/876 [==============================] - 1s 661us/step - loss: 0.6431 - acc: 0.6393 - val_loss: 1.0595 - val_acc: 0.0000e+00\n",
      "Epoch 29/40\n",
      "876/876 [==============================] - 1s 856us/step - loss: 0.6426 - acc: 0.6393 - val_loss: 1.0306 - val_acc: 0.0045\n",
      "Epoch 30/40\n",
      "876/876 [==============================] - 1s 727us/step - loss: 0.6416 - acc: 0.6404 - val_loss: 1.0488 - val_acc: 0.0000e+00\n",
      "Epoch 31/40\n",
      "876/876 [==============================] - 1s 921us/step - loss: 0.6417 - acc: 0.6416 - val_loss: 1.0435 - val_acc: 0.0000e+00\n",
      "Epoch 32/40\n",
      "876/876 [==============================] - 1s 729us/step - loss: 0.6414 - acc: 0.6370 - val_loss: 0.9981 - val_acc: 0.0045\n",
      "Epoch 33/40\n",
      "876/876 [==============================] - 1s 809us/step - loss: 0.6411 - acc: 0.6370 - val_loss: 1.1071 - val_acc: 0.0000e+00\n",
      "Epoch 34/40\n",
      "876/876 [==============================] - 1s 832us/step - loss: 0.6406 - acc: 0.6416 - val_loss: 1.0071 - val_acc: 0.0045\n",
      "Epoch 35/40\n",
      "876/876 [==============================] - 1s 855us/step - loss: 0.6401 - acc: 0.6427 - val_loss: 0.9976 - val_acc: 0.0455\n",
      "Epoch 36/40\n",
      "876/876 [==============================] - 1s 848us/step - loss: 0.6412 - acc: 0.6370 - val_loss: 1.0260 - val_acc: 0.0045\n",
      "Epoch 37/40\n",
      "876/876 [==============================] - 1s 810us/step - loss: 0.6383 - acc: 0.6404 - val_loss: 1.0088 - val_acc: 0.0500\n",
      "Epoch 38/40\n",
      "876/876 [==============================] - 1s 810us/step - loss: 0.6402 - acc: 0.6416 - val_loss: 1.0463 - val_acc: 0.0045\n",
      "Epoch 39/40\n",
      "876/876 [==============================] - 1s 929us/step - loss: 0.6388 - acc: 0.6347 - val_loss: 1.0423 - val_acc: 0.0045\n",
      "Epoch 40/40\n",
      "876/876 [==============================] - 1s 774us/step - loss: 0.6381 - acc: 0.6393 - val_loss: 1.0039 - val_acc: 0.0455\n",
      "122/122 [==============================] - 0s 42us/step\n",
      "Average accuracy of model on the dev set =  0.49795081995458146\n",
      "Training on fold 9/10.............................................\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_55 (Dense)             (None, 32)                288       \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,721\n",
      "Trainable params: 2,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 877 samples, validate on 220 samples\n",
      "Epoch 1/40\n",
      "877/877 [==============================] - 2s 2ms/step - loss: 0.6643 - acc: 0.6249 - val_loss: 0.9877 - val_acc: 0.0000e+00\n",
      "Epoch 2/40\n",
      "877/877 [==============================] - 1s 911us/step - loss: 0.6625 - acc: 0.6249 - val_loss: 0.9796 - val_acc: 0.0000e+00\n",
      "Epoch 3/40\n",
      "877/877 [==============================] - 1s 853us/step - loss: 0.6627 - acc: 0.6249 - val_loss: 0.9627 - val_acc: 0.0000e+00\n",
      "Epoch 4/40\n",
      "877/877 [==============================] - 1s 840us/step - loss: 0.6622 - acc: 0.6249 - val_loss: 0.9829 - val_acc: 0.0000e+00\n",
      "Epoch 5/40\n",
      "877/877 [==============================] - 1s 776us/step - loss: 0.6615 - acc: 0.6249 - val_loss: 0.9816 - val_acc: 0.0000e+00\n",
      "Epoch 6/40\n",
      "877/877 [==============================] - 1s 819us/step - loss: 0.6611 - acc: 0.6249 - val_loss: 0.9522 - val_acc: 0.0000e+00\n",
      "Epoch 7/40\n",
      "877/877 [==============================] - 1s 866us/step - loss: 0.6615 - acc: 0.6249 - val_loss: 0.9898 - val_acc: 0.0000e+00\n",
      "Epoch 8/40\n",
      "877/877 [==============================] - 1s 875us/step - loss: 0.6606 - acc: 0.6249 - val_loss: 0.9825 - val_acc: 0.0000e+00\n",
      "Epoch 9/40\n",
      "877/877 [==============================] - 1s 915us/step - loss: 0.6592 - acc: 0.6249 - val_loss: 0.9642 - val_acc: 0.0000e+00\n",
      "Epoch 10/40\n",
      "877/877 [==============================] - 1s 907us/step - loss: 0.6587 - acc: 0.6249 - val_loss: 0.9765 - val_acc: 0.0000e+00\n",
      "Epoch 11/40\n",
      "877/877 [==============================] - 1s 923us/step - loss: 0.6571 - acc: 0.6260 - val_loss: 0.9555 - val_acc: 0.0000e+00\n",
      "Epoch 12/40\n",
      "877/877 [==============================] - 1s 951us/step - loss: 0.6548 - acc: 0.6294 - val_loss: 1.0208 - val_acc: 0.0000e+00\n",
      "Epoch 13/40\n",
      "877/877 [==============================] - 1s 917us/step - loss: 0.6535 - acc: 0.6271 - val_loss: 1.0330 - val_acc: 0.0000e+00\n",
      "Epoch 14/40\n",
      "877/877 [==============================] - 1s 942us/step - loss: 0.6520 - acc: 0.6283 - val_loss: 0.9482 - val_acc: 0.0045\n",
      "Epoch 15/40\n",
      "877/877 [==============================] - 1s 1ms/step - loss: 0.6486 - acc: 0.6328 - val_loss: 1.0364 - val_acc: 0.0000e+00\n",
      "Epoch 16/40\n",
      "877/877 [==============================] - 1s 1ms/step - loss: 0.6476 - acc: 0.6351 - val_loss: 1.0070 - val_acc: 0.0182\n",
      "Epoch 17/40\n",
      "877/877 [==============================] - 1s 916us/step - loss: 0.6464 - acc: 0.6340 - val_loss: 0.9625 - val_acc: 0.0500\n",
      "Epoch 18/40\n",
      "877/877 [==============================] - 1s 972us/step - loss: 0.6448 - acc: 0.6431 - val_loss: 0.9738 - val_acc: 0.0318\n",
      "Epoch 19/40\n",
      "877/877 [==============================] - 1s 1ms/step - loss: 0.6448 - acc: 0.6454 - val_loss: 1.0114 - val_acc: 0.0318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/40\n",
      "877/877 [==============================] - 1s 968us/step - loss: 0.6432 - acc: 0.6442 - val_loss: 1.0130 - val_acc: 0.0318\n",
      "Epoch 21/40\n",
      "877/877 [==============================] - 1s 1ms/step - loss: 0.6426 - acc: 0.6420 - val_loss: 0.9815 - val_acc: 0.0318\n",
      "Epoch 22/40\n",
      "877/877 [==============================] - 1s 953us/step - loss: 0.6409 - acc: 0.6454 - val_loss: 0.9840 - val_acc: 0.0318\n",
      "Epoch 23/40\n",
      "877/877 [==============================] - 1s 935us/step - loss: 0.6413 - acc: 0.6454 - val_loss: 1.0400 - val_acc: 0.0318\n",
      "Epoch 24/40\n",
      "877/877 [==============================] - 1s 895us/step - loss: 0.6400 - acc: 0.6477 - val_loss: 1.0322 - val_acc: 0.0318\n",
      "Epoch 25/40\n",
      "877/877 [==============================] - 1s 987us/step - loss: 0.6381 - acc: 0.6420 - val_loss: 1.0818 - val_acc: 0.0273\n",
      "Epoch 26/40\n",
      "877/877 [==============================] - 1s 1ms/step - loss: 0.6398 - acc: 0.6454 - val_loss: 1.0292 - val_acc: 0.0318\n",
      "Epoch 27/40\n",
      "877/877 [==============================] - 1s 891us/step - loss: 0.6385 - acc: 0.6522 - val_loss: 0.9865 - val_acc: 0.0500\n",
      "Epoch 28/40\n",
      "877/877 [==============================] - 1s 917us/step - loss: 0.6378 - acc: 0.6488 - val_loss: 1.0194 - val_acc: 0.0318\n",
      "Epoch 29/40\n",
      "877/877 [==============================] - 1s 925us/step - loss: 0.6382 - acc: 0.6477 - val_loss: 0.9822 - val_acc: 0.0318\n",
      "Epoch 30/40\n",
      "877/877 [==============================] - 1s 904us/step - loss: 0.6369 - acc: 0.6477 - val_loss: 0.9915 - val_acc: 0.0318\n",
      "Epoch 31/40\n",
      "877/877 [==============================] - 1s 888us/step - loss: 0.6363 - acc: 0.6465 - val_loss: 1.0435 - val_acc: 0.0273\n",
      "Epoch 32/40\n",
      "877/877 [==============================] - 1s 929us/step - loss: 0.6358 - acc: 0.6431 - val_loss: 0.9938 - val_acc: 0.0500\n",
      "Epoch 33/40\n",
      "877/877 [==============================] - 1s 898us/step - loss: 0.6342 - acc: 0.6499 - val_loss: 0.9989 - val_acc: 0.0318\n",
      "Epoch 34/40\n",
      "877/877 [==============================] - 1s 898us/step - loss: 0.6354 - acc: 0.6477 - val_loss: 0.9653 - val_acc: 0.0500\n",
      "Epoch 35/40\n",
      "877/877 [==============================] - 1s 910us/step - loss: 0.6337 - acc: 0.6499 - val_loss: 0.9802 - val_acc: 0.0500\n",
      "Epoch 36/40\n",
      "877/877 [==============================] - 1s 924us/step - loss: 0.6353 - acc: 0.6431 - val_loss: 0.9741 - val_acc: 0.0500\n",
      "Epoch 37/40\n",
      "877/877 [==============================] - 1s 949us/step - loss: 0.6337 - acc: 0.6499 - val_loss: 1.0399 - val_acc: 0.0273\n",
      "Epoch 38/40\n",
      "877/877 [==============================] - 1s 909us/step - loss: 0.6330 - acc: 0.6488 - val_loss: 1.0499 - val_acc: 0.0318\n",
      "Epoch 39/40\n",
      "877/877 [==============================] - 1s 950us/step - loss: 0.6330 - acc: 0.6477 - val_loss: 1.0046 - val_acc: 0.0318\n",
      "Epoch 40/40\n",
      "877/877 [==============================] - 1s 925us/step - loss: 0.6336 - acc: 0.6511 - val_loss: 1.0596 - val_acc: 0.0318\n",
      "121/121 [==============================] - 0s 90us/step\n",
      "Average accuracy of model on the dev set =  0.4986376434285428\n",
      "Training on fold 10/10.............................................\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_61 (Dense)             (None, 32)                288       \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,721\n",
      "Trainable params: 2,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 877 samples, validate on 220 samples\n",
      "Epoch 1/40\n",
      "877/877 [==============================] - 2s 3ms/step - loss: 0.6737 - acc: 0.5849 - val_loss: 0.9623 - val_acc: 0.0000e+00\n",
      "Epoch 2/40\n",
      "877/877 [==============================] - 1s 952us/step - loss: 0.6623 - acc: 0.6249 - val_loss: 1.0025 - val_acc: 0.0000e+00\n",
      "Epoch 3/40\n",
      "877/877 [==============================] - 1s 1ms/step - loss: 0.6612 - acc: 0.6249 - val_loss: 0.9963 - val_acc: 0.0000e+00\n",
      "Epoch 4/40\n",
      "877/877 [==============================] - 1s 952us/step - loss: 0.6602 - acc: 0.6249 - val_loss: 1.0377 - val_acc: 0.0000e+00\n",
      "Epoch 5/40\n",
      "877/877 [==============================] - 1s 958us/step - loss: 0.6603 - acc: 0.6249 - val_loss: 1.0104 - val_acc: 0.0000e+00\n",
      "Epoch 6/40\n",
      "877/877 [==============================] - 1s 959us/step - loss: 0.6599 - acc: 0.6249 - val_loss: 1.0364 - val_acc: 0.0000e+00\n",
      "Epoch 7/40\n",
      "877/877 [==============================] - 1s 1ms/step - loss: 0.6578 - acc: 0.6249 - val_loss: 0.9558 - val_acc: 0.0000e+00\n",
      "Epoch 8/40\n",
      "877/877 [==============================] - 1s 1ms/step - loss: 0.6588 - acc: 0.6249 - val_loss: 0.9946 - val_acc: 0.0000e+00\n",
      "Epoch 9/40\n",
      "877/877 [==============================] - 1s 959us/step - loss: 0.6578 - acc: 0.6249 - val_loss: 0.9984 - val_acc: 0.0000e+00\n",
      "Epoch 10/40\n",
      "877/877 [==============================] - 1s 1ms/step - loss: 0.6564 - acc: 0.6249 - val_loss: 0.9959 - val_acc: 0.0000e+00\n",
      "Epoch 11/40\n",
      "877/877 [==============================] - 1s 1ms/step - loss: 0.6562 - acc: 0.6249 - val_loss: 1.0334 - val_acc: 0.0000e+00\n",
      "Epoch 12/40\n",
      "877/877 [==============================] - 1s 1ms/step - loss: 0.6553 - acc: 0.6249 - val_loss: 1.0379 - val_acc: 0.0000e+00\n",
      "Epoch 13/40\n",
      "877/877 [==============================] - 1s 1ms/step - loss: 0.6547 - acc: 0.6249 - val_loss: 1.0154 - val_acc: 0.0000e+00\n",
      "Epoch 14/40\n",
      "877/877 [==============================] - 1s 1ms/step - loss: 0.6536 - acc: 0.6249 - val_loss: 1.0777 - val_acc: 0.0000e+00\n",
      "Epoch 15/40\n",
      "877/877 [==============================] - 1s 1ms/step - loss: 0.6519 - acc: 0.6249 - val_loss: 0.9896 - val_acc: 0.0091\n",
      "Epoch 16/40\n",
      "877/877 [==============================] - 1s 972us/step - loss: 0.6513 - acc: 0.6294 - val_loss: 1.0006 - val_acc: 0.0000e+00\n",
      "Epoch 17/40\n",
      "877/877 [==============================] - 1s 930us/step - loss: 0.6509 - acc: 0.6340 - val_loss: 0.9861 - val_acc: 0.0000e+00\n",
      "Epoch 18/40\n",
      "877/877 [==============================] - 1s 1ms/step - loss: 0.6502 - acc: 0.6351 - val_loss: 1.0116 - val_acc: 0.0091\n",
      "Epoch 19/40\n",
      "877/877 [==============================] - 1s 1ms/step - loss: 0.6489 - acc: 0.6420 - val_loss: 1.0646 - val_acc: 0.0000e+00\n",
      "Epoch 20/40\n",
      "877/877 [==============================] - 1s 1ms/step - loss: 0.6469 - acc: 0.6408 - val_loss: 1.0582 - val_acc: 0.0000e+00\n",
      "Epoch 21/40\n",
      "877/877 [==============================] - 1s 1ms/step - loss: 0.6454 - acc: 0.6420 - val_loss: 0.9802 - val_acc: 0.0500\n",
      "Epoch 22/40\n",
      "877/877 [==============================] - 1s 1ms/step - loss: 0.6465 - acc: 0.6374 - val_loss: 1.0002 - val_acc: 0.0500\n",
      "Epoch 23/40\n",
      "877/877 [==============================] - 1s 1ms/step - loss: 0.6443 - acc: 0.6442 - val_loss: 1.0097 - val_acc: 0.0500\n",
      "Epoch 24/40\n",
      "877/877 [==============================] - 1s 1ms/step - loss: 0.6433 - acc: 0.6397 - val_loss: 1.0628 - val_acc: 0.0500\n",
      "Epoch 25/40\n",
      "877/877 [==============================] - 1s 1ms/step - loss: 0.6423 - acc: 0.6442 - val_loss: 1.1284 - val_acc: 0.0364\n",
      "Epoch 26/40\n",
      "877/877 [==============================] - 1s 1ms/step - loss: 0.6433 - acc: 0.6363 - val_loss: 1.0259 - val_acc: 0.0455\n",
      "Epoch 27/40\n",
      "877/877 [==============================] - 1s 1ms/step - loss: 0.6424 - acc: 0.6385 - val_loss: 1.0500 - val_acc: 0.0409\n",
      "Epoch 28/40\n",
      "877/877 [==============================] - 1s 1ms/step - loss: 0.6420 - acc: 0.6397 - val_loss: 1.0020 - val_acc: 0.0455\n",
      "Epoch 29/40\n",
      "877/877 [==============================] - 1s 997us/step - loss: 0.6397 - acc: 0.6465 - val_loss: 1.0635 - val_acc: 0.0409\n",
      "Epoch 30/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "877/877 [==============================] - 1s 945us/step - loss: 0.6409 - acc: 0.6431 - val_loss: 1.0583 - val_acc: 0.0455\n",
      "Epoch 31/40\n",
      "877/877 [==============================] - 1s 1ms/step - loss: 0.6383 - acc: 0.6499 - val_loss: 1.0050 - val_acc: 0.0455\n",
      "Epoch 32/40\n",
      "877/877 [==============================] - 1s 1ms/step - loss: 0.6394 - acc: 0.6385 - val_loss: 1.0852 - val_acc: 0.0409\n",
      "Epoch 33/40\n",
      "877/877 [==============================] - 1s 1ms/step - loss: 0.6388 - acc: 0.6420 - val_loss: 0.9952 - val_acc: 0.0455\n",
      "Epoch 34/40\n",
      "877/877 [==============================] - 1s 1ms/step - loss: 0.6372 - acc: 0.6465 - val_loss: 1.0627 - val_acc: 0.0409\n",
      "Epoch 35/40\n",
      "877/877 [==============================] - 1s 1ms/step - loss: 0.6384 - acc: 0.6454 - val_loss: 1.1073 - val_acc: 0.0409\n",
      "Epoch 36/40\n",
      "877/877 [==============================] - 1s 978us/step - loss: 0.6368 - acc: 0.6442 - val_loss: 1.0068 - val_acc: 0.0455\n",
      "Epoch 37/40\n",
      "877/877 [==============================] - 1s 1ms/step - loss: 0.6377 - acc: 0.6420 - val_loss: 1.0766 - val_acc: 0.0409\n",
      "Epoch 38/40\n",
      "877/877 [==============================] - 1s 1ms/step - loss: 0.6367 - acc: 0.6488 - val_loss: 1.0369 - val_acc: 0.0455\n",
      "Epoch 39/40\n",
      "877/877 [==============================] - 1s 953us/step - loss: 0.6354 - acc: 0.6442 - val_loss: 1.0484 - val_acc: 0.0455 0s - loss: 0.6330 - acc: 0.\n",
      "Epoch 40/40\n",
      "877/877 [==============================] - 1s 946us/step - loss: 0.6378 - acc: 0.6477 - val_loss: 1.0369 - val_acc: 0.0455\n",
      "121/121 [==============================] - 0s 68us/step\n",
      "Average accuracy of model on the dev set =  0.49836065590824763\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, random_state=12)\n",
    "avg_loss = []\n",
    "avg_acc = []\n",
    "# Loop through the indices the split() method returns\n",
    "for index, (train_index, test_index) in enumerate(skf.split(all_data, labels)):\n",
    "    print(\"Training on fold \" + str(index + 1) + \"/10.............................................\")\n",
    "    # Generate batches from indices\n",
    "    x_train, x_test = all_data[train_index], all_data[test_index]\n",
    "    # use one-hot vectors as labels\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "\n",
    "    network = models.Sequential()\n",
    "    \n",
    "\n",
    "    network.add(layers.Dense(32, input_shape=(8,)))\n",
    "    network.add(layers.Dense(32, activation=\"relu\"))\n",
    "    network.add(layers.Dense(16, activation=\"relu\"))\n",
    "    # network.add(layers.Dropout(0.3))\n",
    "    network.add(layers.Dense(16, activation=\"relu\"))\n",
    "    # network.add(layers.Dropout(0.3))\n",
    "    network.add(layers.Dense(32, activation=\"sigmoid\"))\n",
    "    network.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Adam = Adam(lr=0.05)\n",
    "    network.compile(optimizer=Adam(lr=0.0004),\n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=['acc'])\n",
    "\n",
    "    network.summary()\n",
    "\n",
    "    history = network.fit(x_train, y_train, validation_split=0.2,\n",
    "                          epochs=40, verbose=1, batch_size=3)\n",
    "\n",
    "    loss, accuracy = network.evaluate(x_test, y_test)\n",
    "\n",
    "    # evaluate and store the accuracy\n",
    "#     loss, accuracy = model.evaluate(xtest_imagelist, ytest, verbose=1)\n",
    "    avg_loss.append(loss)\n",
    "    avg_acc.append(accuracy)\n",
    "\n",
    "    # cross validation score\n",
    "    print(\"Average accuracy of model on the dev set = \", np.mean(avg_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
