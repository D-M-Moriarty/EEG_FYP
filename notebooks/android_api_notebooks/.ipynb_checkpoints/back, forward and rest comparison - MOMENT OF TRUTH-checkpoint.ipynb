{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "rest_android = pd.read_csv(\"../../data_files/data_from_android_api/rest/rest_25_mins.csv\")\n",
    "\n",
    "forward_android1 = pd.read_csv(\"../../data_files/data_from_android_api/forward/forward_5mins_1.csv\")\n",
    "forward_android2 = pd.read_csv(\"../../data_files/data_from_android_api/forward/forward_5mins_2.csv\")\n",
    "forward_android3 = pd.read_csv(\"../../data_files/data_from_android_api/forward/forward_5mins_3.csv\")\n",
    "forward_android4 = pd.read_csv(\"../../data_files/data_from_android_api/forward/forward_5mins_4.csv\")\n",
    "forward_android5 = pd.read_csv(\"../../data_files/data_from_android_api/forward/forward_5mins_5.csv\")\n",
    "\n",
    "back1 = pd.read_csv('../../data_files/data_from_android_api/back/back_5mins_1.csv')\n",
    "back2 = pd.read_csv('../../data_files/data_from_android_api/back/back_5mins_2.csv')\n",
    "back3 = pd.read_csv('../../data_files/data_from_android_api/back/back_5mins_3.csv')\n",
    "back4 = pd.read_csv('../../data_files/data_from_android_api/back/back_5mins_4.csv')\n",
    "back5 = pd.read_csv('../../data_files/data_from_android_api/back/back_5mins_5.csv')\n",
    "\n",
    "forward = pd.concat([forward_android1, forward_android2, forward_android3,\n",
    "                     forward_android4, forward_android5])\n",
    "\n",
    "back = pd.concat([back1, back2, back3, back4, back5])\n",
    "\n",
    "dataDF = pd.concat([forward, back])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "u = [back.delta.mean(), back.theta.mean(), back.alphaLow.mean(), \n",
    "     back.betaHigh.mean(), back.betaLow.mean(), back.alphaHigh.mean(), \n",
    "     back.gammaLow.mean(), back.gammaMid.mean()]\n",
    "\n",
    "d = [forward.delta.mean(), forward.theta.mean(), forward.alphaLow.mean(), \n",
    "     forward.betaHigh.mean(), forward.betaLow.mean(), forward.alphaHigh.mean(), \n",
    "     forward.gammaLow.mean(), forward.gammaMid.mean()]\n",
    "\n",
    "\n",
    "index = ['delta', 'theta', 'alphaLow','alphaHigh', 'betaLow', 'betaHigh', 'gammaLow', 'gammaMid']\n",
    "\n",
    "df = pd.DataFrame({'back': u, 'forward': d}, index=index)\n",
    "ax = df.plot.bar(rot=0, figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# create an array of shape 30706, 9 = number of records by the features\n",
    "data = np.array([[0 for x in range(8)] for y in range(len(dataDF))])\n",
    "for i in range(len(dataDF)):\n",
    "    data[i] = [dataDF.delta.values[i],\n",
    "                       dataDF.theta.values[i],\n",
    "                       dataDF.alphaLow.values[i],\n",
    "                       dataDF.alphaHigh.values[i],\n",
    "                       dataDF.betaLow.values[i],\n",
    "                       dataDF.betaHigh.values[i],\n",
    "                       dataDF.gammaLow.values[i],\n",
    "                       dataDF.gammaMid.values[i]]\n",
    "    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "encoder = LabelBinarizer()\n",
    "labels = encoder.fit_transform(dataDF.action.values)\n",
    "\n",
    "# creating training and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, labels)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "scaler = MinMaxScaler()\n",
    "stan_scaler = StandardScaler()\n",
    "\n",
    "x_train = stan_scaler.fit_transform(x_train)\n",
    "x_test = stan_scaler.transform(x_test)\n",
    "\n",
    "all_data = dataDF.drop(['action'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20389367 0.15616694 0.11025529 0.09656994 0.11201106 0.12193826\n",
      " 0.09635809 0.10280676]\n",
      "The score for Random Forest  0.6296296296296297\n",
      "2346\n",
      "Accuracy for x_test: 0.6296296296296297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:40: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:40: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracy: 0.59 (+/- 0.23)\n",
      "[0.35350318 0.39171975 0.63897764 0.67092652 0.62619808 0.69009585\n",
      " 0.66453674 0.68589744 0.54487179 0.58974359]\n",
      "Thresh=0.096, n=8, Accuracy: 64.24%\n",
      "Thresh=0.097, n=7, Accuracy: 60.03%\n",
      "Thresh=0.103, n=6, Accuracy: 63.35%\n",
      "Thresh=0.110, n=5, Accuracy: 62.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:40: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:40: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:40: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:40: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:40: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:40: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresh=0.112, n=4, Accuracy: 59.77%\n",
      "Thresh=0.122, n=3, Accuracy: 60.41%\n",
      "Thresh=0.156, n=2, Accuracy: 62.07%\n",
      "Thresh=0.204, n=1, Accuracy: 57.22%\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# XGBoost\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "from numpy import sort\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Random Forrest\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(x_train, y_train)\n",
    "\n",
    "print(rfc.feature_importances_)\n",
    "\n",
    "print(\"The score for Random Forest \", rfc.score(x_test, y_test))\n",
    "y_pred = rfc.predict(x_test)\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(len(y_train))\n",
    "print(\"Accuracy for x_test:\", metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "scores = cross_val_score(rfc, all_data, labels, cv=10, scoring='accuracy')\n",
    "print(\"Cross Validation Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "print(scores)\n",
    "\n",
    "# Fit model using each importance as a threshold\n",
    "thresholds = sort(rfc.feature_importances_)\n",
    "for thresh in thresholds:\n",
    "\t# select features using threshold\n",
    "\tselection = SelectFromModel(rfc, threshold=thresh, prefit=True)\n",
    "\tselect_X_train = selection.transform(x_train)\n",
    "\t# train model\n",
    "\tselection_model = RandomForestClassifier()\n",
    "\tselection_model.fit(select_X_train, y_train)\n",
    "\t# eval model\n",
    "\tselect_X_test = selection.transform(x_test)\n",
    "\ty_pred = selection_model.predict(select_X_test)\n",
    "\tpredictions = [round(value) for value in y_pred]\n",
    "\taccuracy = accuracy_score(y_test, predictions)\n",
    "\tprint(\"Thresh=%.3f, n=%d, Accuracy: %.2f%%\" % (thresh, select_X_train.shape[1], accuracy*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "The score for XGBoost  0.6475095785440613\n",
      "Accuracy for x_test: 0.6475095785440613\n",
      "Accuracy: 64.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracy: 0.64 (+/- 0.33)\n",
      "[0.33121019 0.34394904 0.6485623  0.77955272 0.75399361 0.78594249\n",
      " 0.71246006 0.80448718 0.59294872 0.63782051]\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(x_train, y_train)\n",
    "\n",
    "# plot feature importance\n",
    "plot_importance(xgb)\n",
    "pyplot.show()\n",
    "print(xgb)\n",
    "print(\"The score for XGBoost \", xgb.score(x_test, y_test))\n",
    "y_pred = xgb.predict(x_test)\n",
    "\n",
    "print(\"Accuracy for x_test:\", metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = metrics.accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "\n",
    "scores = cross_val_score(xgb, all_data, labels, cv=10, scoring='accuracy')\n",
    "print(\"Cross Validation Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_set = [(x_train, y_train), (x_test, y_test)]\n",
    "eval_metric = [\"auc\",\"error\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Tuning and feature importance XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score for XGBoost  0.6442307692307693\n",
      "Accuracy for x_test: 0.6442307692307693\n",
      "Accuracy: 64.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracy: 0.65 (+/- 0.32)\n",
      "[0.33757962 0.36942675 0.66453674 0.74121406 0.7827476  0.78913738\n",
      " 0.7284345  0.80128205 0.6025641  0.64423077]\n",
      "Thresh=0.080, n=8, Accuracy: 64.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresh=0.084, n=7, Accuracy: 62.82%\n",
      "Thresh=0.085, n=6, Accuracy: 63.14%\n",
      "Thresh=0.100, n=5, Accuracy: 62.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresh=0.101, n=4, Accuracy: 61.86%\n",
      "Thresh=0.128, n=3, Accuracy: 63.14%\n",
      "Thresh=0.131, n=2, Accuracy: 64.10%\n",
      "Thresh=0.291, n=1, Accuracy: 63.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "from numpy import sort\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "xgb = XGBClassifier(silent=True, \n",
    "                      scale_pos_weight=1,\n",
    "                      learning_rate=0.01,  \n",
    "                      colsample_bytree = 1,\n",
    "                      subsample = 0.3,\n",
    "                      objective='binary:logistic', \n",
    "                      n_estimators=100, \n",
    "                      reg_alpha = 0.3,\n",
    "                      max_depth=4, \n",
    "                      gamma=2)\n",
    "xgb.fit(x_train, y_train)\n",
    "# plot feature importance\n",
    "plot_importance(xgb)\n",
    "pyplot.show()\n",
    "# print(xgb)\n",
    "print(\"The score for XGBoost \", xgb.score(x_test, y_test))\n",
    "y_pred = xgb.predict(x_test)\n",
    "\n",
    "print(\"Accuracy for x_test:\", metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = metrics.accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "\n",
    "scores = cross_val_score(xgb, all_data, labels, cv=10, scoring='accuracy')\n",
    "print(\"Cross Validation Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "print(scores)\n",
    "\n",
    "# Fit model using each importance as a threshold\n",
    "thresholds = sort(xgb.feature_importances_)\n",
    "for thresh in thresholds:\n",
    "\t# select features using threshold\n",
    "\tselection = SelectFromModel(xgb, threshold=thresh, prefit=True)\n",
    "\tselect_X_train = selection.transform(x_train)\n",
    "\t# train model\n",
    "\tselection_model = XGBClassifier(silent=True, \n",
    "                      scale_pos_weight=1,\n",
    "                      learning_rate=0.01,  \n",
    "                      colsample_bytree = 1,\n",
    "                      subsample = 0.3,\n",
    "                      objective='binary:logistic', \n",
    "                      n_estimators=100, \n",
    "                      reg_alpha = 0.3,\n",
    "                      max_depth=4, \n",
    "                      gamma=2)\n",
    "\tselection_model.fit(select_X_train, y_train)\n",
    "\t# eval model\n",
    "\tselect_X_test = selection.transform(x_test)\n",
    "\ty_pred = selection_model.predict(select_X_test)\n",
    "\tpredictions = [round(value) for value in y_pred]\n",
    "\taccuracy = accuracy_score(y_test, predictions)\n",
    "\tprint(\"Thresh=%.3f, n=%d, Accuracy: %.2f%%\" % (thresh, select_X_train.shape[1], accuracy*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_120 (Dense)            (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_121 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_123 (Dense)            (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 2,865\n",
      "Trainable params: 2,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "2817/2817 [==============================] - 4s 1ms/step - loss: 0.6896 - acc: 0.5169\n",
      "Epoch 2/50\n",
      "2817/2817 [==============================] - 3s 985us/step - loss: 0.6856 - acc: 0.5296\n",
      "Epoch 3/50\n",
      "2817/2817 [==============================] - 2s 747us/step - loss: 0.6843 - acc: 0.5435\n",
      "Epoch 4/50\n",
      "2817/2817 [==============================] - 2s 746us/step - loss: 0.6834 - acc: 0.5499\n",
      "Epoch 5/50\n",
      "2817/2817 [==============================] - 2s 740us/step - loss: 0.6821 - acc: 0.5517\n",
      "Epoch 6/50\n",
      "2817/2817 [==============================] - 2s 762us/step - loss: 0.6812 - acc: 0.5577\n",
      "Epoch 7/50\n",
      "2817/2817 [==============================] - 3s 966us/step - loss: 0.6806 - acc: 0.5612\n",
      "Epoch 8/50\n",
      "2817/2817 [==============================] - 3s 982us/step - loss: 0.6797 - acc: 0.5722\n",
      "Epoch 9/50\n",
      "2817/2817 [==============================] - 3s 979us/step - loss: 0.6781 - acc: 0.5630\n",
      "Epoch 10/50\n",
      "2817/2817 [==============================] - 2s 851us/step - loss: 0.6781 - acc: 0.5747\n",
      "Epoch 11/50\n",
      "2817/2817 [==============================] - 2s 864us/step - loss: 0.6768 - acc: 0.5903\n",
      "Epoch 12/50\n",
      "2817/2817 [==============================] - 2s 728us/step - loss: 0.6747 - acc: 0.5687\n",
      "Epoch 13/50\n",
      "2817/2817 [==============================] - 3s 987us/step - loss: 0.6743 - acc: 0.5847\n",
      "Epoch 14/50\n",
      "2817/2817 [==============================] - 2s 808us/step - loss: 0.6721 - acc: 0.5921\n",
      "Epoch 15/50\n",
      "2817/2817 [==============================] - 2s 756us/step - loss: 0.6714 - acc: 0.5960\n",
      "Epoch 16/50\n",
      "2817/2817 [==============================] - 2s 743us/step - loss: 0.6682 - acc: 0.6021\n",
      "Epoch 17/50\n",
      "2817/2817 [==============================] - 2s 809us/step - loss: 0.6671 - acc: 0.6095\n",
      "Epoch 18/50\n",
      "2817/2817 [==============================] - 2s 765us/step - loss: 0.6648 - acc: 0.6134\n",
      "Epoch 19/50\n",
      "2817/2817 [==============================] - 2s 771us/step - loss: 0.6609 - acc: 0.6120\n",
      "Epoch 20/50\n",
      "2817/2817 [==============================] - 2s 762us/step - loss: 0.6595 - acc: 0.6148\n",
      "Epoch 21/50\n",
      "2817/2817 [==============================] - 2s 757us/step - loss: 0.6567 - acc: 0.6223\n",
      "Epoch 22/50\n",
      "2817/2817 [==============================] - 2s 750us/step - loss: 0.6547 - acc: 0.6276\n",
      "Epoch 23/50\n",
      "2817/2817 [==============================] - 2s 790us/step - loss: 0.6513 - acc: 0.6333\n",
      "Epoch 24/50\n",
      "2817/2817 [==============================] - 2s 792us/step - loss: 0.6499 - acc: 0.6262\n",
      "Epoch 25/50\n",
      "2817/2817 [==============================] - 2s 852us/step - loss: 0.6491 - acc: 0.6354\n",
      "Epoch 26/50\n",
      "2817/2817 [==============================] - 3s 1ms/step - loss: 0.6454 - acc: 0.6322\n",
      "Epoch 27/50\n",
      "2817/2817 [==============================] - 2s 823us/step - loss: 0.6450 - acc: 0.6386\n",
      "Epoch 28/50\n",
      "2817/2817 [==============================] - 3s 924us/step - loss: 0.6424 - acc: 0.6326\n",
      "Epoch 29/50\n",
      "2817/2817 [==============================] - 2s 808us/step - loss: 0.6420 - acc: 0.6326 0s - loss: 0.638\n",
      "Epoch 30/50\n",
      "2817/2817 [==============================] - 2s 831us/step - loss: 0.6415 - acc: 0.6319\n",
      "Epoch 31/50\n",
      "2817/2817 [==============================] - 2s 813us/step - loss: 0.6398 - acc: 0.6386 0s - loss: 0.6410 - acc: 0.\n",
      "Epoch 32/50\n",
      "2817/2817 [==============================] - 3s 1ms/step - loss: 0.6377 - acc: 0.6436\n",
      "Epoch 33/50\n",
      "2817/2817 [==============================] - 3s 917us/step - loss: 0.6368 - acc: 0.6514\n",
      "Epoch 34/50\n",
      "2817/2817 [==============================] - 3s 1ms/step - loss: 0.6358 - acc: 0.6457\n",
      "Epoch 35/50\n",
      "2817/2817 [==============================] - 3s 1ms/step - loss: 0.6352 - acc: 0.6429\n",
      "Epoch 36/50\n",
      "2817/2817 [==============================] - 3s 969us/step - loss: 0.6328 - acc: 0.6479\n",
      "Epoch 37/50\n",
      "2817/2817 [==============================] - 3s 1ms/step - loss: 0.6314 - acc: 0.6432\n",
      "Epoch 38/50\n",
      "2817/2817 [==============================] - 2s 792us/step - loss: 0.6330 - acc: 0.6510\n",
      "Epoch 39/50\n",
      "2817/2817 [==============================] - 3s 1ms/step - loss: 0.6310 - acc: 0.6486\n",
      "Epoch 40/50\n",
      "2817/2817 [==============================] - 3s 1ms/step - loss: 0.6303 - acc: 0.6535\n",
      "Epoch 41/50\n",
      "2817/2817 [==============================] - 4s 1ms/step - loss: 0.6309 - acc: 0.6542\n",
      "Epoch 42/50\n",
      "2817/2817 [==============================] - 3s 1ms/step - loss: 0.6296 - acc: 0.6546\n",
      "Epoch 43/50\n",
      "2817/2817 [==============================] - 3s 1ms/step - loss: 0.6292 - acc: 0.6510\n",
      "Epoch 44/50\n",
      "2817/2817 [==============================] - 3s 1ms/step - loss: 0.6259 - acc: 0.6560\n",
      "Epoch 45/50\n",
      "2817/2817 [==============================] - 3s 940us/step - loss: 0.6263 - acc: 0.6560\n",
      "Epoch 46/50\n",
      "2817/2817 [==============================] - 3s 1ms/step - loss: 0.6251 - acc: 0.6560\n",
      "Epoch 47/50\n",
      "2817/2817 [==============================] - 3s 937us/step - loss: 0.6239 - acc: 0.6518\n",
      "Epoch 48/50\n",
      "2817/2817 [==============================] - 2s 870us/step - loss: 0.6233 - acc: 0.6546\n",
      "Epoch 49/50\n",
      "2817/2817 [==============================] - 2s 830us/step - loss: 0.6232 - acc: 0.6578\n",
      "Epoch 50/50\n",
      "2817/2817 [==============================] - 3s 909us/step - loss: 0.6231 - acc: 0.6507\n",
      "312/312 [==============================] - 1s 2ms/step\n",
      "loss and metrics [0.6535329558910468, 0.6442307684666071]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "scaler = MinMaxScaler()\n",
    "stan_scaler = StandardScaler()\n",
    "\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "# from keras import regularizers kernel_regularizer=regularizers.l2(0.01), \n",
    "from keras.optimizers import Adam\n",
    "\n",
    "network = models.Sequential()\n",
    "\n",
    "network.add(layers.Dense(16, input_shape=(8,)))\n",
    "network.add(layers.Dense(32, activation=\"relu\"))\n",
    "network.add(layers.Dense(64, activation=\"relu\"))\n",
    "# network.add(layers.Dense(64, activation=\"relu\"))\n",
    "# network.add(layers.Dense(32, activation=\"relu\"))\n",
    "# network.add(layers.Dense(32, activation=\"relu\"))\n",
    "# network.add(layers.Dense(16, activation=\"sigmoid\"))\n",
    "network.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Adam = Adam(lr=0.05)\n",
    "network.compile(optimizer=Adam(lr=0.00038),\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['acc'])\n",
    "\n",
    "network.summary()\n",
    "\n",
    "history = network.fit(x_train, y_train,\n",
    "                      epochs=50, verbose=1, batch_size=2)\n",
    "\n",
    "loss_and_metrics = network.evaluate(x_test, y_test)\n",
    "print('loss and metrics', loss_and_metrics)\n",
    "\n",
    "# print('prediction: ', network.predict(test_data))\n",
    "\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenmoriarty/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "all_labels = dataDF.action.values\n",
    "\n",
    "encoder = LabelBinarizer()\n",
    "all_labels = encoder.fit_transform(all_labels)\n",
    "    \n",
    "# create an array of shape 30706, 9 = number of records by the features\n",
    "all_data = np.array([[0 for x in range(8)] for y in range(len(dataDF))])\n",
    "for i in range(len(dataDF)):\n",
    "    all_data[i] = [dataDF.delta.values[i],\n",
    "                       dataDF.theta.values[i],\n",
    "                       dataDF.alphaLow.values[i],\n",
    "                       dataDF.alphaHigh.values[i],\n",
    "                       dataDF.betaLow.values[i],\n",
    "                       dataDF.betaHigh.values[i],\n",
    "                       dataDF.gammaLow.values[i],\n",
    "                       dataDF.gammaMid.values[i]]\n",
    "    \n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "scaler = MinMaxScaler()\n",
    "stan_scaler = StandardScaler()\n",
    "\n",
    "all_data = scaler.fit_transform(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold 1/10.............................................\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 5,425\n",
      "Trainable params: 5,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2252 samples, validate on 563 samples\n",
      "Epoch 1/40\n",
      "2252/2252 [==============================] - 2s 908us/step - loss: 0.6619 - acc: 0.6061 - val_loss: 1.0431 - val_acc: 0.0515\n",
      "Epoch 2/40\n",
      "2252/2252 [==============================] - 2s 672us/step - loss: 0.6366 - acc: 0.6652 - val_loss: 1.0199 - val_acc: 0.0835\n",
      "Epoch 3/40\n",
      "2252/2252 [==============================] - 2s 695us/step - loss: 0.6339 - acc: 0.6656 - val_loss: 1.0683 - val_acc: 0.0835 0s - loss: 0.6323 -\n",
      "Epoch 4/40\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.6317 - acc: 0.6656 - val_loss: 1.0105 - val_acc: 0.0853\n",
      "Epoch 5/40\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.6323 - acc: 0.6656 - val_loss: 0.9871 - val_acc: 0.0941\n",
      "Epoch 6/40\n",
      "2252/2252 [==============================] - 1s 621us/step - loss: 0.6316 - acc: 0.6661 - val_loss: 1.0634 - val_acc: 0.0941\n",
      "Epoch 7/40\n",
      "2252/2252 [==============================] - 1s 629us/step - loss: 0.6304 - acc: 0.6670 - val_loss: 1.0896 - val_acc: 0.0853\n",
      "Epoch 8/40\n",
      "2252/2252 [==============================] - 1s 623us/step - loss: 0.6295 - acc: 0.6670 - val_loss: 1.0784 - val_acc: 0.0959\n",
      "Epoch 9/40\n",
      "2252/2252 [==============================] - 1s 628us/step - loss: 0.6269 - acc: 0.6679 - val_loss: 1.1134 - val_acc: 0.0977\n",
      "Epoch 10/40\n",
      "2252/2252 [==============================] - 1s 645us/step - loss: 0.6256 - acc: 0.6674 - val_loss: 0.9685 - val_acc: 0.0977: 0s - loss: 0.6217 - \n",
      "Epoch 11/40\n",
      "2252/2252 [==============================] - 1s 639us/step - loss: 0.6222 - acc: 0.6674 - val_loss: 1.0795 - val_acc: 0.0959\n",
      "Epoch 12/40\n",
      "2252/2252 [==============================] - 1s 638us/step - loss: 0.6180 - acc: 0.6679 - val_loss: 1.1366 - val_acc: 0.07820s - loss: 0\n",
      "Epoch 13/40\n",
      "2252/2252 [==============================] - 1s 619us/step - loss: 0.6123 - acc: 0.6714 - val_loss: 0.9559 - val_acc: 0.0977\n",
      "Epoch 14/40\n",
      "2252/2252 [==============================] - 1s 625us/step - loss: 0.6035 - acc: 0.6812 - val_loss: 1.1573 - val_acc: 0.0959\n",
      "Epoch 15/40\n",
      "2252/2252 [==============================] - 1s 657us/step - loss: 0.5940 - acc: 0.6865 - val_loss: 0.8356 - val_acc: 0.4405\n",
      "Epoch 16/40\n",
      "2252/2252 [==============================] - 1s 632us/step - loss: 0.5870 - acc: 0.7016 - val_loss: 0.8344 - val_acc: 0.4760\n",
      "Epoch 17/40\n",
      "2252/2252 [==============================] - 1s 623us/step - loss: 0.5846 - acc: 0.7012 - val_loss: 1.0993 - val_acc: 0.1670\n",
      "Epoch 18/40\n",
      "2252/2252 [==============================] - 1s 530us/step - loss: 0.5781 - acc: 0.7114 - val_loss: 1.0211 - val_acc: 0.3179\n",
      "Epoch 19/40\n",
      "2252/2252 [==============================] - 1s 550us/step - loss: 0.5736 - acc: 0.7060 - val_loss: 0.9448 - val_acc: 0.4636\n",
      "Epoch 20/40\n",
      "2252/2252 [==============================] - 1s 645us/step - loss: 0.5715 - acc: 0.7154 - val_loss: 0.8549 - val_acc: 0.4867\n",
      "Epoch 21/40\n",
      "2252/2252 [==============================] - 2s 678us/step - loss: 0.5655 - acc: 0.7163 - val_loss: 0.9868 - val_acc: 0.4387\n",
      "Epoch 22/40\n",
      "2252/2252 [==============================] - 1s 658us/step - loss: 0.5699 - acc: 0.7216 - val_loss: 1.2419 - val_acc: 0.1012\n",
      "Epoch 23/40\n",
      "2252/2252 [==============================] - 1s 645us/step - loss: 0.5682 - acc: 0.7202 - val_loss: 0.9169 - val_acc: 0.4831\n",
      "Epoch 24/40\n",
      "2252/2252 [==============================] - 1s 615us/step - loss: 0.5639 - acc: 0.7180 - val_loss: 0.8981 - val_acc: 0.4796\n",
      "Epoch 25/40\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.5617 - acc: 0.7282 - val_loss: 0.7812 - val_acc: 0.5684\n",
      "Epoch 26/40\n",
      "2252/2252 [==============================] - 1s 663us/step - loss: 0.5629 - acc: 0.7251 - val_loss: 0.9607 - val_acc: 0.4352\n",
      "Epoch 27/40\n",
      "2252/2252 [==============================] - 2s 697us/step - loss: 0.5617 - acc: 0.7216 - val_loss: 0.9614 - val_acc: 0.3961\n",
      "Epoch 28/40\n",
      "2252/2252 [==============================] - 1s 624us/step - loss: 0.5566 - acc: 0.7327 - val_loss: 0.8629 - val_acc: 0.5329\n",
      "Epoch 29/40\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.5593 - acc: 0.7211 - val_loss: 0.9797 - val_acc: 0.4316\n",
      "Epoch 30/40\n",
      "2252/2252 [==============================] - 1s 652us/step - loss: 0.5567 - acc: 0.7269 - val_loss: 0.8732 - val_acc: 0.4849\n",
      "Epoch 31/40\n",
      "2252/2252 [==============================] - 2s 672us/step - loss: 0.5564 - acc: 0.7300 - val_loss: 0.9603 - val_acc: 0.4494\n",
      "Epoch 32/40\n",
      "2252/2252 [==============================] - 2s 710us/step - loss: 0.5552 - acc: 0.7300 - val_loss: 1.1786 - val_acc: 0.1776\n",
      "Epoch 33/40\n",
      "2252/2252 [==============================] - 2s 733us/step - loss: 0.5537 - acc: 0.7278 - val_loss: 0.9138 - val_acc: 0.4547\n",
      "Epoch 34/40\n",
      "2252/2252 [==============================] - 2s 718us/step - loss: 0.5550 - acc: 0.7322 - val_loss: 0.9703 - val_acc: 0.4440\n",
      "Epoch 35/40\n",
      "2252/2252 [==============================] - 1s 656us/step - loss: 0.5536 - acc: 0.7336 - val_loss: 0.9583 - val_acc: 0.4281\n",
      "Epoch 36/40\n",
      "2252/2252 [==============================] - 1s 567us/step - loss: 0.5542 - acc: 0.7318 - val_loss: 1.0494 - val_acc: 0.3783\n",
      "Epoch 37/40\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.5505 - acc: 0.7362 - val_loss: 1.0140 - val_acc: 0.3943\n",
      "Epoch 38/40\n",
      "2252/2252 [==============================] - 1s 602us/step - loss: 0.5522 - acc: 0.7345 - val_loss: 0.8939 - val_acc: 0.5009\n",
      "Epoch 39/40\n",
      "2252/2252 [==============================] - 2s 669us/step - loss: 0.5475 - acc: 0.7353 - val_loss: 1.0247 - val_acc: 0.3979\n",
      "Epoch 40/40\n",
      "2252/2252 [==============================] - 1s 607us/step - loss: 0.5517 - acc: 0.7389 - val_loss: 0.9800 - val_acc: 0.4245\n",
      "314/314 [==============================] - 0s 28us/step\n",
      "Average accuracy of model on the dev set =  0.39490445864618207\n",
      "Training on fold 2/10.............................................\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 5,425\n",
      "Trainable params: 5,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2252 samples, validate on 563 samples\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2252/2252 [==============================] - 2s 1ms/step - loss: 0.6490 - acc: 0.6448 - val_loss: 1.0607 - val_acc: 0.0515\n",
      "Epoch 2/40\n",
      "2252/2252 [==============================] - 1s 653us/step - loss: 0.6354 - acc: 0.6554 - val_loss: 1.0835 - val_acc: 0.0710\n",
      "Epoch 3/40\n",
      "2252/2252 [==============================] - 1s 651us/step - loss: 0.6313 - acc: 0.6607 - val_loss: 1.0986 - val_acc: 0.0746\n",
      "Epoch 4/40\n",
      "2252/2252 [==============================] - 1s 627us/step - loss: 0.6309 - acc: 0.6634 - val_loss: 1.0604 - val_acc: 0.0906\n",
      "Epoch 5/40\n",
      "2252/2252 [==============================] - 1s 660us/step - loss: 0.6294 - acc: 0.6634 - val_loss: 1.0422 - val_acc: 0.0906\n",
      "Epoch 6/40\n",
      "2252/2252 [==============================] - 2s 690us/step - loss: 0.6274 - acc: 0.6621 - val_loss: 1.0202 - val_acc: 0.0906\n",
      "Epoch 7/40\n",
      "2252/2252 [==============================] - 1s 644us/step - loss: 0.6264 - acc: 0.6612 - val_loss: 1.0681 - val_acc: 0.0906\n",
      "Epoch 8/40\n",
      "2252/2252 [==============================] - 1s 609us/step - loss: 0.6234 - acc: 0.6625 - val_loss: 1.1020 - val_acc: 0.0728\n",
      "Epoch 9/40\n",
      "2252/2252 [==============================] - 1s 531us/step - loss: 0.6194 - acc: 0.6625 - val_loss: 0.9744 - val_acc: 0.2149\n",
      "Epoch 10/40\n",
      "2252/2252 [==============================] - 1s 635us/step - loss: 0.6140 - acc: 0.6656 - val_loss: 1.0087 - val_acc: 0.0977\n",
      "Epoch 11/40\n",
      "2252/2252 [==============================] - 2s 684us/step - loss: 0.6075 - acc: 0.6816 - val_loss: 1.0003 - val_acc: 0.3339\n",
      "Epoch 12/40\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.6008 - acc: 0.6812 - val_loss: 1.0011 - val_acc: 0.4050\n",
      "Epoch 13/40\n",
      "2252/2252 [==============================] - 1s 654us/step - loss: 0.5950 - acc: 0.6954 - val_loss: 1.1101 - val_acc: 0.1723\n",
      "Epoch 14/40\n",
      "2252/2252 [==============================] - 1s 665us/step - loss: 0.5915 - acc: 0.6989 - val_loss: 0.9546 - val_acc: 0.4227\n",
      "Epoch 15/40\n",
      "2252/2252 [==============================] - 2s 681us/step - loss: 0.5867 - acc: 0.7083 - val_loss: 1.0486 - val_acc: 0.3250\n",
      "Epoch 16/40\n",
      "2252/2252 [==============================] - 2s 676us/step - loss: 0.5831 - acc: 0.7052 - val_loss: 0.9045 - val_acc: 0.3783\n",
      "Epoch 17/40\n",
      "2252/2252 [==============================] - 2s 674us/step - loss: 0.5830 - acc: 0.7109 - val_loss: 0.8252 - val_acc: 0.4725\n",
      "Epoch 18/40\n",
      "2252/2252 [==============================] - 2s 722us/step - loss: 0.5796 - acc: 0.7131 - val_loss: 1.0594 - val_acc: 0.3641\n",
      "Epoch 19/40\n",
      "2252/2252 [==============================] - 2s 677us/step - loss: 0.5780 - acc: 0.7109 - val_loss: 0.9939 - val_acc: 0.4032\n",
      "Epoch 20/40\n",
      "2252/2252 [==============================] - 1s 644us/step - loss: 0.5782 - acc: 0.7136 - val_loss: 0.9977 - val_acc: 0.4032\n",
      "Epoch 21/40\n",
      "2252/2252 [==============================] - 2s 773us/step - loss: 0.5760 - acc: 0.7149 - val_loss: 0.9677 - val_acc: 0.4121\n",
      "Epoch 22/40\n",
      "2252/2252 [==============================] - 2s 705us/step - loss: 0.5723 - acc: 0.7149 - val_loss: 0.8940 - val_acc: 0.4387\n",
      "Epoch 23/40\n",
      "2252/2252 [==============================] - 2s 807us/step - loss: 0.5696 - acc: 0.7185 - val_loss: 1.0063 - val_acc: 0.4050\n",
      "Epoch 24/40\n",
      "2252/2252 [==============================] - 2s 708us/step - loss: 0.5692 - acc: 0.7118 - val_loss: 1.0421 - val_acc: 0.3535\n",
      "Epoch 25/40\n",
      "2252/2252 [==============================] - 1s 577us/step - loss: 0.5703 - acc: 0.7100 - val_loss: 1.0196 - val_acc: 0.3268\n",
      "Epoch 26/40\n",
      "2252/2252 [==============================] - 1s 545us/step - loss: 0.5638 - acc: 0.7278 - val_loss: 1.0756 - val_acc: 0.3606\n",
      "Epoch 27/40\n",
      "2252/2252 [==============================] - 1s 549us/step - loss: 0.5662 - acc: 0.7211 - val_loss: 0.9461 - val_acc: 0.4085\n",
      "Epoch 28/40\n",
      "2252/2252 [==============================] - 1s 547us/step - loss: 0.5643 - acc: 0.7225 - val_loss: 0.8878 - val_acc: 0.4085\n",
      "Epoch 29/40\n",
      "2252/2252 [==============================] - 1s 629us/step - loss: 0.5631 - acc: 0.7207 - val_loss: 0.9621 - val_acc: 0.3890\n",
      "Epoch 30/40\n",
      "2252/2252 [==============================] - 1s 575us/step - loss: 0.5626 - acc: 0.7247 - val_loss: 0.9645 - val_acc: 0.4156\n",
      "Epoch 31/40\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.5560 - acc: 0.7300 - val_loss: 0.8658 - val_acc: 0.5364\n",
      "Epoch 32/40\n",
      "2252/2252 [==============================] - 1s 622us/step - loss: 0.5622 - acc: 0.7265 - val_loss: 0.9114 - val_acc: 0.5133\n",
      "Epoch 33/40\n",
      "2252/2252 [==============================] - 1s 622us/step - loss: 0.5533 - acc: 0.7331 - val_loss: 0.9271 - val_acc: 0.4298\n",
      "Epoch 34/40\n",
      "2252/2252 [==============================] - 1s 601us/step - loss: 0.5563 - acc: 0.7229 - val_loss: 1.0569 - val_acc: 0.3286s - loss: 0.5597 - acc: 0.72\n",
      "Epoch 35/40\n",
      "2252/2252 [==============================] - 1s 660us/step - loss: 0.5586 - acc: 0.7238 - val_loss: 0.9708 - val_acc: 0.4103\n",
      "Epoch 36/40\n",
      "2252/2252 [==============================] - 2s 737us/step - loss: 0.5553 - acc: 0.7300 - val_loss: 1.0501 - val_acc: 0.3428\n",
      "Epoch 37/40\n",
      "2252/2252 [==============================] - 2s 800us/step - loss: 0.5545 - acc: 0.7305 - val_loss: 1.0608 - val_acc: 0.4050\n",
      "Epoch 38/40\n",
      "2252/2252 [==============================] - 2s 786us/step - loss: 0.5519 - acc: 0.7313 - val_loss: 0.9199 - val_acc: 0.3837\n",
      "Epoch 39/40\n",
      "2252/2252 [==============================] - 2s 741us/step - loss: 0.5543 - acc: 0.7345 - val_loss: 0.8746 - val_acc: 0.4938\n",
      "Epoch 40/40\n",
      "2252/2252 [==============================] - 2s 688us/step - loss: 0.5521 - acc: 0.7300 - val_loss: 0.9626 - val_acc: 0.4085\n",
      "314/314 [==============================] - 0s 25us/step\n",
      "Average accuracy of model on the dev set =  0.4028662420856725\n",
      "Training on fold 3/10.............................................\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_21 (Dense)             (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 5,425\n",
      "Trainable params: 5,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2252 samples, validate on 564 samples\n",
      "Epoch 1/40\n",
      "2252/2252 [==============================] - 3s 1ms/step - loss: 0.6512 - acc: 0.6443 - val_loss: 1.0613 - val_acc: 0.0000e+00\n",
      "Epoch 2/40\n",
      "2252/2252 [==============================] - 2s 705us/step - loss: 0.6471 - acc: 0.6443 - val_loss: 1.0209 - val_acc: 0.0000e+00\n",
      "Epoch 3/40\n",
      "2252/2252 [==============================] - 1s 621us/step - loss: 0.6440 - acc: 0.6425 - val_loss: 1.0239 - val_acc: 0.0709\n",
      "Epoch 4/40\n",
      "2252/2252 [==============================] - 1s 618us/step - loss: 0.6424 - acc: 0.6474 - val_loss: 1.0251 - val_acc: 0.0851\n",
      "Epoch 5/40\n",
      "2252/2252 [==============================] - 1s 634us/step - loss: 0.6407 - acc: 0.6514 - val_loss: 1.0456 - val_acc: 0.0709\n",
      "Epoch 6/40\n",
      "2252/2252 [==============================] - 1s 639us/step - loss: 0.6398 - acc: 0.6496 - val_loss: 0.9753 - val_acc: 0.0975\n",
      "Epoch 7/40\n",
      "2252/2252 [==============================] - 1s 537us/step - loss: 0.6385 - acc: 0.6510 - val_loss: 0.9826 - val_acc: 0.0940\n",
      "Epoch 8/40\n",
      "2252/2252 [==============================] - 1s 628us/step - loss: 0.6377 - acc: 0.6536 - val_loss: 1.0029 - val_acc: 0.0940\n",
      "Epoch 9/40\n",
      "2252/2252 [==============================] - 1s 611us/step - loss: 0.6347 - acc: 0.6528 - val_loss: 1.0311 - val_acc: 0.0940loss: 0.6344 - \n",
      "Epoch 10/40\n",
      "2252/2252 [==============================] - 1s 638us/step - loss: 0.6330 - acc: 0.6567 - val_loss: 0.9259 - val_acc: 0.0993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/40\n",
      "2252/2252 [==============================] - 1s 627us/step - loss: 0.6298 - acc: 0.6532 - val_loss: 1.0809 - val_acc: 0.0993\n",
      "Epoch 12/40\n",
      "2252/2252 [==============================] - 1s 618us/step - loss: 0.6291 - acc: 0.6563 - val_loss: 1.0811 - val_acc: 0.0940\n",
      "Epoch 13/40\n",
      "2252/2252 [==============================] - 1s 651us/step - loss: 0.6250 - acc: 0.6599 - val_loss: 1.0659 - val_acc: 0.0957\n",
      "Epoch 14/40\n",
      "2252/2252 [==============================] - 1s 660us/step - loss: 0.6221 - acc: 0.6679 - val_loss: 0.9925 - val_acc: 0.0993\n",
      "Epoch 15/40\n",
      "2252/2252 [==============================] - 1s 629us/step - loss: 0.6196 - acc: 0.6612 - val_loss: 0.9042 - val_acc: 0.3599\n",
      "Epoch 16/40\n",
      "2252/2252 [==============================] - 1s 614us/step - loss: 0.6186 - acc: 0.6630 - val_loss: 1.0768 - val_acc: 0.0957\n",
      "Epoch 17/40\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.6182 - acc: 0.6687 - val_loss: 0.9186 - val_acc: 0.1950\n",
      "Epoch 18/40\n",
      "2252/2252 [==============================] - 2s 684us/step - loss: 0.6127 - acc: 0.6674 - val_loss: 1.0112 - val_acc: 0.1543\n",
      "Epoch 19/40\n",
      "2252/2252 [==============================] - 1s 586us/step - loss: 0.6141 - acc: 0.6679 - val_loss: 1.0782 - val_acc: 0.0957\n",
      "Epoch 20/40\n",
      "2252/2252 [==============================] - 2s 669us/step - loss: 0.6132 - acc: 0.6661 - val_loss: 0.8894 - val_acc: 0.3475\n",
      "Epoch 21/40\n",
      "2252/2252 [==============================] - 2s 743us/step - loss: 0.6104 - acc: 0.6776 - val_loss: 0.9260 - val_acc: 0.3741\n",
      "Epoch 22/40\n",
      "2252/2252 [==============================] - 2s 730us/step - loss: 0.6096 - acc: 0.6767 - val_loss: 0.9172 - val_acc: 0.4504\n",
      "Epoch 23/40\n",
      "2252/2252 [==============================] - 2s 813us/step - loss: 0.6085 - acc: 0.6852 - val_loss: 0.9432 - val_acc: 0.3635\n",
      "Epoch 24/40\n",
      "2252/2252 [==============================] - 1s 617us/step - loss: 0.6065 - acc: 0.6781 - val_loss: 0.8468 - val_acc: 0.4734\n",
      "Epoch 25/40\n",
      "2252/2252 [==============================] - 1s 554us/step - loss: 0.6056 - acc: 0.6821 - val_loss: 1.0322 - val_acc: 0.2996\n",
      "Epoch 26/40\n",
      "2252/2252 [==============================] - 1s 631us/step - loss: 0.6031 - acc: 0.6838 - val_loss: 1.1604 - val_acc: 0.1135\n",
      "Epoch 27/40\n",
      "2252/2252 [==============================] - 1s 618us/step - loss: 0.6028 - acc: 0.6887 - val_loss: 1.0110 - val_acc: 0.3156\n",
      "Epoch 28/40\n",
      "2252/2252 [==============================] - 1s 615us/step - loss: 0.6038 - acc: 0.6861 - val_loss: 1.0650 - val_acc: 0.2535\n",
      "Epoch 29/40\n",
      "2252/2252 [==============================] - 1s 629us/step - loss: 0.6014 - acc: 0.6861 - val_loss: 0.9578 - val_acc: 0.3741\n",
      "Epoch 30/40\n",
      "2252/2252 [==============================] - 1s 615us/step - loss: 0.6014 - acc: 0.6883 - val_loss: 0.8171 - val_acc: 0.5018\n",
      "Epoch 31/40\n",
      "2252/2252 [==============================] - 1s 583us/step - loss: 0.6007 - acc: 0.6923 - val_loss: 0.9851 - val_acc: 0.2589\n",
      "Epoch 32/40\n",
      "2252/2252 [==============================] - 1s 599us/step - loss: 0.6010 - acc: 0.6936 - val_loss: 1.0289 - val_acc: 0.2553\n",
      "Epoch 33/40\n",
      "2252/2252 [==============================] - 1s 616us/step - loss: 0.5967 - acc: 0.6963 - val_loss: 0.9773 - val_acc: 0.3280\n",
      "Epoch 34/40\n",
      "2252/2252 [==============================] - 2s 723us/step - loss: 0.5957 - acc: 0.7007 - val_loss: 0.9808 - val_acc: 0.3564\n",
      "Epoch 35/40\n",
      "2252/2252 [==============================] - 2s 692us/step - loss: 0.5953 - acc: 0.6954 - val_loss: 1.1161 - val_acc: 0.2287\n",
      "Epoch 36/40\n",
      "2252/2252 [==============================] - 2s 671us/step - loss: 0.5956 - acc: 0.6963 - val_loss: 0.9871 - val_acc: 0.3723\n",
      "Epoch 37/40\n",
      "2252/2252 [==============================] - 1s 655us/step - loss: 0.5885 - acc: 0.7025 - val_loss: 0.8857 - val_acc: 0.4043\n",
      "Epoch 38/40\n",
      "2252/2252 [==============================] - 2s 668us/step - loss: 0.5922 - acc: 0.6963 - val_loss: 1.0902 - val_acc: 0.2589\n",
      "Epoch 39/40\n",
      "2252/2252 [==============================] - 2s 679us/step - loss: 0.5915 - acc: 0.7020 - val_loss: 1.0323 - val_acc: 0.2943\n",
      "Epoch 40/40\n",
      "2252/2252 [==============================] - 2s 747us/step - loss: 0.5899 - acc: 0.7016 - val_loss: 0.9585 - val_acc: 0.3723\n",
      "313/313 [==============================] - 0s 30us/step\n",
      "Average accuracy of model on the dev set =  0.4719853753844796\n",
      "Training on fold 4/10.............................................\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_27 (Dense)             (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 5,425\n",
      "Trainable params: 5,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2252 samples, validate on 564 samples\n",
      "Epoch 1/40\n",
      "2252/2252 [==============================] - 3s 1ms/step - loss: 0.6564 - acc: 0.6359 - val_loss: 1.1240 - val_acc: 0.0000e+00\n",
      "Epoch 2/40\n",
      "2252/2252 [==============================] - 2s 803us/step - loss: 0.6493 - acc: 0.6443 - val_loss: 1.0192 - val_acc: 0.0000e+00\n",
      "Epoch 3/40\n",
      "2252/2252 [==============================] - 1s 659us/step - loss: 0.6468 - acc: 0.6443 - val_loss: 0.9837 - val_acc: 0.0000e+00\n",
      "Epoch 4/40\n",
      "2252/2252 [==============================] - 1s 619us/step - loss: 0.6472 - acc: 0.6443 - val_loss: 1.0930 - val_acc: 0.0000e+00\n",
      "Epoch 5/40\n",
      "2252/2252 [==============================] - 2s 740us/step - loss: 0.6470 - acc: 0.6443 - val_loss: 0.9951 - val_acc: 0.0000e+00\n",
      "Epoch 6/40\n",
      "2252/2252 [==============================] - 2s 716us/step - loss: 0.6460 - acc: 0.6430 - val_loss: 1.0179 - val_acc: 0.0000e+00\n",
      "Epoch 7/40\n",
      "2252/2252 [==============================] - 2s 754us/step - loss: 0.6448 - acc: 0.6452 - val_loss: 1.0128 - val_acc: 0.0018\n",
      "Epoch 8/40\n",
      "2252/2252 [==============================] - 2s 810us/step - loss: 0.6442 - acc: 0.6528 - val_loss: 1.0339 - val_acc: 0.0000e+00\n",
      "Epoch 9/40\n",
      "2252/2252 [==============================] - 2s 830us/step - loss: 0.6439 - acc: 0.6461 - val_loss: 1.0758 - val_acc: 0.0621\n",
      "Epoch 10/40\n",
      "2252/2252 [==============================] - 2s 827us/step - loss: 0.6429 - acc: 0.6439 - val_loss: 1.0758 - val_acc: 0.0656\n",
      "Epoch 11/40\n",
      "2252/2252 [==============================] - 2s 880us/step - loss: 0.6432 - acc: 0.6461 - val_loss: 1.0558 - val_acc: 0.0638\n",
      "Epoch 12/40\n",
      "2252/2252 [==============================] - 2s 869us/step - loss: 0.6420 - acc: 0.6483 - val_loss: 1.0373 - val_acc: 0.0638\n",
      "Epoch 13/40\n",
      "2252/2252 [==============================] - 2s 878us/step - loss: 0.6411 - acc: 0.6496 - val_loss: 0.9400 - val_acc: 0.0762\n",
      "Epoch 14/40\n",
      "2252/2252 [==============================] - 2s 820us/step - loss: 0.6413 - acc: 0.6465 - val_loss: 1.0733 - val_acc: 0.0124\n",
      "Epoch 15/40\n",
      "2252/2252 [==============================] - 2s 887us/step - loss: 0.6406 - acc: 0.6456 - val_loss: 0.9934 - val_acc: 0.0656\n",
      "Epoch 16/40\n",
      "2252/2252 [==============================] - 2s 820us/step - loss: 0.6394 - acc: 0.6501 - val_loss: 1.1027 - val_acc: 0.0638\n",
      "Epoch 17/40\n",
      "2252/2252 [==============================] - 2s 827us/step - loss: 0.6388 - acc: 0.6514 - val_loss: 0.9590 - val_acc: 0.0762\n",
      "Epoch 18/40\n",
      "2252/2252 [==============================] - 2s 835us/step - loss: 0.6385 - acc: 0.6514 - val_loss: 1.0113 - val_acc: 0.0887\n",
      "Epoch 19/40\n",
      "2252/2252 [==============================] - 2s 824us/step - loss: 0.6373 - acc: 0.6532 - val_loss: 1.0893 - val_acc: 0.0745\n",
      "Epoch 20/40\n",
      "2252/2252 [==============================] - 2s 834us/step - loss: 0.6363 - acc: 0.6550 - val_loss: 1.1520 - val_acc: 0.0124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/40\n",
      "2252/2252 [==============================] - 2s 853us/step - loss: 0.6354 - acc: 0.6572 - val_loss: 1.1314 - val_acc: 0.0124\n",
      "Epoch 22/40\n",
      "2252/2252 [==============================] - 2s 794us/step - loss: 0.6343 - acc: 0.6563 - val_loss: 1.0776 - val_acc: 0.0124\n",
      "Epoch 23/40\n",
      "2252/2252 [==============================] - 2s 735us/step - loss: 0.6337 - acc: 0.6585 - val_loss: 1.0736 - val_acc: 0.0124\n",
      "Epoch 24/40\n",
      "2252/2252 [==============================] - 2s 859us/step - loss: 0.6322 - acc: 0.6563 - val_loss: 1.0610 - val_acc: 0.0142\n",
      "Epoch 25/40\n",
      "2252/2252 [==============================] - 2s 838us/step - loss: 0.6306 - acc: 0.6554 - val_loss: 1.0646 - val_acc: 0.0230\n",
      "Epoch 26/40\n",
      "2252/2252 [==============================] - 2s 876us/step - loss: 0.6294 - acc: 0.6563 - val_loss: 0.9817 - val_acc: 0.0230\n",
      "Epoch 27/40\n",
      "2252/2252 [==============================] - 2s 882us/step - loss: 0.6281 - acc: 0.6545 - val_loss: 0.9654 - val_acc: 0.0940\n",
      "Epoch 28/40\n",
      "2252/2252 [==============================] - 2s 969us/step - loss: 0.6249 - acc: 0.6563 - val_loss: 1.1115 - val_acc: 0.0266\n",
      "Epoch 29/40\n",
      "2252/2252 [==============================] - 2s 973us/step - loss: 0.6254 - acc: 0.6532 - val_loss: 1.0267 - val_acc: 0.0284\n",
      "Epoch 30/40\n",
      "2252/2252 [==============================] - 2s 889us/step - loss: 0.6217 - acc: 0.6625 - val_loss: 0.9506 - val_acc: 0.1684\n",
      "Epoch 31/40\n",
      "2252/2252 [==============================] - 2s 869us/step - loss: 0.6213 - acc: 0.6621 - val_loss: 1.0136 - val_acc: 0.0798\n",
      "Epoch 32/40\n",
      "2252/2252 [==============================] - 2s 954us/step - loss: 0.6198 - acc: 0.6612 - val_loss: 0.9909 - val_acc: 0.1454\n",
      "Epoch 33/40\n",
      "2252/2252 [==============================] - 2s 971us/step - loss: 0.6177 - acc: 0.6665 - val_loss: 1.0243 - val_acc: 0.0319\n",
      "Epoch 34/40\n",
      "2252/2252 [==============================] - 2s 909us/step - loss: 0.6175 - acc: 0.6603 - val_loss: 0.9768 - val_acc: 0.2784\n",
      "Epoch 35/40\n",
      "2252/2252 [==============================] - 2s 912us/step - loss: 0.6157 - acc: 0.6679 - val_loss: 1.0258 - val_acc: 0.1170\n",
      "Epoch 36/40\n",
      "2252/2252 [==============================] - 2s 902us/step - loss: 0.6135 - acc: 0.6732 - val_loss: 1.0196 - val_acc: 0.0993\n",
      "Epoch 37/40\n",
      "2252/2252 [==============================] - 2s 913us/step - loss: 0.6125 - acc: 0.6745 - val_loss: 0.8319 - val_acc: 0.4787\n",
      "Epoch 38/40\n",
      "2252/2252 [==============================] - 2s 916us/step - loss: 0.6113 - acc: 0.6741 - val_loss: 0.9265 - val_acc: 0.2784\n",
      "Epoch 39/40\n",
      "2252/2252 [==============================] - 2s 867us/step - loss: 0.6123 - acc: 0.6652 - val_loss: 1.1567 - val_acc: 0.0266\n",
      "Epoch 40/40\n",
      "2252/2252 [==============================] - 2s 898us/step - loss: 0.6092 - acc: 0.6772 - val_loss: 0.9078 - val_acc: 0.3706\n",
      "313/313 [==============================] - 0s 40us/step\n",
      "Average accuracy of model on the dev set =  0.5209219391722477\n",
      "Training on fold 5/10.............................................\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_33 (Dense)             (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 5,425\n",
      "Trainable params: 5,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2252 samples, validate on 564 samples\n",
      "Epoch 1/40\n",
      "2252/2252 [==============================] - 3s 1ms/step - loss: 0.6694 - acc: 0.5981 - val_loss: 1.0907 - val_acc: 0.0000e+00\n",
      "Epoch 2/40\n",
      "2252/2252 [==============================] - 2s 815us/step - loss: 0.6493 - acc: 0.6443 - val_loss: 1.0323 - val_acc: 0.0000e+00\n",
      "Epoch 3/40\n",
      "2252/2252 [==============================] - 2s 794us/step - loss: 0.6477 - acc: 0.6452 - val_loss: 1.0430 - val_acc: 0.0000e+00\n",
      "Epoch 4/40\n",
      "2252/2252 [==============================] - 2s 737us/step - loss: 0.6467 - acc: 0.6465 - val_loss: 1.0304 - val_acc: 0.0514\n",
      "Epoch 5/40\n",
      "2252/2252 [==============================] - 2s 770us/step - loss: 0.6458 - acc: 0.6465 - val_loss: 1.0248 - val_acc: 0.0922\n",
      "Epoch 6/40\n",
      "2252/2252 [==============================] - 2s 755us/step - loss: 0.6451 - acc: 0.6514 - val_loss: 1.0806 - val_acc: 0.0000e+00\n",
      "Epoch 7/40\n",
      "2252/2252 [==============================] - 2s 761us/step - loss: 0.6448 - acc: 0.6483 - val_loss: 1.0329 - val_acc: 0.0727\n",
      "Epoch 8/40\n",
      "2252/2252 [==============================] - 2s 741us/step - loss: 0.6450 - acc: 0.6479 - val_loss: 0.9404 - val_acc: 0.0993\n",
      "Epoch 9/40\n",
      "2252/2252 [==============================] - 2s 713us/step - loss: 0.6446 - acc: 0.6505 - val_loss: 0.9513 - val_acc: 0.0993\n",
      "Epoch 10/40\n",
      "2252/2252 [==============================] - 2s 788us/step - loss: 0.6425 - acc: 0.6501 - val_loss: 0.9445 - val_acc: 0.0993\n",
      "Epoch 11/40\n",
      "2252/2252 [==============================] - 2s 742us/step - loss: 0.6436 - acc: 0.6488 - val_loss: 0.9684 - val_acc: 0.0957\n",
      "Epoch 12/40\n",
      "2252/2252 [==============================] - 2s 720us/step - loss: 0.6431 - acc: 0.6505 - val_loss: 1.0917 - val_acc: 0.0674\n",
      "Epoch 13/40\n",
      "2252/2252 [==============================] - 2s 724us/step - loss: 0.6426 - acc: 0.6492 - val_loss: 0.9521 - val_acc: 0.0993\n",
      "Epoch 14/40\n",
      "2252/2252 [==============================] - 2s 912us/step - loss: 0.6417 - acc: 0.6510 - val_loss: 1.1021 - val_acc: 0.0727\n",
      "Epoch 15/40\n",
      "2252/2252 [==============================] - 2s 796us/step - loss: 0.6406 - acc: 0.6510 - val_loss: 1.0788 - val_acc: 0.0124\n",
      "Epoch 16/40\n",
      "2252/2252 [==============================] - 2s 672us/step - loss: 0.6403 - acc: 0.6488 - val_loss: 1.0215 - val_acc: 0.0940\n",
      "Epoch 17/40\n",
      "2252/2252 [==============================] - 2s 747us/step - loss: 0.6383 - acc: 0.6470 - val_loss: 0.9449 - val_acc: 0.0993\n",
      "Epoch 18/40\n",
      "2252/2252 [==============================] - 2s 721us/step - loss: 0.6376 - acc: 0.6465 - val_loss: 1.0037 - val_acc: 0.0940\n",
      "Epoch 19/40\n",
      "2252/2252 [==============================] - 2s 728us/step - loss: 0.6349 - acc: 0.6510 - val_loss: 1.0529 - val_acc: 0.0957\n",
      "Epoch 20/40\n",
      "2252/2252 [==============================] - 2s 805us/step - loss: 0.6348 - acc: 0.6501 - val_loss: 0.9241 - val_acc: 0.0940\n",
      "Epoch 21/40\n",
      "2252/2252 [==============================] - 2s 739us/step - loss: 0.6331 - acc: 0.6510 - val_loss: 1.0062 - val_acc: 0.0248\n",
      "Epoch 22/40\n",
      "2252/2252 [==============================] - 2s 740us/step - loss: 0.6311 - acc: 0.6505 - val_loss: 1.1155 - val_acc: 0.0940\n",
      "Epoch 23/40\n",
      "2252/2252 [==============================] - 2s 802us/step - loss: 0.6313 - acc: 0.6519 - val_loss: 1.0639 - val_acc: 0.0940\n",
      "Epoch 24/40\n",
      "2252/2252 [==============================] - 2s 726us/step - loss: 0.6296 - acc: 0.6510 - val_loss: 0.9274 - val_acc: 0.0940\n",
      "Epoch 25/40\n",
      "2252/2252 [==============================] - 2s 781us/step - loss: 0.6271 - acc: 0.6505 - val_loss: 1.0546 - val_acc: 0.0940\n",
      "Epoch 26/40\n",
      "2252/2252 [==============================] - 2s 769us/step - loss: 0.6280 - acc: 0.6567 - val_loss: 0.9987 - val_acc: 0.0284\n",
      "Epoch 27/40\n",
      "2252/2252 [==============================] - 2s 797us/step - loss: 0.6268 - acc: 0.6541 - val_loss: 0.8819 - val_acc: 0.1082\n",
      "Epoch 28/40\n",
      "2252/2252 [==============================] - 2s 786us/step - loss: 0.6241 - acc: 0.6510 - val_loss: 1.0352 - val_acc: 0.0798\n",
      "Epoch 29/40\n",
      "2252/2252 [==============================] - 2s 835us/step - loss: 0.6258 - acc: 0.6501 - val_loss: 0.9886 - val_acc: 0.0975\n",
      "Epoch 30/40\n",
      "2252/2252 [==============================] - 2s 770us/step - loss: 0.6236 - acc: 0.6523 - val_loss: 1.0495 - val_acc: 0.0940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/40\n",
      "2252/2252 [==============================] - 2s 752us/step - loss: 0.6225 - acc: 0.6581 - val_loss: 0.9373 - val_acc: 0.1152\n",
      "Epoch 32/40\n",
      "2252/2252 [==============================] - 2s 791us/step - loss: 0.6230 - acc: 0.6607 - val_loss: 1.0909 - val_acc: 0.1011\n",
      "Epoch 33/40\n",
      "2252/2252 [==============================] - 2s 759us/step - loss: 0.6223 - acc: 0.6652 - val_loss: 0.9495 - val_acc: 0.2234\n",
      "Epoch 34/40\n",
      "2252/2252 [==============================] - 2s 738us/step - loss: 0.6193 - acc: 0.6674 - val_loss: 1.1458 - val_acc: 0.1028\n",
      "Epoch 35/40\n",
      "2252/2252 [==============================] - 2s 760us/step - loss: 0.6198 - acc: 0.6599 - val_loss: 0.9363 - val_acc: 0.1401\n",
      "Epoch 36/40\n",
      "2252/2252 [==============================] - 2s 788us/step - loss: 0.6211 - acc: 0.6572 - val_loss: 1.0061 - val_acc: 0.1152\n",
      "Epoch 37/40\n",
      "2252/2252 [==============================] - 2s 776us/step - loss: 0.6180 - acc: 0.6630 - val_loss: 0.9855 - val_acc: 0.2411\n",
      "Epoch 38/40\n",
      "2252/2252 [==============================] - 2s 759us/step - loss: 0.6184 - acc: 0.6612 - val_loss: 1.0704 - val_acc: 0.0975\n",
      "Epoch 39/40\n",
      "2252/2252 [==============================] - 2s 745us/step - loss: 0.6197 - acc: 0.6625 - val_loss: 0.9887 - val_acc: 0.1862\n",
      "Epoch 40/40\n",
      "2252/2252 [==============================] - 2s 811us/step - loss: 0.6174 - acc: 0.6727 - val_loss: 0.9463 - val_acc: 0.2677\n",
      "313/313 [==============================] - 0s 34us/step\n",
      "Average accuracy of model on the dev set =  0.5566736534028328\n",
      "Training on fold 6/10.............................................\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_39 (Dense)             (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 5,425\n",
      "Trainable params: 5,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2252 samples, validate on 564 samples\n",
      "Epoch 1/40\n",
      "2252/2252 [==============================] - 3s 1ms/step - loss: 0.6599 - acc: 0.6172 - val_loss: 1.0785 - val_acc: 0.0000e+00\n",
      "Epoch 2/40\n",
      "2252/2252 [==============================] - 2s 695us/step - loss: 0.6479 - acc: 0.6377 - val_loss: 0.9727 - val_acc: 0.0514\n",
      "Epoch 3/40\n",
      "2252/2252 [==============================] - 2s 776us/step - loss: 0.6444 - acc: 0.6456 - val_loss: 0.9516 - val_acc: 0.0940\n",
      "Epoch 4/40\n",
      "2252/2252 [==============================] - 2s 750us/step - loss: 0.6430 - acc: 0.6536 - val_loss: 1.0657 - val_acc: 0.0816\n",
      "Epoch 5/40\n",
      "2252/2252 [==============================] - 2s 793us/step - loss: 0.6420 - acc: 0.6528 - val_loss: 1.0375 - val_acc: 0.0940\n",
      "Epoch 6/40\n",
      "2252/2252 [==============================] - 2s 819us/step - loss: 0.6415 - acc: 0.6532 - val_loss: 1.0436 - val_acc: 0.0957\n",
      "Epoch 7/40\n",
      "2252/2252 [==============================] - 2s 778us/step - loss: 0.6394 - acc: 0.6541 - val_loss: 1.1452 - val_acc: 0.0851\n",
      "Epoch 8/40\n",
      "2252/2252 [==============================] - 2s 812us/step - loss: 0.6398 - acc: 0.6532 - val_loss: 0.9721 - val_acc: 0.0993\n",
      "Epoch 9/40\n",
      "2252/2252 [==============================] - 2s 810us/step - loss: 0.6388 - acc: 0.6541 - val_loss: 0.9883 - val_acc: 0.0975\n",
      "Epoch 10/40\n",
      "2252/2252 [==============================] - 2s 765us/step - loss: 0.6378 - acc: 0.6523 - val_loss: 1.0438 - val_acc: 0.0975\n",
      "Epoch 11/40\n",
      "2252/2252 [==============================] - 2s 868us/step - loss: 0.6377 - acc: 0.6541 - val_loss: 1.0624 - val_acc: 0.0975\n",
      "Epoch 12/40\n",
      "2252/2252 [==============================] - 2s 807us/step - loss: 0.6362 - acc: 0.6550 - val_loss: 1.0473 - val_acc: 0.0993\n",
      "Epoch 13/40\n",
      "2252/2252 [==============================] - 2s 859us/step - loss: 0.6354 - acc: 0.6545 - val_loss: 1.0520 - val_acc: 0.0993\n",
      "Epoch 14/40\n",
      "2252/2252 [==============================] - 2s 761us/step - loss: 0.6334 - acc: 0.6567 - val_loss: 0.9948 - val_acc: 0.0993\n",
      "Epoch 15/40\n",
      "2252/2252 [==============================] - 2s 891us/step - loss: 0.6325 - acc: 0.6541 - val_loss: 1.0294 - val_acc: 0.0993\n",
      "Epoch 16/40\n",
      "2252/2252 [==============================] - 2s 680us/step - loss: 0.6307 - acc: 0.6567 - val_loss: 1.0466 - val_acc: 0.0833\n",
      "Epoch 17/40\n",
      "2252/2252 [==============================] - 1s 615us/step - loss: 0.6307 - acc: 0.6554 - val_loss: 0.9920 - val_acc: 0.0993\n",
      "Epoch 18/40\n",
      "2252/2252 [==============================] - 1s 616us/step - loss: 0.6274 - acc: 0.6550 - val_loss: 0.9934 - val_acc: 0.0993\n",
      "Epoch 19/40\n",
      "2252/2252 [==============================] - 2s 733us/step - loss: 0.6270 - acc: 0.6630 - val_loss: 0.9214 - val_acc: 0.1082\n",
      "Epoch 20/40\n",
      "2252/2252 [==============================] - 2s 721us/step - loss: 0.6246 - acc: 0.6607 - val_loss: 1.0985 - val_acc: 0.0798\n",
      "Epoch 21/40\n",
      "2252/2252 [==============================] - 2s 956us/step - loss: 0.6241 - acc: 0.6572 - val_loss: 0.9747 - val_acc: 0.1135\n",
      "Epoch 22/40\n",
      "2252/2252 [==============================] - 2s 752us/step - loss: 0.6235 - acc: 0.6661 - val_loss: 0.9831 - val_acc: 0.1099\n",
      "Epoch 23/40\n",
      "2252/2252 [==============================] - 2s 757us/step - loss: 0.6195 - acc: 0.6674 - val_loss: 0.9279 - val_acc: 0.1241\n",
      "Epoch 24/40\n",
      "2252/2252 [==============================] - 1s 648us/step - loss: 0.6210 - acc: 0.6634 - val_loss: 0.9923 - val_acc: 0.1117\n",
      "Epoch 25/40\n",
      "2252/2252 [==============================] - 2s 731us/step - loss: 0.6193 - acc: 0.6670 - val_loss: 0.9800 - val_acc: 0.1099\n",
      "Epoch 26/40\n",
      "2252/2252 [==============================] - 1s 630us/step - loss: 0.6173 - acc: 0.6692 - val_loss: 1.0317 - val_acc: 0.1082\n",
      "Epoch 27/40\n",
      "2252/2252 [==============================] - 1s 658us/step - loss: 0.6179 - acc: 0.6687 - val_loss: 1.0126 - val_acc: 0.1135\n",
      "Epoch 28/40\n",
      "2252/2252 [==============================] - 1s 637us/step - loss: 0.6158 - acc: 0.6674 - val_loss: 0.9590 - val_acc: 0.1667\n",
      "Epoch 29/40\n",
      "2252/2252 [==============================] - 1s 625us/step - loss: 0.6136 - acc: 0.6781 - val_loss: 1.1356 - val_acc: 0.0940\n",
      "Epoch 30/40\n",
      "2252/2252 [==============================] - 2s 671us/step - loss: 0.6156 - acc: 0.6710 - val_loss: 1.1299 - val_acc: 0.1099\n",
      "Epoch 31/40\n",
      "2252/2252 [==============================] - 1s 641us/step - loss: 0.6155 - acc: 0.6683 - val_loss: 1.0871 - val_acc: 0.0957\n",
      "Epoch 32/40\n",
      "2252/2252 [==============================] - 1s 622us/step - loss: 0.6107 - acc: 0.6821 - val_loss: 0.9295 - val_acc: 0.4521\n",
      "Epoch 33/40\n",
      "2252/2252 [==============================] - 2s 776us/step - loss: 0.6127 - acc: 0.6829 - val_loss: 0.9040 - val_acc: 0.3493\n",
      "Epoch 34/40\n",
      "2252/2252 [==============================] - 2s 808us/step - loss: 0.6097 - acc: 0.6772 - val_loss: 0.9864 - val_acc: 0.1117\n",
      "Epoch 35/40\n",
      "2252/2252 [==============================] - 2s 912us/step - loss: 0.6099 - acc: 0.6807 - val_loss: 0.8929 - val_acc: 0.3954\n",
      "Epoch 36/40\n",
      "2252/2252 [==============================] - 2s 781us/step - loss: 0.6083 - acc: 0.6821 - val_loss: 0.9716 - val_acc: 0.2589\n",
      "Epoch 37/40\n",
      "2252/2252 [==============================] - 2s 782us/step - loss: 0.6072 - acc: 0.6825 - val_loss: 0.9260 - val_acc: 0.3422\n",
      "Epoch 38/40\n",
      "2252/2252 [==============================] - 2s 773us/step - loss: 0.6078 - acc: 0.6865 - val_loss: 0.9814 - val_acc: 0.2748\n",
      "Epoch 39/40\n",
      "2252/2252 [==============================] - 2s 746us/step - loss: 0.6064 - acc: 0.6838 - val_loss: 0.9672 - val_acc: 0.2252\n",
      "Epoch 40/40\n",
      "2252/2252 [==============================] - 2s 741us/step - loss: 0.6046 - acc: 0.6878 - val_loss: 0.9044 - val_acc: 0.3848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 35us/step\n",
      "Average accuracy of model on the dev set =  0.5868979059302528\n",
      "Training on fold 7/10.............................................\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_45 (Dense)             (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 5,425\n",
      "Trainable params: 5,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2252 samples, validate on 564 samples\n",
      "Epoch 1/40\n",
      "2252/2252 [==============================] - 3s 1ms/step - loss: 0.6721 - acc: 0.6030 - val_loss: 1.1029 - val_acc: 0.0000e+00\n",
      "Epoch 2/40\n",
      "2252/2252 [==============================] - 2s 761us/step - loss: 0.6479 - acc: 0.6470 - val_loss: 1.0827 - val_acc: 0.0000e+00\n",
      "Epoch 3/40\n",
      "2252/2252 [==============================] - 2s 802us/step - loss: 0.6456 - acc: 0.6443 - val_loss: 1.1237 - val_acc: 0.0479\n",
      "Epoch 4/40\n",
      "2252/2252 [==============================] - 2s 757us/step - loss: 0.6444 - acc: 0.6501 - val_loss: 1.0400 - val_acc: 0.0567\n",
      "Epoch 5/40\n",
      "2252/2252 [==============================] - 2s 726us/step - loss: 0.6436 - acc: 0.6501 - val_loss: 1.0038 - val_acc: 0.0851\n",
      "Epoch 6/40\n",
      "2252/2252 [==============================] - 2s 791us/step - loss: 0.6439 - acc: 0.6505 - val_loss: 1.0336 - val_acc: 0.0798\n",
      "Epoch 7/40\n",
      "2252/2252 [==============================] - 2s 772us/step - loss: 0.6430 - acc: 0.6536 - val_loss: 1.0436 - val_acc: 0.0621\n",
      "Epoch 8/40\n",
      "2252/2252 [==============================] - 2s 861us/step - loss: 0.6426 - acc: 0.6496 - val_loss: 1.0104 - val_acc: 0.0851\n",
      "Epoch 9/40\n",
      "2252/2252 [==============================] - 2s 873us/step - loss: 0.6420 - acc: 0.6536 - val_loss: 0.9543 - val_acc: 0.0957\n",
      "Epoch 10/40\n",
      "2252/2252 [==============================] - 2s 830us/step - loss: 0.6412 - acc: 0.6528 - val_loss: 1.0426 - val_acc: 0.0603\n",
      "Epoch 11/40\n",
      "2252/2252 [==============================] - 2s 749us/step - loss: 0.6417 - acc: 0.6505 - val_loss: 1.0825 - val_acc: 0.0816\n",
      "Epoch 12/40\n",
      "2252/2252 [==============================] - 2s 819us/step - loss: 0.6407 - acc: 0.6536 - val_loss: 1.0982 - val_acc: 0.0603\n",
      "Epoch 13/40\n",
      "2252/2252 [==============================] - 2s 771us/step - loss: 0.6391 - acc: 0.6523 - val_loss: 1.0966 - val_acc: 0.0816\n",
      "Epoch 14/40\n",
      "2252/2252 [==============================] - 2s 747us/step - loss: 0.6384 - acc: 0.6519 - val_loss: 1.0873 - val_acc: 0.0798\n",
      "Epoch 15/40\n",
      "2252/2252 [==============================] - 1s 633us/step - loss: 0.6377 - acc: 0.6519 - val_loss: 1.0854 - val_acc: 0.0798\n",
      "Epoch 16/40\n",
      "2252/2252 [==============================] - 1s 622us/step - loss: 0.6364 - acc: 0.6541 - val_loss: 1.2068 - val_acc: 0.0798\n",
      "Epoch 17/40\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.6364 - acc: 0.6536 - val_loss: 1.0985 - val_acc: 0.0798\n",
      "Epoch 18/40\n",
      "2252/2252 [==============================] - 1s 629us/step - loss: 0.6349 - acc: 0.6559 - val_loss: 1.1627 - val_acc: 0.0798\n",
      "Epoch 19/40\n",
      "2252/2252 [==============================] - 1s 606us/step - loss: 0.6344 - acc: 0.6550 - val_loss: 1.1055 - val_acc: 0.0922\n",
      "Epoch 20/40\n",
      "2252/2252 [==============================] - 1s 655us/step - loss: 0.6339 - acc: 0.6545 - val_loss: 1.0632 - val_acc: 0.0904\n",
      "Epoch 21/40\n",
      "2252/2252 [==============================] - 1s 633us/step - loss: 0.6318 - acc: 0.6545 - val_loss: 1.0183 - val_acc: 0.0922\n",
      "Epoch 22/40\n",
      "2252/2252 [==============================] - 2s 690us/step - loss: 0.6311 - acc: 0.6554 - val_loss: 1.0468 - val_acc: 0.0674\n",
      "Epoch 23/40\n",
      "2252/2252 [==============================] - 1s 622us/step - loss: 0.6275 - acc: 0.6581 - val_loss: 1.0408 - val_acc: 0.1011\n",
      "Epoch 24/40\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.6277 - acc: 0.6541 - val_loss: 0.9766 - val_acc: 0.0266\n",
      "Epoch 25/40\n",
      "2252/2252 [==============================] - 1s 648us/step - loss: 0.6271 - acc: 0.6536 - val_loss: 0.9897 - val_acc: 0.0780\n",
      "Epoch 26/40\n",
      "2252/2252 [==============================] - 1s 625us/step - loss: 0.6237 - acc: 0.6563 - val_loss: 0.8841 - val_acc: 0.3422\n",
      "Epoch 27/40\n",
      "2252/2252 [==============================] - 1s 533us/step - loss: 0.6242 - acc: 0.6532 - val_loss: 1.0203 - val_acc: 0.0957\n",
      "Epoch 28/40\n",
      "2252/2252 [==============================] - 1s 648us/step - loss: 0.6231 - acc: 0.6599 - val_loss: 1.0051 - val_acc: 0.0957\n",
      "Epoch 29/40\n",
      "2252/2252 [==============================] - 1s 638us/step - loss: 0.6202 - acc: 0.6612 - val_loss: 1.0681 - val_acc: 0.0993\n",
      "Epoch 30/40\n",
      "2252/2252 [==============================] - 2s 672us/step - loss: 0.6203 - acc: 0.6639 - val_loss: 1.1045 - val_acc: 0.0195\n",
      "Epoch 31/40\n",
      "2252/2252 [==============================] - 2s 688us/step - loss: 0.6190 - acc: 0.6643 - val_loss: 0.9631 - val_acc: 0.1844\n",
      "Epoch 32/40\n",
      "2252/2252 [==============================] - 1s 604us/step - loss: 0.6184 - acc: 0.6696 - val_loss: 0.9407 - val_acc: 0.3121\n",
      "Epoch 33/40\n",
      "2252/2252 [==============================] - 1s 626us/step - loss: 0.6170 - acc: 0.6714 - val_loss: 1.0360 - val_acc: 0.0993\n",
      "Epoch 34/40\n",
      "2252/2252 [==============================] - 1s 604us/step - loss: 0.6176 - acc: 0.6661 - val_loss: 0.8980 - val_acc: 0.3972\n",
      "Epoch 35/40\n",
      "2252/2252 [==============================] - 1s 576us/step - loss: 0.6135 - acc: 0.6692 - val_loss: 1.0059 - val_acc: 0.2713\n",
      "Epoch 36/40\n",
      "2252/2252 [==============================] - 2s 666us/step - loss: 0.6146 - acc: 0.6683 - val_loss: 1.0485 - val_acc: 0.0514\n",
      "Epoch 37/40\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.6142 - acc: 0.6665 - val_loss: 0.8637 - val_acc: 0.4238\n",
      "Epoch 38/40\n",
      "2252/2252 [==============================] - 1s 657us/step - loss: 0.6134 - acc: 0.6701 - val_loss: 0.8956 - val_acc: 0.3883\n",
      "Epoch 39/40\n",
      "2252/2252 [==============================] - 2s 672us/step - loss: 0.6121 - acc: 0.6745 - val_loss: 1.0012 - val_acc: 0.2801 0.6106 - acc: \n",
      "Epoch 40/40\n",
      "2252/2252 [==============================] - 2s 718us/step - loss: 0.6129 - acc: 0.6683 - val_loss: 1.0220 - val_acc: 0.2234\n",
      "313/313 [==============================] - 0s 24us/step\n",
      "Average accuracy of model on the dev set =  0.5938814549039902\n",
      "Training on fold 8/10.............................................\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_51 (Dense)             (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 5,425\n",
      "Trainable params: 5,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2253 samples, validate on 564 samples\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2253/2253 [==============================] - 3s 1ms/step - loss: 0.6507 - acc: 0.6440 - val_loss: 1.0625 - val_acc: 0.0000e+00\n",
      "Epoch 2/40\n",
      "2253/2253 [==============================] - 1s 619us/step - loss: 0.6471 - acc: 0.6436 - val_loss: 1.0394 - val_acc: 0.0000e+00\n",
      "Epoch 3/40\n",
      "2253/2253 [==============================] - 2s 668us/step - loss: 0.6441 - acc: 0.6431 - val_loss: 0.9738 - val_acc: 0.1011\n",
      "Epoch 4/40\n",
      "2253/2253 [==============================] - 1s 614us/step - loss: 0.6424 - acc: 0.6502 - val_loss: 1.0481 - val_acc: 0.0957\n",
      "Epoch 5/40\n",
      "2253/2253 [==============================] - 1s 643us/step - loss: 0.6412 - acc: 0.6489 - val_loss: 1.0937 - val_acc: 0.0993\n",
      "Epoch 6/40\n",
      "2253/2253 [==============================] - 1s 633us/step - loss: 0.6403 - acc: 0.6525 - val_loss: 1.0639 - val_acc: 0.1011\n",
      "Epoch 7/40\n",
      "2253/2253 [==============================] - 2s 685us/step - loss: 0.6384 - acc: 0.6511 - val_loss: 1.0646 - val_acc: 0.0904\n",
      "Epoch 8/40\n",
      "2253/2253 [==============================] - 1s 653us/step - loss: 0.6362 - acc: 0.6511 - val_loss: 1.0406 - val_acc: 0.1028\n",
      "Epoch 9/40\n",
      "2253/2253 [==============================] - 1s 637us/step - loss: 0.6356 - acc: 0.6565 - val_loss: 1.0155 - val_acc: 0.0993\n",
      "Epoch 10/40\n",
      "2253/2253 [==============================] - 2s 671us/step - loss: 0.6334 - acc: 0.6551 - val_loss: 1.0147 - val_acc: 0.1011\n",
      "Epoch 11/40\n",
      "2253/2253 [==============================] - 1s 643us/step - loss: 0.6314 - acc: 0.6556 - val_loss: 1.1386 - val_acc: 0.1011\n",
      "Epoch 12/40\n",
      "2253/2253 [==============================] - 1s 655us/step - loss: 0.6287 - acc: 0.6556 - val_loss: 0.9595 - val_acc: 0.1046\n",
      "Epoch 13/40\n",
      "2253/2253 [==============================] - 1s 602us/step - loss: 0.6293 - acc: 0.6542 - val_loss: 1.0979 - val_acc: 0.1028\n",
      "Epoch 14/40\n",
      "2253/2253 [==============================] - 1s 595us/step - loss: 0.6258 - acc: 0.6565 - val_loss: 0.9980 - val_acc: 0.1099\n",
      "Epoch 15/40\n",
      "2253/2253 [==============================] - 1s 646us/step - loss: 0.6259 - acc: 0.6565 - val_loss: 1.0034 - val_acc: 0.1028\n",
      "Epoch 16/40\n",
      "2253/2253 [==============================] - 1s 625us/step - loss: 0.6241 - acc: 0.6587 - val_loss: 1.0360 - val_acc: 0.0745\n",
      "Epoch 17/40\n",
      "2253/2253 [==============================] - 1s 649us/step - loss: 0.6232 - acc: 0.6613 - val_loss: 0.8662 - val_acc: 0.4433\n",
      "Epoch 18/40\n",
      "2253/2253 [==============================] - 1s 648us/step - loss: 0.6194 - acc: 0.6715 - val_loss: 0.8809 - val_acc: 0.4113\n",
      "Epoch 19/40\n",
      "2253/2253 [==============================] - 2s 690us/step - loss: 0.6178 - acc: 0.6689 - val_loss: 1.0781 - val_acc: 0.1294\n",
      "Epoch 20/40\n",
      "2253/2253 [==============================] - 1s 611us/step - loss: 0.6178 - acc: 0.6742 - val_loss: 0.9441 - val_acc: 0.3422\n",
      "Epoch 21/40\n",
      "2253/2253 [==============================] - 1s 624us/step - loss: 0.6151 - acc: 0.6747 - val_loss: 1.0938 - val_acc: 0.1135\n",
      "Epoch 22/40\n",
      "2253/2253 [==============================] - 1s 665us/step - loss: 0.6163 - acc: 0.6662 - val_loss: 0.8764 - val_acc: 0.4220\n",
      "Epoch 23/40\n",
      "2253/2253 [==============================] - 1s 662us/step - loss: 0.6151 - acc: 0.6742 - val_loss: 0.9724 - val_acc: 0.2465\n",
      "Epoch 24/40\n",
      "2253/2253 [==============================] - 1s 613us/step - loss: 0.6127 - acc: 0.6782 - val_loss: 0.9990 - val_acc: 0.2748\n",
      "Epoch 25/40\n",
      "2253/2253 [==============================] - 1s 650us/step - loss: 0.6122 - acc: 0.6751 - val_loss: 0.9542 - val_acc: 0.3599\n",
      "Epoch 26/40\n",
      "2253/2253 [==============================] - 1s 604us/step - loss: 0.6092 - acc: 0.6778 - val_loss: 0.9666 - val_acc: 0.3156\n",
      "Epoch 27/40\n",
      "2253/2253 [==============================] - 1s 632us/step - loss: 0.6113 - acc: 0.6813 - val_loss: 0.9300 - val_acc: 0.3936\n",
      "Epoch 28/40\n",
      "2253/2253 [==============================] - 1s 599us/step - loss: 0.6049 - acc: 0.6849 - val_loss: 0.9137 - val_acc: 0.3582\n",
      "Epoch 29/40\n",
      "2253/2253 [==============================] - 2s 670us/step - loss: 0.6070 - acc: 0.6831 - val_loss: 0.9414 - val_acc: 0.3121\n",
      "Epoch 30/40\n",
      "2253/2253 [==============================] - 2s 672us/step - loss: 0.6082 - acc: 0.6818 - val_loss: 0.9890 - val_acc: 0.3014\n",
      "Epoch 31/40\n",
      "2253/2253 [==============================] - 2s 666us/step - loss: 0.6044 - acc: 0.6835 - val_loss: 1.0759 - val_acc: 0.2996\n",
      "Epoch 32/40\n",
      "2253/2253 [==============================] - 1s 604us/step - loss: 0.6042 - acc: 0.6858 - val_loss: 0.9041 - val_acc: 0.4167\n",
      "Epoch 33/40\n",
      "2253/2253 [==============================] - 1s 664us/step - loss: 0.6043 - acc: 0.6871 - val_loss: 0.8857 - val_acc: 0.4787\n",
      "Epoch 34/40\n",
      "2253/2253 [==============================] - 1s 641us/step - loss: 0.6053 - acc: 0.6866 - val_loss: 1.0409 - val_acc: 0.3227\n",
      "Epoch 35/40\n",
      "2253/2253 [==============================] - 2s 683us/step - loss: 0.6017 - acc: 0.6897 - val_loss: 0.8685 - val_acc: 0.4238\n",
      "Epoch 36/40\n",
      "2253/2253 [==============================] - 2s 670us/step - loss: 0.6028 - acc: 0.6893 - val_loss: 0.9593 - val_acc: 0.3387\n",
      "Epoch 37/40\n",
      "2253/2253 [==============================] - 1s 662us/step - loss: 0.6020 - acc: 0.6822 - val_loss: 0.8249 - val_acc: 0.5000\n",
      "Epoch 38/40\n",
      "2253/2253 [==============================] - 1s 660us/step - loss: 0.5987 - acc: 0.6884 - val_loss: 0.9265 - val_acc: 0.3936\n",
      "Epoch 39/40\n",
      "2253/2253 [==============================] - 1s 635us/step - loss: 0.5980 - acc: 0.6924 - val_loss: 1.1206 - val_acc: 0.2819\n",
      "Epoch 40/40\n",
      "2253/2253 [==============================] - 1s 616us/step - loss: 0.5985 - acc: 0.6933 - val_loss: 1.0232 - val_acc: 0.2535\n",
      "312/312 [==============================] - 0s 25us/step\n",
      "Average accuracy of model on the dev set =  0.6069860165352148\n",
      "Training on fold 9/10.............................................\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_57 (Dense)             (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 5,425\n",
      "Trainable params: 5,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2253 samples, validate on 564 samples\n",
      "Epoch 1/40\n",
      "2253/2253 [==============================] - 2s 1ms/step - loss: 0.6845 - acc: 0.5735 - val_loss: 0.9301 - val_acc: 0.0000e+00\n",
      "Epoch 2/40\n",
      "2253/2253 [==============================] - 1s 621us/step - loss: 0.6497 - acc: 0.6431 - val_loss: 1.0210 - val_acc: 0.0000e+00\n",
      "Epoch 3/40\n",
      "2253/2253 [==============================] - 1s 615us/step - loss: 0.6467 - acc: 0.6418 - val_loss: 0.9799 - val_acc: 0.0550\n",
      "Epoch 4/40\n",
      "2253/2253 [==============================] - 1s 623us/step - loss: 0.6456 - acc: 0.6462 - val_loss: 1.1226 - val_acc: 0.0550\n",
      "Epoch 5/40\n",
      "2253/2253 [==============================] - 2s 677us/step - loss: 0.6446 - acc: 0.6480 - val_loss: 1.0630 - val_acc: 0.0550\n",
      "Epoch 6/40\n",
      "2253/2253 [==============================] - 1s 657us/step - loss: 0.6439 - acc: 0.6494 - val_loss: 0.9786 - val_acc: 0.0887\n",
      "Epoch 7/40\n",
      "2253/2253 [==============================] - 2s 670us/step - loss: 0.6434 - acc: 0.6489 - val_loss: 1.0955 - val_acc: 0.0727\n",
      "Epoch 8/40\n",
      "2253/2253 [==============================] - 2s 674us/step - loss: 0.6436 - acc: 0.6476 - val_loss: 1.0548 - val_acc: 0.0887\n",
      "Epoch 9/40\n",
      "2253/2253 [==============================] - 2s 670us/step - loss: 0.6428 - acc: 0.6498 - val_loss: 0.9602 - val_acc: 0.0887\n",
      "Epoch 10/40\n",
      "2253/2253 [==============================] - 1s 645us/step - loss: 0.6423 - acc: 0.6507 - val_loss: 1.0936 - val_acc: 0.0727\n",
      "Epoch 11/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2253/2253 [==============================] - 1s 648us/step - loss: 0.6430 - acc: 0.6511 - val_loss: 1.0230 - val_acc: 0.0887\n",
      "Epoch 12/40\n",
      "2253/2253 [==============================] - 1s 648us/step - loss: 0.6411 - acc: 0.6516 - val_loss: 0.9787 - val_acc: 0.0904\n",
      "Epoch 13/40\n",
      "2253/2253 [==============================] - 1s 620us/step - loss: 0.6414 - acc: 0.6494 - val_loss: 1.0678 - val_acc: 0.0887\n",
      "Epoch 14/40\n",
      "2253/2253 [==============================] - 2s 667us/step - loss: 0.6413 - acc: 0.6529 - val_loss: 0.9228 - val_acc: 0.0975\n",
      "Epoch 15/40\n",
      "2253/2253 [==============================] - 1s 637us/step - loss: 0.6413 - acc: 0.6520 - val_loss: 0.9942 - val_acc: 0.0904\n",
      "Epoch 16/40\n",
      "2253/2253 [==============================] - 1s 616us/step - loss: 0.6395 - acc: 0.6511 - val_loss: 1.0723 - val_acc: 0.0727\n",
      "Epoch 17/40\n",
      "2253/2253 [==============================] - 2s 680us/step - loss: 0.6394 - acc: 0.6520 - val_loss: 0.9729 - val_acc: 0.0922\n",
      "Epoch 18/40\n",
      "2253/2253 [==============================] - 1s 625us/step - loss: 0.6365 - acc: 0.6542 - val_loss: 1.1654 - val_acc: 0.0904\n",
      "Epoch 19/40\n",
      "2253/2253 [==============================] - 1s 655us/step - loss: 0.6373 - acc: 0.6529 - val_loss: 1.0029 - val_acc: 0.1011\n",
      "Epoch 20/40\n",
      "2253/2253 [==============================] - 1s 602us/step - loss: 0.6350 - acc: 0.6551 - val_loss: 1.0181 - val_acc: 0.1011\n",
      "Epoch 21/40\n",
      "2253/2253 [==============================] - 1s 662us/step - loss: 0.6364 - acc: 0.6573 - val_loss: 1.0307 - val_acc: 0.1011\n",
      "Epoch 22/40\n",
      "2253/2253 [==============================] - 1s 639us/step - loss: 0.6345 - acc: 0.6565 - val_loss: 0.9423 - val_acc: 0.1011\n",
      "Epoch 23/40\n",
      "2253/2253 [==============================] - 2s 681us/step - loss: 0.6331 - acc: 0.6560 - val_loss: 1.1599 - val_acc: 0.0195\n",
      "Epoch 24/40\n",
      "2253/2253 [==============================] - 1s 641us/step - loss: 0.6336 - acc: 0.6525 - val_loss: 0.9832 - val_acc: 0.1011\n",
      "Epoch 25/40\n",
      "2253/2253 [==============================] - 2s 672us/step - loss: 0.6315 - acc: 0.6560 - val_loss: 0.9809 - val_acc: 0.1011\n",
      "Epoch 26/40\n",
      "2253/2253 [==============================] - 1s 624us/step - loss: 0.6311 - acc: 0.6565 - val_loss: 0.9863 - val_acc: 0.0301\n",
      "Epoch 27/40\n",
      "2253/2253 [==============================] - 1s 632us/step - loss: 0.6299 - acc: 0.6573 - val_loss: 0.9218 - val_acc: 0.1064\n",
      "Epoch 28/40\n",
      "2253/2253 [==============================] - 1s 658us/step - loss: 0.6286 - acc: 0.6596 - val_loss: 1.0439 - val_acc: 0.0301\n",
      "Epoch 29/40\n",
      "2253/2253 [==============================] - 1s 654us/step - loss: 0.6281 - acc: 0.6538 - val_loss: 1.1446 - val_acc: 0.0851\n",
      "Epoch 30/40\n",
      "2253/2253 [==============================] - 1s 617us/step - loss: 0.6271 - acc: 0.6578 - val_loss: 0.9491 - val_acc: 0.0496\n",
      "Epoch 31/40\n",
      "2253/2253 [==============================] - 1s 596us/step - loss: 0.6245 - acc: 0.6547 - val_loss: 1.0107 - val_acc: 0.1046\n",
      "Epoch 32/40\n",
      "2253/2253 [==============================] - 1s 638us/step - loss: 0.6251 - acc: 0.6516 - val_loss: 0.9870 - val_acc: 0.0514\n",
      "Epoch 33/40\n",
      "2253/2253 [==============================] - 1s 650us/step - loss: 0.6228 - acc: 0.6587 - val_loss: 1.0295 - val_acc: 0.1046\n",
      "Epoch 34/40\n",
      "2253/2253 [==============================] - 2s 673us/step - loss: 0.6214 - acc: 0.6636 - val_loss: 0.9737 - val_acc: 0.0496\n",
      "Epoch 35/40\n",
      "2253/2253 [==============================] - 2s 673us/step - loss: 0.6200 - acc: 0.6622 - val_loss: 0.8444 - val_acc: 0.3191\n",
      "Epoch 36/40\n",
      "2253/2253 [==============================] - 2s 666us/step - loss: 0.6186 - acc: 0.6671 - val_loss: 1.0727 - val_acc: 0.0479\n",
      "Epoch 37/40\n",
      "2253/2253 [==============================] - 2s 669us/step - loss: 0.6180 - acc: 0.6684 - val_loss: 0.9236 - val_acc: 0.2553\n",
      "Epoch 38/40\n",
      "2253/2253 [==============================] - 2s 667us/step - loss: 0.6178 - acc: 0.6653 - val_loss: 0.9279 - val_acc: 0.1986\n",
      "Epoch 39/40\n",
      "2253/2253 [==============================] - 1s 622us/step - loss: 0.6148 - acc: 0.6693 - val_loss: 0.7086 - val_acc: 0.5904\n",
      "Epoch 40/40\n",
      "2253/2253 [==============================] - 1s 628us/step - loss: 0.6162 - acc: 0.6591 - val_loss: 0.9069 - val_acc: 0.3085\n",
      "312/312 [==============================] - 0s 27us/step\n",
      "Average accuracy of model on the dev set =  0.600796687062641\n",
      "Training on fold 10/10.............................................\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_63 (Dense)             (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 5,425\n",
      "Trainable params: 5,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2253 samples, validate on 564 samples\n",
      "Epoch 1/40\n",
      "2253/2253 [==============================] - 3s 1ms/step - loss: 0.6501 - acc: 0.6440 - val_loss: 1.1179 - val_acc: 0.0000e+00\n",
      "Epoch 2/40\n",
      "2253/2253 [==============================] - 2s 688us/step - loss: 0.6482 - acc: 0.6440 - val_loss: 0.9796 - val_acc: 0.0000e+00\n",
      "Epoch 3/40\n",
      "2253/2253 [==============================] - 2s 669us/step - loss: 0.6447 - acc: 0.6436 - val_loss: 1.0816 - val_acc: 0.0603\n",
      "Epoch 4/40\n",
      "2253/2253 [==============================] - 2s 682us/step - loss: 0.6439 - acc: 0.6498 - val_loss: 1.0109 - val_acc: 0.0975\n",
      "Epoch 5/40\n",
      "2253/2253 [==============================] - 1s 664us/step - loss: 0.6425 - acc: 0.6520 - val_loss: 1.0719 - val_acc: 0.0727\n",
      "Epoch 6/40\n",
      "2253/2253 [==============================] - 2s 706us/step - loss: 0.6417 - acc: 0.6516 - val_loss: 1.1002 - val_acc: 0.0603\n",
      "Epoch 7/40\n",
      "2253/2253 [==============================] - 2s 694us/step - loss: 0.6415 - acc: 0.6516 - val_loss: 1.0096 - val_acc: 0.1046\n",
      "Epoch 8/40\n",
      "2253/2253 [==============================] - 2s 767us/step - loss: 0.6404 - acc: 0.6516 - val_loss: 1.0331 - val_acc: 0.1064\n",
      "Epoch 9/40\n",
      "2253/2253 [==============================] - 2s 674us/step - loss: 0.6395 - acc: 0.6520 - val_loss: 0.9835 - val_acc: 0.1082\n",
      "Epoch 10/40\n",
      "2253/2253 [==============================] - 2s 667us/step - loss: 0.6389 - acc: 0.6516 - val_loss: 1.0397 - val_acc: 0.1082\n",
      "Epoch 11/40\n",
      "2253/2253 [==============================] - 2s 828us/step - loss: 0.6379 - acc: 0.6520 - val_loss: 1.0805 - val_acc: 0.1046\n",
      "Epoch 12/40\n",
      "2253/2253 [==============================] - 2s 669us/step - loss: 0.6375 - acc: 0.6511 - val_loss: 0.9857 - val_acc: 0.1099\n",
      "Epoch 13/40\n",
      "2253/2253 [==============================] - 2s 684us/step - loss: 0.6354 - acc: 0.6525 - val_loss: 1.0374 - val_acc: 0.1117\n",
      "Epoch 14/40\n",
      "2253/2253 [==============================] - 2s 669us/step - loss: 0.6345 - acc: 0.6538 - val_loss: 1.0528 - val_acc: 0.0833\n",
      "Epoch 15/40\n",
      "2253/2253 [==============================] - 1s 638us/step - loss: 0.6335 - acc: 0.6534 - val_loss: 0.8958 - val_acc: 0.1099\n",
      "Epoch 16/40\n",
      "2253/2253 [==============================] - 2s 671us/step - loss: 0.6322 - acc: 0.6556 - val_loss: 1.0238 - val_acc: 0.1082\n",
      "Epoch 17/40\n",
      "2253/2253 [==============================] - 2s 699us/step - loss: 0.6298 - acc: 0.6551 - val_loss: 1.0886 - val_acc: 0.0887\n",
      "Epoch 18/40\n",
      "2253/2253 [==============================] - 1s 656us/step - loss: 0.6289 - acc: 0.6551 - val_loss: 1.0136 - val_acc: 0.1117\n",
      "Epoch 19/40\n",
      "2253/2253 [==============================] - 1s 580us/step - loss: 0.6292 - acc: 0.6565 - val_loss: 0.9669 - val_acc: 0.1117\n",
      "Epoch 20/40\n",
      "2253/2253 [==============================] - 2s 689us/step - loss: 0.6259 - acc: 0.6560 - val_loss: 0.9492 - val_acc: 0.1135\n",
      "Epoch 21/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2253/2253 [==============================] - 2s 753us/step - loss: 0.6242 - acc: 0.6605 - val_loss: 0.9758 - val_acc: 0.0904\n",
      "Epoch 22/40\n",
      "2253/2253 [==============================] - 2s 674us/step - loss: 0.6231 - acc: 0.6618 - val_loss: 1.0375 - val_acc: 0.2447\n",
      "Epoch 23/40\n",
      "2253/2253 [==============================] - 2s 781us/step - loss: 0.6220 - acc: 0.6640 - val_loss: 1.0012 - val_acc: 0.0922\n",
      "Epoch 24/40\n",
      "2253/2253 [==============================] - 2s 730us/step - loss: 0.6214 - acc: 0.6618 - val_loss: 0.9891 - val_acc: 0.1933\n",
      "Epoch 25/40\n",
      "2253/2253 [==============================] - 2s 696us/step - loss: 0.6186 - acc: 0.6693 - val_loss: 0.8716 - val_acc: 0.2837\n",
      "Epoch 26/40\n",
      "2253/2253 [==============================] - 2s 669us/step - loss: 0.6181 - acc: 0.6618 - val_loss: 0.7652 - val_acc: 0.5355\n",
      "Epoch 27/40\n",
      "2253/2253 [==============================] - 2s 683us/step - loss: 0.6167 - acc: 0.6627 - val_loss: 0.9682 - val_acc: 0.1844\n",
      "Epoch 28/40\n",
      "2253/2253 [==============================] - 2s 674us/step - loss: 0.6164 - acc: 0.6742 - val_loss: 1.0052 - val_acc: 0.1702\n",
      "Epoch 29/40\n",
      "2253/2253 [==============================] - 2s 684us/step - loss: 0.6140 - acc: 0.6702 - val_loss: 0.9509 - val_acc: 0.1933\n",
      "Epoch 30/40\n",
      "2253/2253 [==============================] - 2s 679us/step - loss: 0.6130 - acc: 0.6676 - val_loss: 0.9457 - val_acc: 0.1454\n",
      "Epoch 31/40\n",
      "2253/2253 [==============================] - 2s 670us/step - loss: 0.6097 - acc: 0.6858 - val_loss: 0.8918 - val_acc: 0.4096\n",
      "Epoch 32/40\n",
      "2253/2253 [==============================] - 2s 705us/step - loss: 0.6094 - acc: 0.6769 - val_loss: 0.8504 - val_acc: 0.4433\n",
      "Epoch 33/40\n",
      "2253/2253 [==============================] - 2s 673us/step - loss: 0.6089 - acc: 0.6840 - val_loss: 0.9072 - val_acc: 0.3103\n",
      "Epoch 34/40\n",
      "2253/2253 [==============================] - 2s 672us/step - loss: 0.6091 - acc: 0.6791 - val_loss: 1.1297 - val_acc: 0.1241\n",
      "Epoch 35/40\n",
      "2253/2253 [==============================] - 2s 701us/step - loss: 0.6097 - acc: 0.6778 - val_loss: 0.9123 - val_acc: 0.4096\n",
      "Epoch 36/40\n",
      "2253/2253 [==============================] - 2s 688us/step - loss: 0.6056 - acc: 0.6818 - val_loss: 0.8253 - val_acc: 0.5053\n",
      "Epoch 37/40\n",
      "2253/2253 [==============================] - 2s 692us/step - loss: 0.6037 - acc: 0.6791 - val_loss: 0.8366 - val_acc: 0.5089\n",
      "Epoch 38/40\n",
      "2253/2253 [==============================] - 2s 668us/step - loss: 0.6045 - acc: 0.6835 - val_loss: 0.8485 - val_acc: 0.4858\n",
      "Epoch 39/40\n",
      "2253/2253 [==============================] - 2s 735us/step - loss: 0.6049 - acc: 0.6738 - val_loss: 0.7803 - val_acc: 0.5851\n",
      "Epoch 40/40\n",
      "2253/2253 [==============================] - 2s 730us/step - loss: 0.6022 - acc: 0.6813 - val_loss: 0.9331 - val_acc: 0.3511\n",
      "312/312 [==============================] - 0s 31us/step\n",
      "Average accuracy of model on the dev set =  0.5987298388787494\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, random_state=12)\n",
    "avg_loss = []\n",
    "avg_acc = []\n",
    "# Loop through the indices the split() method returns\n",
    "for index, (train_index, test_index) in enumerate(skf.split(all_data, labels)):\n",
    "    print(\"Training on fold \" + str(index + 1) + \"/10.............................................\")\n",
    "    # Generate batches from indices\n",
    "    x_train, x_test = all_data[train_index], all_data[test_index]\n",
    "    # use one-hot vectors as labels\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "\n",
    "    network = models.Sequential()\n",
    "    \n",
    "\n",
    "    network.add(layers.Dense(16, input_shape=(8,)))\n",
    "    network.add(layers.Dense(32, activation=\"relu\"))\n",
    "    network.add(layers.Dense(64, activation=\"relu\"))\n",
    "    network.add(layers.Dense(32, activation=\"relu\"))\n",
    "    network.add(layers.Dense(16, activation=\"sigmoid\"))\n",
    "    network.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Adam = Adam(lr=0.05)\n",
    "    network.compile(optimizer=Adam(lr=0.00038),\n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=['acc'])\n",
    "\n",
    "    network.summary()\n",
    "\n",
    "    history = network.fit(x_train, y_train, validation_split=0.2,\n",
    "                          epochs=40, verbose=1, batch_size=3)\n",
    "\n",
    "    loss, accuracy = network.evaluate(x_test, y_test)\n",
    "\n",
    "    # evaluate and store the accuracy\n",
    "#     loss, accuracy = model.evaluate(xtest_imagelist, ytest, verbose=1)\n",
    "    avg_loss.append(loss)\n",
    "    avg_acc.append(accuracy)\n",
    "\n",
    "    # cross validation score\n",
    "    print(\"Average accuracy of model on the dev set = \", np.mean(avg_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
